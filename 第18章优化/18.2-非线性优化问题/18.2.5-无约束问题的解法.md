# 18.2.5 无约束问题的解法

考虑一般的优化问题

$$
f\left( \underline{\mathbf{x}}\right)  = \min !,\;\underline{\mathbf{x}} \in  {\mathbb{R}}^{n}, \tag{18.72}
$$

这里 $f$ 是连续可微函数. 本节描述的每一种方法一般是构建一无穷序列 $\left\{  {\underline{\mathbf{x}}}^{k}\right\}   \subset  {\mathbb{R}}^{n}$ , 其聚点是一平稳点. 这个点列将从 ${\underline{x}}^{1}$ 开始,按照如下递推公式构建:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}\;\left( {k = 1,2,\cdots }\right) , \tag{18.73}
$$

即首先在 ${\underline{x}}^{k}$ 处确定一方向 ${\underline{d}}^{k}$ ,而步长 ${\alpha }_{k}$ 表示在 ${\underline{x}}^{k}$ 沿 ${\underline{d}}^{k}$ 方向离 ${\underline{x}}^{k + 1}$ 有多远. 这样的方法称作下降法, 是指

$$
f\left( {\underline{\mathbf{x}}}^{k + 1}\right)  < f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) . \tag{18.74}
$$

等式 $\nabla f\left( \underline{\mathbf{x}}\right)  = 0$ 刻画平稳点,并且可以用作迭代算法的停止规则,其中 $\nabla$ 表示梯度算子 (参见第 933 页 13.2.6.1).

## 18.2.5.1 最速下降法

从现时点 ${\underline{x}}^{k}$ 出发,函数下降最快速的方向是

$$
{\underline{\mathbf{d}}}^{k} =  - \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) , \tag{18.75a}
$$

从而,

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\alpha }_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) . \tag{18.75b}
$$

最速下降法以 $f\left( \underline{\mathbf{x}}\right)  = f\left( {\underline{\mathbf{x}}}^{i}\right)$ 为水平线的示意图见图 18.6.

![01936af3-1230-7a0e-9a4a-8542777881ce_31_543_1081_555_301_0.jpg](/images/01936af3-1230-7a0e-9a4a-8542777881ce_31_543_1081_555_301_0.jpg)

<center>图 18.6</center>

步长 ${\alpha }_{k}$ 由线搜索确定,即 ${\alpha }_{k}$ 是一维问题

$$
f\left( {{\underline{\mathbf{x}}}^{k} + \alpha {\underline{\mathbf{d}}}^{k}}\right)  = \min !,\;\alpha  \geq  0 \tag{18.76}
$$

的解. 上述问题可以用 1208 页 18.2.4 给出的方法求解.

最速下降法(18.75b)收敛得相当慢. 对于序列 $\left\{  {\underline{x}}^{k}\right\}$ 的每个聚点 ${\underline{x}}^{ * }$ ,有 $\nabla f\left( {\underline{\mathbf{x}}}^{ * }\right)  = 0$ . 在二次目标函数情形下,即 $f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} + {\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}}$ ,该方法取如下特殊形式:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}, \tag{18.77a}
$$

其中

$$
{\underline{\mathbf{d}}}^{k} =  - \left( {2\mathbf{C}{\underline{\mathbf{x}}}^{k} + \underline{\mathbf{p}}}\right) ,\;\text{ 且 }\;{\alpha }_{k} = \frac{{\underline{\mathbf{d}}}^{{k}^{\mathrm{T}}}{\mathbf{d}}^{k}}{2{\underline{\mathbf{d}}}^{{k}^{\mathrm{T}}}\mathbf{C}{\underline{\mathbf{d}}}^{k}}. \tag{18.77b}
$$

## 18.2.5.2 牛顿法的应用

假定在当前的近似点 ${\underline{x}}^{k}$ 处,函数 $f$ 由如下二次函数逼近:

$$
q\left( \underline{\mathbf{x}}\right)  = f\left( {\underline{\mathbf{x}}}^{k}\right)  + {\left( \underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  + \frac{1}{2}{\left( \underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right) \left( {\underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{k}}\right) . \tag{18.78}
$$

这里 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right)$ 是黑塞矩阵,即 $f$ 在 ${\underline{\mathbf{x}}}^{k}$ 处的二阶偏导数矩阵. 如果 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right)$ 是正定的,则 $q\left( \underline{\mathbf{x}}\right)$ 在 ${\underline{\mathbf{x}}}^{k + 1}$ 处达到绝对极小,且 $\nabla q\left( {\underline{\mathbf{x}}}^{k + 1}\right)  = 0$ ,从而得到牛顿方法:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) , \tag{18.79a}
$$

即

$$
{\underline{\mathbf{d}}}^{k} =  - {\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) ,\;\text{且}{\alpha }_{k}\text{见 (18.73).} \tag{18.79b}
$$

牛顿法收敛速度快, 但它也有如下缺点:

a) 矩阵 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right)$ 必须是正定的.

b) 该方法仅对充分好的初始点收敛.

c) 步长可能没有影响.

d) 该方法并不是一种下降法.

e) 计算逆矩阵 ${\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right)$ 的计算量相当大.

通过所谓的阻尼牛顿法可能会适当减少某些缺点 (例如 1251 页 19.2.2.2):

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\alpha }_{k}{\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) , \tag{18.80}
$$

其中的松弛因子 ${\alpha }_{k}$ 比如可以通过前面给出的原则来确定 (参见第 1210 页 18.2.5.1).

## 18.2.5.3 共轭梯度法

两个向量 ${\underline{\mathbf{d}}}^{1},{\underline{\mathbf{d}}}^{2}$ 称作相对于对称正定矩阵 $\mathbf{C}$ 是共轭向量,是指它们满足

$$
{\underline{\mathbf{d}}}^{{1}^{\mathrm{T}}}\mathbf{C}{\underline{\mathbf{d}}}^{2} = 0. \tag{18.81}
$$

如果 ${\underline{\mathbf{d}}}^{1},{\underline{\mathbf{d}}}^{2},\cdots ,{\underline{\mathbf{d}}}^{n}$ 相对于矩阵 $\mathbf{C}$ 是两两共轭的,那么凸二次问题 $q\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} +$ ${\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}},\underline{\mathbf{x}} \in  {\mathbb{R}}^{n}$ 可以通过 $n$ 步求解,为此只要从 ${\underline{\mathbf{x}}}^{1}$ 出发构建序列 ${\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}$ , 其中 ${\alpha }_{k}$ 是最优步长. 假设 $f\left( \underline{x}\right)$ 在 ${\underline{x}}^{ * }$ 的邻域内是近似二次函数,即 $C \approx  \frac{1}{2}H\left( {\underline{x}}^{ * }\right)$ , 则为二次目标函数研发的方法也可应用于更一般的函数 $f\left( \underline{x}\right)$ ,而无须明着使用矩阵 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{ * }\right)$ .

共轭梯度法分如下几个步骤:

a) ${\underline{x}}^{1} \in  {\mathbb{R}}^{n},{\underline{d}}^{1} =  - \nabla f\left( {\underline{x}}^{1}\right)$ ,其中 ${\underline{x}}^{1}$ 是 ${\underline{x}}^{ * }$ 的一个适当的初始近似. (18.82)

b) ${\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}\left( {k = 1,\cdots , n}\right)$ ,其中 ${\alpha }_{k} \geq  0$ 使得 $f\left( {{\underline{\mathbf{x}}}^{k} + \alpha {\underline{\mathbf{d}}}^{k}}\right)$ 达到极小.(18.83a)

$$
{\underline{\mathbf{d}}}^{k + 1} =  - \nabla f\left( {\underline{\mathbf{x}}}^{k + 1}\right)  + {\mu }_{k}{\underline{\mathbf{d}}}^{k}\;\left( {k = 1,\cdots , n - 1}\right) , \tag{18.83b}
$$

其中

$$
{\mu }_{k} = \frac{\nabla f{\left( {\underline{\mathbf{x}}}^{k + 1}\right) }^{\mathrm{T}}\nabla f\left( {\underline{\mathbf{x}}}^{k + 1}\right) }{\nabla f{\left( {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) },\;{\underline{\mathbf{d}}}^{n + 1} =  - \nabla f\left( {\underline{\mathbf{x}}}^{n + 1}\right) . \tag{18.83c}
$$

c) 用 ${\underline{x}}^{n + 1}$ 和 ${\underline{d}}^{n + 1}$ 代替 ${\underline{x}}^{1}$ 和 ${\underline{d}}^{1}$ ,重复步骤 b).

## 18.2.5.4 戴维顿 (Davidon)、弗莱彻 (Fletcher) 和鲍威尔 (Powell)(DFP) 方法

在 DFP 方法中,从 ${\underline{x}}^{1}$ 出发的点列根据下列公式确定:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\alpha }_{k}{\mathbf{M}}_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) , \tag{18.84}
$$

这里 ${\mathbf{M}}_{k}$ 是对称正定矩阵. 在 $f$ 为二次函数的情形下,这一方法的想法是逆黑塞矩阵由矩阵 ${\mathbf{M}}_{k}$ 逐步近似. 从对称正定矩阵 ${\mathbf{M}}_{1}$ ,例如, ${\mathbf{M}}_{1} = \mathbf{I}(\mathbf{I}$ 为单位矩阵) 出发, ${\mathbf{M}}_{k}$ 由 ${\mathbf{M}}_{k - 1}$ 加上一个 2 秩修正矩阵确定:

$$
{\mathbf{M}}_{k} = {\mathbf{M}}_{k - 1} + \frac{{\underline{\mathbf{v}}}^{k}{\underline{\mathbf{v}}}^{{k}^{\mathrm{T}}}}{{\underline{\mathbf{v}}}^{{k}^{\mathrm{T}}}{\underline{\mathbf{v}}}^{k}} - \frac{\left( {{\mathbf{M}}_{k - 1}{\underline{\mathbf{w}}}^{k}}\right) {\left( {\mathbf{M}}_{k - 1}{\underline{\mathbf{w}}}^{k}\right) }^{\mathrm{T}}}{{\underline{\mathbf{w}}}^{{k}^{\mathrm{T}}}{\mathbf{M}}_{k}{\underline{\mathbf{w}}}^{k}}, \tag{18.85}
$$

其中 ${\underline{\mathbf{v}}}^{k} = {\underline{\mathbf{x}}}^{k} - {\underline{\mathbf{x}}}^{k - 1},{\underline{\mathbf{w}}}^{k} = \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  - \nabla f\left( {\underline{\mathbf{x}}}^{k - 1}\right) \left( {k = 2,3,\cdots }\right)$ . 步长 ${\alpha }_{k}$ 从求解下列优化问题得到:

$$
f\left( {{\underline{\mathbf{x}}}^{k} - \alpha {\mathbf{M}}_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) }\right)  = \min !,\;\alpha  \geq  0. \tag{18.86}
$$

如果 $f\left( \underline{x}\right)$ 是二次函数,则 DFP 方法变成共轭梯度法,相应的初始 ${\mathbf{M}}_{1} = \mathbf{I}$ .
