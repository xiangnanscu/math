## 第 18 章 优 化

### 18.1 线性规划

#### 18.1.1 问题的提法和几何表达

##### 18.1.1.1 线性规划问题的形式

###### 1. 目的

线性规划的目的是寻找有穷个变量的线性目标函数(OF) 在有穷个线性方程或不等式约束(CT) 限制下的最大值或最小值.

许多实际问题都可以直接叙述为线性规划问题, 或者用线性规划问题近似建模.

###### 2. 一般形式线性规划问题的一般形式是

OF: $f\left( \underline{\mathbf{x}}\right)  = {c}_{1}{x}_{1} + \cdots  + {c}_{r}{x}_{r} + {c}_{r + 1}{x}_{r + 1} + \cdots  + {c}_{n}{x}_{n} = \max$ ! (18.1a)

$$
\left. \begin{matrix} \vdots & & \vdots & & \vdots \\  {a}_{1,1}{x}_{1} + \cdots  + {a}_{1, r}{x}_{r} + {a}_{1, r + 1} + \cdots  + {a}_{1, n}{x}_{n} \leq  {b}_{1}, & & & & \\  \vdots & & \vdots & & \vdots \\  {a}_{s,1}{x}_{1} + \cdots  + {a}_{s, r}{x}_{r} + {a}_{s, r + 1}{x}_{r + 1} + \cdots  + {a}_{s, n}{x}_{n} \leq  {b}_{s}, & & & & \\  {a}_{s + 1,1}{x}_{1} + \cdots  + {a}_{s + 1, r}{x}_{r} + {a}_{s + 1, r + 1}{x}_{r + 1} + \cdots  + {a}_{s + 1, n}{x}_{n} = {b}_{s + 1, r}, & & & & \\  \vdots & & \vdots & & \vdots \\  {a}_{m,1}{x}_{1} + \cdots  + {a}_{m, r}{x}_{r} + {a}_{m, r + 1}{x}_{r + 1} + \cdots  + {a}_{m, n}{x}_{n} = {b}_{m, r}, & & & & \\  \vdots & & \vdots & & \\  {a}_{m,1}{x}_{1} + \cdots  + {a}_{m, r}{x}_{r} + {a}_{m, r + 1}{x}_{r + 1} + \cdots  + {a}_{m, n}{x}_{n} = {b}_{m, r}, & & & & \\  {x}_{1} \geq  0, & & \cdots & {x}_{m, r} \geq  0,\;{x}_{m + 1, r}{x}_{m + 2} = \cdots ,\;{x}_{m} \geq  0. &  \end{matrix}\right\}
$$

(18.1b)

采用更紧凑的向量记号, 上述问题可以写成

OF: $f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{c}}}^{{1}^{\mathrm{T}}}{\underline{\mathbf{x}}}^{1} + {\underline{\mathbf{c}}}^{{2}^{\mathrm{T}}}{\underline{\mathbf{x}}}^{2} = \max$ !(18.2a)

$$
\left. \begin{matrix} \text{ CT: } & {\mathbf{A}}_{11}{\underline{\mathbf{x}}}^{1} + {\mathbf{A}}_{12}{\underline{\mathbf{x}}}^{2} \leq  {\underline{\mathbf{b}}}^{1}, \\   & {\mathbf{A}}_{21}{\underline{\mathbf{x}}}^{1} + {\mathbf{A}}_{22}{\underline{\mathbf{x}}}^{2} = {\underline{\mathbf{b}}}^{2}, \\   & {\underline{\mathbf{x}}}^{1} \geq  \underline{\mathbf{0}},\;{\underline{\mathbf{x}}}^{2}\text{ 自由. } \end{matrix}\right\}   \tag{18.2b}
$$

这里使用如下记号:

$$
{\underline{\mathbf{c}}}^{1} = \left\lbrack  \begin{matrix} {c}_{1} \\  {c}_{2} \\  \vdots \\  {c}_{r} \end{matrix}\right\rbrack  ,\;{\underline{\mathbf{c}}}^{2} = \left\lbrack  \begin{matrix} {c}_{r + 1} \\  {c}_{r + 2} \\  \vdots \\  {c}_{n} \end{matrix}\right\rbrack  ,\;{\underline{\mathbf{x}}}^{1} = \left\lbrack  \begin{matrix} {x}_{1} \\  {x}_{2} \\  \vdots \\  {x}_{r} \end{matrix}\right\rbrack  ,\;{\underline{\mathbf{x}}}^{2} = \left\lbrack  \begin{matrix} {x}_{r + 1} \\  {x}_{r + 2} \\  \vdots \\  {x}_{n} \end{matrix}\right\rbrack  , \tag{18.2c}
$$

$$
{\mathbf{A}}_{11} = \left\lbrack  \begin{matrix} {a}_{1,1} & {a}_{1,2} & \cdots & {a}_{1, r} \\  {a}_{2,1} & {a}_{2,2} & \cdots & {a}_{2, r} \\  \vdots & \vdots & & \vdots \\  {a}_{s,1} & {a}_{s,2} & \cdots & {a}_{s, r} \end{matrix}\right\rbrack
$$

$$
{\mathbf{A}}_{12} = \left\lbrack  \begin{matrix} {a}_{1, r + 1} & {a}_{1, r + 2} & \cdots & {a}_{1, n} \\  {a}_{2, r + 1} & {a}_{2, r + 2} & \cdots & {a}_{2, n} \\  \vdots & \vdots & & \vdots \\  {a}_{s, r + 1} & {a}_{s, r + 2} & \cdots & {a}_{s, n} \end{matrix}\right\rbrack  , \tag{18.2d}
$$

$$
{\mathbf{A}}_{21} = \left\lbrack  \begin{matrix} {a}_{s + 1,1} & {a}_{s + 1,2} & \cdots & {a}_{s + 1, r} \\  {a}_{s + 2,1} & {a}_{s + 2,2} & \cdots & {a}_{s + 2, r} \\  \vdots & \vdots & & \vdots \\  {a}_{m,1} & {a}_{m,2} & \cdots & {a}_{m, r} \end{matrix}\right\rbrack
$$

$$
{\mathbf{A}}_{22} = \left\lbrack  \begin{matrix} {a}_{s + 1, r + 1} & {a}_{s + 1, r + 2} & \cdots & {a}_{s + 1, n} \\  {a}_{s + 2, r + 1} & {a}_{s + 2, r + 2} & \cdots & {a}_{s + 2, n} \\  \vdots & \vdots & & \vdots \\  {a}_{m, r + 1} & {a}_{m, r + 2} & \cdots & {a}_{m, n} \end{matrix}\right\rbrack  . \tag{18.2e}
$$

###### 3. 约束

对于不等号 “ $\geq$ ” 的约束,只要乘以(-1),就变成上面形式的约束.

###### 4. 极小问题

对于极小问题 $f\left( \underline{x}\right)  = \min$ !,通过目标函数乘以(-1),就变成等价的极大问题

$$
- f\left( \underline{\mathbf{x}}\right)  = \max ! \tag{18.3}
$$

###### 5. 整数规划

有时候某些变量仅限于取整数值. 这里我们不讨论这样的离散问题.

###### 6. 仅含非负变量和松弛变量情形的表达

在应用某些解法时, 仅仅考虑非负变量, 以及以等式形式给出的约束 (18.1b) 和 (18.2b).

$$
\text{OF:}\;f\left( \underline{\mathbf{x}}\right)  = {c}_{1}{x}_{1} + \cdots  + {c}_{r}{x}_{r} + {c}_{r + 1}{x}_{r + 1} + \cdots  + {c}_{n}{x}_{n} = \max \text{!} \tag{18.4a}
$$

$$
\left. \begin{matrix} {a}_{1,1}{x}_{1} + \cdots  + {a}_{1, n}{x}_{n} = {b}_{1}, \\  \vdots \\  {a}_{m,1}{x}_{1} + \cdots  + {a}_{m, n}{x}_{n} = {b}_{m}, \\  {x}_{1} \geq  0,\;\cdots ,\;{x}_{n} \geq  0. \end{matrix}\right\}   \tag{18.4b}
$$

每个自由变量 ${x}_{k}$ 必须分解成两个非负变量之差 ${x}_{k} = {x}_{k}^{1} - {x}_{k}^{2}$ . 通过增加非负变量, 不等式变成等式; 这些新增的变量称作松弛变量. 这就是说, 问题可以在 (18.4a, 18.4b) 给出的形式下进行研究,这里 $n$ 是增加了的变量数. 写成向量形式为

OF: $\;f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{c}}}^{\mathrm{T}}\underline{\mathbf{x}} = \max$ !(18.5a)

CT: $\;\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}},\;\underline{\mathbf{x}} \geq  \underline{\mathbf{0}}$ .(18.5b)

一般可以假定 $m \leq  n$ ,否则,方程组会包含线性相关或相互矛盾的方程.

###### 7. 可行集

所有满足 (18.2b) 的向量集合称作原问题的可行集. 如果自由变量做如上改写, 每个形如 “ $\leq$ ” 的不等式都改写成如 (18.4a) 和 (18.4b) 的等式,于是所有满足约束条件的非负向量 $\underline{x} \geq  \underline{0}$ 的向量的集合称作可行集 $M$ :

$$
M = \left\{  {\underline{\mathbf{x}} \in  {\mathbb{R}}^{n} : \underline{\mathbf{x}} \geq  \underline{\mathbf{0}},\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}}\right\}  . \tag{18.6a}
$$

如果点 ${\underline{x}}^{ * } \in  M$ 满足

$$
f\left( {\underline{\mathbf{x}}}^{ * }\right)  \geq  f\left( \underline{\mathbf{x}}\right) ,\;\forall \underline{\mathbf{x}} \in  M, \tag{18.6b}
$$

则 ${\underline{x}}^{ * }$ 称作线性规划问题的极大点或解点. 显然, ${\underline{x}}^{ * }$ 的非松弛变量分量构成原问题的解.

##### 18.1.1.2 例子和图解法

###### 1. 生产两个产品的例子

假定为了生产两个产品 ${E}_{1}$ 和 ${E}_{2}$ 需要原材料 ${R}_{1},{R}_{2}$ 和 ${R}_{3}$ . 表 18.1 表明为了生产 ${E}_{1}$ 和 ${E}_{2}$ 每一个单位产品需要多少单位的原材料,并且还给出了可利用的原材料总数.

表 18.1

<table><tr><td/><td>${R}_{1}/{E}_{i}$</td><td>${R}_{2}/{E}_{i}$</td><td>${R}_{3}/{E}_{i}$</td></tr><tr><td>${E}_{1}$</td><td>12</td><td>8</td><td>0</td></tr><tr><td>${E}_{2}$</td><td>6</td><td>12</td><td>10</td></tr><tr><td>总数</td><td>630</td><td>620</td><td>350</td></tr></table>

售出一个单位 ${E}_{1}$ 或 ${E}_{2}$ 产品分别可以获得 20 或 60 单位利润 (PR). 要求确定一个生产计划,使得在至少生产 10 个单位 ${E}_{1}$ 产品的前提下,获得最大利润.

现在设 ${x}_{1}$ 和 ${x}_{2}$ 表示生产产品 ${E}_{1}$ 和 ${E}_{2}$ 的单位数,问题就是

OF: $\;f\left( \underline{\mathbf{x}}\right)  = {20}{x}_{1} + {60}{x}_{2} = \max$ !

$$
{12}{x}_{1} + 6{x}_{2} \leq  {630},
$$

$$
8{x}_{1} + {12}{x}_{2} \leq  {620},
$$

$$
{10}{x}_{2} \leq  {350},
$$

$$
{x}_{1} \geq  {10}\text{.}
$$

引入松弛变量 ${x}_{3},{x}_{4},{x}_{5},{x}_{6}$ ,得到

$$
\text{OF:}f\left( \underline{\mathbf{x}}\right)  = {20}{x}_{1} + {60}{x}_{2} + 0 \cdot  {x}_{3} + 0 \cdot  {x}_{4} + 0 \cdot  {x}_{5} + 0 \cdot  {x}_{6} = \max \text{!}
$$

CT:

$$
{12}{x}_{1} + 6{x}_{2} + {x}_{3}\; = {630},
$$

$$
8{x}_{1} + {12}{x}_{2} + {x}_{4} = {620},
$$

$$
{10}{x}_{2}\; + {x}_{5}\; = {350},
$$

$$
- {x}_{1}\; + {x}_{6} =  - {10}.
$$

###### 2. 线性规划问题的性质

基于这个例子, 可以用图表示法来说明线性规划问题的某些性质. 这里不考虑松弛变量, 仅使用原始变量.

a) 直线 ${a}_{1}{x}_{1} + {a}_{2}{x}_{2} = b$ 把 ${x}_{1},{x}_{2}$ 平面分成两个半平面. 满足不等式 ${a}_{1}{x}_{1} +$ ${a}_{2}{x}_{2} \leq  b$ 的点 $\left( {{x}_{1},{x}_{2}}\right)$ 在其中的一个半平面中. 在笛卡儿坐标下,可以通过直线作出这个点集的图表示. 箭头表示包含该不等式解的半平面. 可行解集 $M$ ,即满足所有不等式的点集是这些半平面的交 (图 18.1). 在这个例子中, $M$ 的点构成一多边形区域. $M$ 无界或为空集都是有可能的. 如果有多于两条边界直线通过这个多边形的一个顶点, 则此顶点就称作退化的 (图 18.2).

![01936af3-1230-7a0e-9a4a-8542777881ce_3_657_1370_329_253_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_3_657_1370_329_253_0.jpg)

图 18.1

![01936af3-1230-7a0e-9a4a-8542777881ce_3_478_1674_683_216_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_3_478_1674_683_216_0.jpg)

图 18.2

b) ${x}_{1},{x}_{2}$ 平面中满足等式 $f\left( x\right)  = {20}{x}_{1} + {60}{x}_{2} = {c}_{0}$ 的每个点都在一条直线上,即与值 ${c}_{0}$ 相关的水平线上. 选择不同的 ${c}_{0}$ ,就得到一族平行的直线,在其每一条直线上, 目标函数的值是常数. 几何上, 规划问题的解应该是这样一些点, 它们属于可行集 $M$ ,也位于水平线 ${20}{x}_{1} + {60}{x}_{2} = {c}_{0},{c}_{0}$ 为最大值. 在这个例子中,解点是 $\left( {{x}_{1},{x}_{2}}\right)  = \left( {{25},{35}}\right)$ ,位于直线 ${20}{x}_{1} + {60}{x}_{2} = {2600}$ . 水平线示于图 18.3 中,这里箭头指向目标函数值增加的方向.

![01936af3-1230-7a0e-9a4a-8542777881ce_4_538_745_565_437_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_4_538_745_565_437_0.jpg)

图 18.3

显然,如果可行集 $M$ 有界,那么至少有一个顶点使得目标函数取到最大值. 如果可行集 $M$ 无界,则有可能目标函数也无界.

#### 18.1.2 线性规划基本概念、规范形

现在考虑线性规划问题(18.5a,18.5b),相应的可行集为 $M$ .

##### 18.1.2.1 极端点和基

###### 1. 极端点的定义

点 $\underline{x} \in  M$ 称作 $M$ 的极端点或顶点,是指对于所有 ${\underline{x}}_{1},{\underline{x}}_{2} \in  M,{\underline{x}}_{1} \neq  {\underline{x}}_{2}$ ,有

$$
\underline{\mathbf{x}} \neq  \lambda {\underline{\mathbf{x}}}_{1} + \left( {1 - \lambda }\right) {\underline{\mathbf{x}}}_{2},\;0 < \lambda  < 1, \tag{18.7}
$$

即 $\underline{x}$ 不在连接 $M$ 任意两不同点的线段的中间.

###### 2. 关于极端点的定理

如果矩阵 $\mathbf{A}$ 中与 $\underline{\mathbf{x}} \in  M$ 的正分量有关的那些列向量是线性无关的,则点 $\underline{\mathbf{x}}$ 是 $M$ 的极端点.

如果 $\mathbf{A}$ 的秩是 $m$ ,那么 $\mathbf{A}$ 中线性无关列的最大数是 $m$ . 因此一个极端点至多拥有 $m$ 个正分量,其分量等于零的数目至少是 $n - m$ 个. 在通常情形下,正好有 $m$ 个正分量. 如果正分量数小于 $m$ ,则就称其为退化极端点.

###### 3. 基

对于每一个极端点,可以选定矩阵 $\mathbf{A}$ 的 $m$ 个线性无关的列向量,这些列对应于其正分量. 这一组线性无关列向量称作该极端点的基. 通常, 每一个极端点恰好有一个基. 然而,退化的极端点就可能选定几个基. 从 $\mathbf{A}$ 的 $n$ 列中选择 $m$ 个线性无关向量,至多有 $\left( \begin{matrix} n \\  m \end{matrix}\right)$ 种可能性. 因此,不同基的数目,从而不同极端点的数目是 $\left( \begin{matrix} n \\  m \end{matrix}\right)$ . 如果 $M$ 非空,则 $M$ 至少有一个极端点.

III: $f\left( \underline{\mathbf{x}}\right)  = 2{x}_{1} + 3{x}_{2} + 4{x}_{3} = \max$ !

CT: $\;{x}_{1} + {x}_{2} + {x}_{3} \geq  1$ ,

$$
{x}_{2} \leq  2 \tag{18.8}
$$

$$
- {x}_{1}\; + 2{x}_{3} \leq  2,
$$

$$
2{x}_{1} - 3{x}_{2} + 2{x}_{3} \leq  2.
$$

由约束条件确定的可行集示于图 18.4. 引入松弛变量 ${x}_{4},{x}_{5},{x}_{6},{x}_{7}$ 后得到

$$
\text{CT:}\;{x}_{1} + {x}_{2} + {x}_{3} - {x}_{4}\; = 1\text{,}
$$

$$
{x}_{2}\; + {x}_{5}\; = 2,
$$

$$
- {x}_{1}\; + 2{x}_{3}\; + {x}_{6}\; = 2,
$$

$$
2{x}_{1} - 3{x}_{2} + 2{x}_{3}\; + {x}_{7} = 2.
$$

多面体的极端点 ${P}_{2} = \left( {0,1,0}\right)$ 对应于扩展系统的点 $\left( {{x}_{1},{x}_{2},{x}_{3},{x}_{4},{x}_{5},{x}_{6},{x}_{7}}\right)  =$ $\left( {0,1,0,0,1,2,5}\right) .A$ 的2,5,6,7列构成相应的基. 退化的极端点 ${P}_{1}$ 对应于 (1,0,0,0,2,3,0). 这一极端点的基包含1,5,6列,以及2,4或 7 列中的一列.

![01936af3-1230-7a0e-9a4a-8542777881ce_5_544_1445_555_428_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_5_544_1445_555_428_0.jpg)

图 18.4

注 这里第一个不等式带不等号 “ $\geq$ ”,从而 ${x}_{4}$ 前不是加号而是减号. 常常将带负号和相应 ${b}_{i} > 0$ 的这种附加变量称作剩余变量,而非松弛变量. 如在第 1189 页 18.1.3.3 所见, 剩余变量的出现要在求解过程中倍加小心.

###### 4. 目标函数取极大值的极端点

定理 如果 $M$ 非空,并且目标函数 $f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{c}}}^{\mathrm{T}}\underline{\mathbf{x}}$ 在 $M$ 上有界,则 $M$ 至少有一个极端点使得目标函数取极大值.

于是线性规划问题的求解就是至少确定一个极端点使得目标函数在其上达到极大值. 通常在实际问题中, 极端点的数目是非常大的, 从而需要有一种方法能够在合理的时间内找到答案. 这样的方法就是单纯形法, 也称作单纯形算法或单纯形程序.

##### 18.1.2.2 线性规划问题的规范形

###### 1. 规范形和基本解

线性规划问题 (18.4a, 18.4b) 总能通过适当的变量重新排序转换成如下形式:

OF : $f\left( \underline{\mathbf{x}}\right)  = {c}_{1}{x}_{1} + \cdots  + {c}_{n - m}{x}_{n - m} + {c}_{0} = \max$ !(18.9a)

CT: ${a}_{1,1}{x}_{1} + \cdots  + {a}_{1, n - m}{x}_{n - m} + {x}_{n - m + 1}\; = {b}_{1}$ ,

$$
\text{注 2 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. ... ..} \tag{18.9b}
$$

$$
{a}_{m,1}{x}_{1} + \cdots  + {a}_{m, n - m}{x}_{n - m}\; + {x}_{n} = {b}_{m},
$$

$$
{x}_{1},\cdots ,{x}_{n - m},{x}_{n - m + 1},\cdots ,{x}_{n} \geq  0.
$$

系数矩阵的最后 $m$ 列显然是线性无关的,从而形成一个基. 基本解 $\left( {{x}_{1},{x}_{2},\cdots }\right.$ , $\left. {{x}_{n - m},{x}_{n - m + 1},\cdots ,{x}_{n}}\right)  = \left( {0,\cdots ,0,{b}_{1},\cdots ,{b}_{m}}\right)$ 可以直接从该方程组确定,但如果 $\underline{b} \geq  \underline{0}$ 不成立,则它不是可行解.

如果 $\underline{b} \geq  \underline{0}$ ,则(18.9a,18.9b)称作线性规划问题的规范形或标准形. 在这种情形下,基本解也是可行解,即 $\underline{\mathbf{x}} \geq  \underline{\mathbf{0}}$ ,并且是 $M$ 的极端点. 变量 ${x}_{1},\cdots ,{x}_{n - m}$ 称作非基变量,而 ${x}_{n - m + 1},\cdots ,{x}_{n}$ 称作基变量. 目标函数在该极端点上取值 ${c}_{0}$ ,因为非基变量等于零.

###### 2. 规范形的确定

如果 $M$ 的极端点是已知的,则线性规划问题(18.5a,18.5b)的规范形可以按如下方式得到. 从 $\mathbf{A}$ 的列中选择对应于该极端点的一个基. 通常,通过极端点的正分量可以确定这些列. 假定基变量组成向量 ${\underline{\mathbf{x}}}_{B}$ ,而非基变量组成 ${\underline{\mathbf{x}}}_{N}$ . 与该基对应的列构成基矩阵 ${\mathbf{A}}_{B}$ ,其余列构成矩阵 ${\mathbf{A}}_{N}$ . 于是

$$
\mathbf{A}\underline{\mathbf{x}} = {\mathbf{A}}_{N}{\underline{\mathbf{x}}}_{N} + {\mathbf{A}}_{B}{\underline{\mathbf{x}}}_{B} = \underline{\mathbf{b}}. \tag{18.10}
$$

矩阵 ${\mathbf{A}}_{B}$ 是非奇异的,其逆 ${\mathbf{A}}_{B}^{-1}$ 即所谓的基逆. 用 ${\mathbf{A}}_{B}^{-1}$ 乘 (18.10),并根据非基变量适当调整目标函数, 就得到线性规划问题的标准形:

OF: $f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{c}}}_{N}^{\mathrm{T}}{\underline{\mathbf{x}}}_{N} + {c}_{0}$ ,(18.11a)

CT: $\;{\mathbf{A}}_{B}^{-1}{\mathbf{A}}_{N}{\underline{\mathbf{x}}}_{N} + {\underline{\mathbf{x}}}_{B} = {\mathbf{A}}_{B}^{-1}\underline{\mathbf{b}},\;{\underline{\mathbf{x}}}_{N} \geq  \underline{\mathbf{0}},\;{\underline{\mathbf{x}}}_{B} \geq  \underline{\mathbf{0}}$ .(18.11b)

注 如果原始系统 (18.1b) 仅有 “ $\leq$ ” 类约束,并且同时 $\underline{b} \geq  \underline{0}$ ,那么扩展系统 (18.4b) 没有剩余变量 (参见第 1183 页 18.1.2.1). 在这种情形下, 立即可知规范形. 选择所有松弛变量作为基变量 ${\underline{\mathbf{x}}}_{B}$ ,结果就是 ${\mathbf{A}}_{B} = \mathbf{I}$ ,而 ${\underline{\mathbf{x}}}_{B} = \underline{\mathbf{b}}$ ,且 ${\underline{\mathbf{x}}}_{N} = \underline{\mathbf{0}}$ 是可行极端点.

$\blacksquare$ 在上面的例子中, $\underline{x} = \left( {0,1,0,0,1,2,5}\right)$ 是一个极端点. 因此,

$$
{\mathbf{A}}_{B} = \left( \begin{matrix} 1 & 0 & 0 & 0 \\  1 & 1 & 0 & 0 \\  0 & 0 & 1 & 0 \\   - 3 & 0 & 0 & 1 \end{matrix}\right) ,\;{\mathbf{A}}_{B}^{-1} = \left( \begin{matrix} 1 & 0 & 0 & 0 \\   - 1 & 1 & 0 & 0 \\  0 & 0 & 1 & 0 \\  3 & 0 & 0 & 1 \end{matrix}\right) ,\;{\mathbf{A}}_{N} = \left( \begin{matrix} 1 & 1 &  - 1 \\  0 & 0 & 0 \\   - 1 & 2 & 0 \\  2 & 2 & 0 \\  {x}_{1} & {x}_{3} & {x}_{4} \end{matrix}\right) ,
$$

(18.12a)

$$
{\mathbf{A}}_{B}^{-1}{\mathbf{A}}_{N} = \left( \begin{matrix} 1 & 1 &  - 1 \\   - 1 &  - 1 & 1 \\   - 1 & 2 & 0 \\  5 & 5 &  - 3 \\  {x}_{1} & {x}_{3} & {x}_{4} \end{matrix}\right) ,\;{\mathbf{A}}_{B}^{-1}\mathbf{b} = \left( \begin{matrix} 1 \\  1 \\  2 \\  5 \end{matrix}\right) . \tag{18.12b}
$$

$$
\left. \begin{aligned} {x}_{1} + {x}_{2} + {x}_{3} - {x}_{4} & & &  = 1, \\   - {x}_{1} - {x}_{3} + {x}_{4} + {x}_{5} & & &  = 1, \\   - {x}_{1} + 2{x}_{3} + {x}_{6} & &  = 2, & \\  5{x}_{1} + 5{x}_{3} - 3{x}_{4} + {x}_{7} & &  = 5. &  \end{aligned}\right\}   \tag{18.13}
$$

从 $f\left( \underline{\mathbf{x}}\right)  = 2{x}_{1} + 3{x}_{2} + 4{x}_{3}$ ,减去第一个约束的 3 倍,得到变换后的目标函数为

$$
f\left( \underline{\mathbf{x}}\right)  =  - {x}_{1} + {x}_{3} + 3{x}_{4} + 3. \tag{18.14}
$$

#### 18.1.3 单纯形法

##### 18.1.3.1 单纯形表

单纯形法用于产生可行集的一列极端点, 其对应的目标函数值不断增加. 为了从给定的一个极端点找出一个新的极端点, 我们从对应于给定极端点的规范形出发, 逐步到达对应于新的极端点的规范形. 为了有一个清晰的排列, 以及比较容易理解相应数字的含义, 我们将规范形 (18.9a, 18.9b) 重新表示成单纯形表 (表 18.2(a), 表 18.2(b)).

表中的第 $k$ 行对应于约束

$$
{x}_{n - m + k} + {a}_{k,1}{x}_{1} + \cdots  + {a}_{k, n - m}{x}_{n - m} = {b}_{k}. \tag{18.15a}
$$

表 18.2(b) 或者更简洁地写作

表 18.2(a)

<table><tr><td/><td>${x}_{1}$</td><td>...</td><td>${x}_{n - m}$</td><td/></tr><tr><td>${x}_{n - m + 1}$</td><td>${a}_{1,1}$</td><td>...</td><td>${a}_{1, n - m}$</td><td>${b}_{1}$</td></tr><tr><td/><td>$\vdots$</td><td/><td>$\vdots$</td><td/></tr><tr><td>${x}_{n}$</td><td>${a}_{m,1}$</td><td>...</td><td>${a}_{m, n - m}$</td><td>${b}_{m}$</td></tr><tr><td/><td>${c}_{1}$</td><td>...</td><td>${c}_{n - m}$</td><td>$- {c}_{0}$</td></tr></table>

<table><tr><td/><td/><td/></tr><tr><td/><td>${\underline{\mathbf{A}}}_{N}$</td><td/></tr><tr><td/><td/><td>$- {c}_{0}$</td></tr></table>

目标函数是

$$
{c}_{1}{x}_{1} + \cdots  + {c}_{n - m}{x}_{n - m} = f\left( \underline{\mathbf{x}}\right)  - {c}_{0}. \tag{18.15b}
$$

从这个单纯形表,就能找出极端点 $\left( {{\underline{x}}_{N},{\underline{x}}_{B}}\right)  = \left( {\underline{0},\underline{b}}\right)$ . 目标函数在这个极端点上的值是 $f\left( \underline{\mathbf{x}}\right)  = {c}_{0}$ . 把 $- {c}_{0}$ 放到表的右下端有利于进行单纯形方法的计算. 在每一个表中总能找出如下三种情形中的一种:

a) ${c}_{j} \leq  0, j = 1,\cdots , n - m$ : 这样的表是最优的. 点 $\left( {{\underline{\mathbf{x}}}_{N},{\underline{\mathbf{x}}}_{B}}\right)  = \left( {\underline{\mathbf{0}},\underline{\mathbf{b}}}\right)$ 是极大点. 如果所有 ${c}_{j}$ 是正的,那么这个顶点是唯一的极大点.

b) 至少有一个 $j$ 使得 ${c}_{j} > 0$ ,并且 ${a}_{ij} \leq  0, i = 1,\cdots , m$ : 线性规划问题没有解,因为目标函数在可行集上无界; 随着 ${x}_{j}$ 的增加,它会无穷增加.

c) 对于每个使得 ${c}_{j} > 0$ 的 $j$ ,至少有一个 $i$ 使得 ${a}_{ij} > 0$ : 有可能从极端点 $\underline{x}$ 移动到邻近的极端点 $\underline{x}$ 时 $f\left( \underline{x}\right)  \geq  f\left( \underline{x}\right)$ . 在非退化极端点 $\underline{x}$ 的情形下, “>” 号总是成立的.

##### 18.1.3.2 过渡到新的单纯形表

###### 1. 非退化情形

如果一个表不是上述最后的情形 (情形 c), 那么新的表就按如下方式确定 (表 18.3). 基变量 ${x}_{p}$ 和非基变量 ${x}_{q}$ 之间通过下列计算进行转换:

a) ${\widetilde{a}}_{pq} = \frac{1}{{a}_{pq}}$ .(18.16a)

b) ${\widetilde{a}}_{pj} = {a}_{pj} \cdot  {\widetilde{a}}_{pq},\;j \neq  q,\;{\widetilde{b}}_{p} = {b}_{p} \cdot  {\widetilde{a}}_{pq}$ .(18.16b)

c) ${\widetilde{a}}_{iq} =  - {a}_{iq} \cdot  {\widetilde{a}}_{pq},\;i \neq  p,\;{\widetilde{c}}_{q} =  - {c}_{q} \cdot  {\widetilde{a}}_{pq}$ .(18.16c)

d) ${\widetilde{a}}_{ij} = {a}_{ij} + {a}_{pj} \cdot  {\widetilde{a}}_{iq},\;i \neq  p,\;j \neq  q$ ,

${\widetilde{b}}_{i} = {b}_{i} + {b}_{p} \cdot  {\widetilde{a}}_{iq}, i \neq  p,$

${\widetilde{c}}_{j} = {c}_{j} + {a}_{pj} \cdot  {\widetilde{c}}_{q},\;j \neq  q,\; - {\widetilde{c}}_{0} =  - {c}_{0} + {b}_{p} \cdot  {\widetilde{c}}_{q}.$ (18.16d)

表 18.3

<table><tr><td/><td>${\underline{\mathbf{x}}}_{N}$</td><td/></tr><tr><td> <img src="https://cdn.noedgeai.com/01936af3-1230-7a0e-9a4a-8542777881ce_8.jpg?x=731&y=1770&w=40&h=27"/> </td><td> <img src="https://cdn.noedgeai.com/01936af3-1230-7a0e-9a4a-8542777881ce_8.jpg?x=796&y=1766&w=46&h=29"/> </td><td> <img src="https://cdn.noedgeai.com/01936af3-1230-7a0e-9a4a-8542777881ce_8.jpg?x=883&y=1770&w=23&h=26"/> </td></tr><tr><td/><td> <img src="https://cdn.noedgeai.com/01936af3-1230-7a0e-9a4a-8542777881ce_8.jpg?x=811&y=1803&w=21&h=31"/> </td><td>$- {c}_{0}$</td></tr></table>

元 ${a}_{pq}$ 称作主元,第 $p$ 行为主行,而第 $q$ 列为主列. 为了选择主元,需要考虑如下两个要求:

a) 应该有 ${\widetilde{c}}_{0} \geq  {c}_{0}$ ;

b) 新的表也必须对应于一个可行解,即必须有 $\widetilde{\underline{b}} \geq  \underline{0}$ .

于是 $\left( {{\underline{\widetilde{\mathbf{x}}}}_{N},{\underline{\widetilde{\mathbf{x}}}}_{B}}\right)  = \left( {\underline{\mathbf{0}},\underline{\widetilde{b}}}\right)$ 是一个新的极端点,在此极端点上目标函数取值 $f\left( \underline{\widetilde{\mathbf{x}}}\right)  =$ ${\widetilde{c}}_{0}$ 不小于以前的值. 如果主元按如下方式选择,则这些条件满足:

a) 为增加目标函数的值,可以选择对应于 ${c}_{q} > 0$ 的列作为主列;

b) 为得到可行解, 主行必须选择为

$$
\frac{{b}_{p}}{{a}_{pq}} = \mathop{\min }\limits_{\substack{{1 \leq  i \leq  m} \\  {{a}_{iq} > 0} }}\left\{  \frac{{b}_{i}}{{a}_{iq}}\right\}  . \tag{18.17}
$$

如果可行集的极端点不是退化的, 则单纯形法在有穷步之后终止 ((情形 a) 或 (情形 b)).

第 1183 页 18.1.2 中的规范形可以写成单纯形表 (表 18.4(a)). 这个表并不是最优的, 因为目标函数在第 3 列中有正系数. 把第 3 列选定为主列 (也可以考虑第 2 列). 对主列的每一正元计算商 ${a}_{i}/{a}_{iq}$ (实际上只有一个). 这些商示于最后一列之后. 最小商就确定主行.$1 : 1$ 6 : 3

表 18.4(a)

<table><tr><td/><td>${x}_{1}$</td><td>${x3}$</td><td>${x}_{4}$</td><td/></tr><tr><td>${x}_{2}$</td><td>1</td><td>1</td><td>-1</td><td>1</td></tr><tr><td>${x}_{5}$</td><td>-1</td><td>$- \underline{1}$</td><td/><td>1</td></tr><tr><td>${x}_{6}$</td><td>-1</td><td>2</td><td>0</td><td>2</td></tr><tr><td>${x}_{7}$</td><td>5</td><td>5</td><td>-3</td><td>5</td></tr><tr><td/><td>-1</td><td>1</td><td>3</td><td>-1</td></tr></table>

<table><tr><td/><td/><td>${x}_{1}$</td><td>${x}_{3}$</td><td>${x}_{5}$</td><td/></tr><tr><td/><td>${x}_{2}$</td><td>0</td><td>0</td><td>1</td><td>2</td></tr><tr><td/><td>${x}_{4}$</td><td>-1</td><td>-1</td><td>1</td><td>1</td></tr><tr><td/><td>${x}_{6}$</td><td>-1</td><td/><td>0</td><td>2</td></tr><tr><td/><td>${x}_{7}$</td><td>2</td><td>2</td><td>3</td><td>8</td></tr><tr><td/><td/><td>2</td><td>$\underline{4}$</td><td>-3</td><td>-6</td></tr></table>

表 18.4(b)$2 : 2$ $8 : 2$

表 18.4(c)

<table><tr><td/><td>${x}_{1}$</td><td>${x}_{6}$</td><td>${x}_{5}$</td><td/></tr><tr><td>${x}_{2}$</td><td>0</td><td>0</td><td>1</td><td>2</td></tr><tr><td>${x}_{4}$</td><td>3</td><td>$\frac{1}{2}$</td><td>1</td><td>2</td></tr><tr><td>${x}_{3}$</td><td>1 2</td><td>$\frac{1}{2}$</td><td>0</td><td>1</td></tr><tr><td>${x}_{7}$</td><td>$\underline{3}$</td><td>-1</td><td>$\underline{3}$</td><td>6</td></tr><tr><td/><td>$\underline{4}$</td><td>-2</td><td>-3</td><td>-10</td></tr></table>

表 18.4(d)

<table><tr><td/><td/><td>${x}_{7}$</td><td>${x}_{6}$</td><td>${x}_{5}$</td><td/></tr><tr><td/><td>${x}_{2}$</td><td/><td> <img src="https://cdn.noedgeai.com/01936af3-1230-7a0e-9a4a-8542777881ce_9.jpg?x=1057&y=1440&w=22&h=26"/> </td><td/><td/></tr><tr><td/><td>${x}_{4}$</td><td/><td/><td>$\frac{1}{2}$</td><td>5</td></tr><tr><td/><td>${x}_{3}$</td><td>$\frac{1}{6}$</td><td>$\frac{1}{3}$</td><td>$\frac{1}{2}$</td><td>2</td></tr><tr><td/><td>${x}_{1}$</td><td>$\frac{1}{3}$</td><td>$- \frac{1}{3}$</td><td> <img src="https://cdn.noedgeai.com/01936af3-1230-7a0e-9a4a-8542777881ce_9.jpg?x=1122&y=1606&w=22&h=29"/> </td><td>2</td></tr><tr><td/><td/><td>$- \frac{4}{3}$</td><td>$- \frac{2}{3}$</td><td>-7</td><td>-18</td></tr></table>

如果它不是唯一的,则对应于新表的极端点是退化的. 在实施(18.16a) $\sim  \left( {{18.16}\mathrm{\;d}}\right)$ 几个步骤之后,就得到表 18.4(b). 这个表确定极端点(0,2,0,1,0,2,8),对应于图 18.4 中的点 ${P}_{7}$ . 由于这个新表仍然不是最优的,将 ${x}_{3}$ 和 ${x}_{6}$ 互换 (表 18.4(c)). 第 3 个表中极端点对应于图 18.4 中的点 ${P}_{6}$ . 在作附加变换之后,得到最优表 (表 18.4(d)),其极大点为 ${\underline{x}}^{ * } = \left( {2,2,2,5,0,0,0}\right)$ ,对应于点 ${P}_{5}$ ,并且目标函数在这里取得最大值 $f\left( {\underline{x}}^{ * }\right)  = {18}$ .

###### 2. 退化情形

如果在单纯形表中无法唯一地选择下一个主元, 则表示新的表有退化极端点. 退化极端点在几何上可以解释为可行解凸多面体的重合顶点. 这样的顶点有几个基. 因此, 在这种情形下可能出现若干步后仍出不来新的顶点, 也可能得到前面已经出现的表格, 从而可能发生无限循环的情形.

在退化的极端点情形下,解决问题的一种可能的办法是对 ${b}_{i}$ 加上小扰动 ${\varepsilon }^{i}$ (选择适当的 ${\varepsilon }^{i} > 0$ ),使得扰动后的极端点不再退化. 如果用 ${\varepsilon }^{i} = 0$ 替换,则从扰动问题的解就可得到退化情形的解.

如果在这种非唯一确定情形下随机选择主列, 则在实际中就可能发生无限循环这种异常情形.

##### 18.1.3.3 初始单纯形表的确定

###### 1. 辅助规划、人工变量

如果在原始约束 (18.1b) 中有等式或带负 ${b}_{i}$ 的不等式,则从单纯形法找出可行解并不是容易的事情. 为此, 在这种情形下, 我们从辅助规划开始来生成一个可行解,并把它作为原始问题单纯形法的出发点. 系统 $\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}$ 的某些方程乘以(-1) 以便满足条件 $\underline{b} \geq  \underline{0}$ . 现在 $A\underline{x} = \underline{b}$ 中的 $\underline{b} \geq  \underline{0}$ ,其每一式的左端加上人工变量 ${y}_{k}\left( {k = 1,\cdots , m}\right)$ ,并考虑辅助规划问题:

$$
{\mathbf{{OF}}}^{ * } : \;g\left( {\underline{\mathbf{x}},\underline{\mathbf{y}}}\right)  =  - {y}_{1} - \cdots  - {y}_{m} = \max ! \tag{18.18a}
$$

$$
\left. \begin{matrix} {a}_{1,1}{x}_{1} + \cdots  + {a}_{1, n}{x}_{n} + {y}_{1} &  = {b}_{1}, & & \\  \vdots & \vdots &  \ddots  & \vdots \\  {a}_{m,1}{x}_{1} + \cdots  + {a}_{m, n}{x}_{n} + & & &  + {y}_{m} = {b}_{m}, \\  {x}_{1},\cdots ,{x}_{n} \geq  0;\;{y}_{1},\cdots ,{y}_{m} \geq  0. & & &  \end{matrix}\right\}   \tag{18.18b}
$$

在这个问题中,变量 ${y}_{1},\cdots ,{y}_{m}$ 是基变量,并且可以着手做第 1 张单纯形表 (表 18.5). 这个表的最后一行包含非基变量之和,这些和是新的辅助目标函数 ${\mathbf{{OF}}}^{ * }$ 的系数. 显然,总有 $g\left( {\underline{\mathbf{x}},\underline{\mathbf{y}}}\right)  \leq  0$ . 如果对于此辅助规划问题的某个极大点 $\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{y}}}^{ * }}\right)$ 有 $g\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{y}}}^{ * }}\right)  = 0$ ,则显然有 ${\underline{\mathbf{y}}}^{ * } = \underline{\mathbf{0}}$ ,从而 ${\underline{\mathbf{x}}}^{ * }$ 是 $\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}$ 的解. 如果 $g\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{y}}}^{ * }}\right)  < 0$ , 则 $\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}$ 无解.

表 18.5

<table><tr><td/><td>${x}_{1}$</td><td>...</td><td>${x}_{n}$</td><td/></tr><tr><td>${y}_{1}$</td><td>${a}_{1,1}$</td><td>...</td><td>${a}_{1, n}$</td><td>${b}_{1}$</td></tr><tr><td>$\vdots$</td><td>$\vdots$</td><td/><td>$\vdots$</td><td>$\vdots$</td></tr><tr><td>${y}_{m}$</td><td>${a}_{m,1}$</td><td>...</td><td>${a}_{m, n}$</td><td>${b}_{m}$</td></tr><tr><td>OF</td><td>${c}_{1}$</td><td>...</td><td>${c}_{m}$</td><td>0</td></tr><tr><td>$\mathbf{{OF}} *$</td><td/><td>...</td><td/><td>$\mathop{\sum }\limits_{{j = 1}}^{n}{b}_{j} =  - g\left( {\underline{\mathbf{0}},\underline{\mathbf{b}}}\right)$</td></tr></table>

###### 2. 辅助规划问题的解

我们的目的是从基中消除人工变量. 下面来准备一个表, 此表不光是为了辅助规划问题. 我们通过人工变量的列和辅助目标函数的行来完成初始表. 辅助目标函数现在包含与等式相关的行所对应的系数之和 (示于下面). 如果人工变量变成了一个非基变量,则其列可以忽略,因为它绝不会再次被选作基变量. 极大点 $\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{y}}}^{ * }}\right)$ 一旦被确定, 则要区分两种情形:

(1) $g\left( {{\underline{x}}^{ * },{\underline{y}}^{ * }}\right)  < 0$ : 系统 $A\underline{x} = \underline{b}$ 无解,线性规划问题没有任何可行解.

(2) $g\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{y}}}^{ * }}\right)  = 0$ : 如果基变量中没有人工变量,则这个表就是原问题的初始表. 否则, 通过单纯形法的附加步骤将基变量中所有人工变量消除.

引入人工变量可能会大大增加问题的规模. 并不是每一个方程都有必要引入人工变量. 如果在引入松弛变量和剩余变量 (参见第 1185 页 18.1.2.1,3. 中的注) 之前约束系统的形式是: ${\mathbf{A}}_{1}\underline{\mathbf{x}} \geq  {\underline{\mathbf{b}}}_{1},{\mathbf{A}}_{2}\underline{\mathbf{x}} = {\underline{\mathbf{b}}}_{2},{\mathbf{A}}_{3}\underline{\mathbf{x}} \leq  {\underline{\mathbf{b}}}_{3}$ ,其中 ${\underline{\mathbf{b}}}_{1},{\underline{\mathbf{b}}}_{2},{\underline{\mathbf{b}}}_{3} > \underline{\mathbf{0}}$ ,那么仅仅前两个系统需要引入人工变量, 至于第三个系统, 可以选松弛变量作为基变量. 在第 1184 页 18.1.2 的例子中, 仅第一个方程需要人工变量:

在 $g\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{y}}}^{ * }}\right)  = 0$ 之下,相应的表 (表 18.6(b)) 是最优的. 在略去第 2 列之后, 就得到原问题的第 1 张表.

<table><tr><td/><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>${x}_{1}$</td><td>${x}_{2}$</td><td>${x}_{3}$</td><td>${x}_{4}$</td><td/><td/></tr><tr><td>${y}_{1}$</td><td>1</td><td>$\underline{1}$</td><td>$\underline{1}$</td><td>-1</td><td>1</td><td>:</td></tr><tr><td>${x}_{5}$</td><td>0</td><td>1</td><td>0</td><td>0</td><td>2</td><td>:</td></tr><tr><td>${x}_{6}$</td><td>-1</td><td>0</td><td>2</td><td>0</td><td>2</td><td/></tr><tr><td>${x}_{7}$</td><td>2</td><td>-3</td><td>2</td><td>0</td><td>2</td><td/></tr><tr><td>$\mathbf{{OF}}$</td><td>2</td><td>$\underline{3}$</td><td>4</td><td>0</td><td>0</td><td/></tr><tr><td>OF*</td><td>1</td><td>1</td><td>1</td><td>-1</td><td>1</td><td/></tr></table>

表 18.6(a)$1 : 1$ $2 : 1$

表 18.6(b)

<table><tr><td/><td/><td/><td/><td/><td/></tr><tr><td/><td>${x}_{1}$</td><td>${y}_{1}$</td><td>${x}_{3}$</td><td>${x}_{4}$</td><td/></tr><tr><td>${x}_{2}$</td><td>1</td><td>1</td><td>1</td><td>-1</td><td>1</td></tr><tr><td>${x}_{5}$</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td></tr><tr><td>${x}_{6}$</td><td>-1</td><td>0</td><td>2</td><td>0</td><td>2</td></tr><tr><td>${x}_{7}$</td><td>5</td><td>3</td><td>5</td><td>-3</td><td>5</td></tr><tr><td>OF</td><td>-1</td><td>-3</td><td>1</td><td>3</td><td>-3</td></tr><tr><td>OF*</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td></tr></table>

##### 18.1.3.4 修正单纯形法

###### 1. 修正单纯形表

假定线性规划问题由如下规范形给出:

$$
\text{OF :}\;f\left( \mathbf{x}\right)  = {c}_{1}{x}_{1} + \cdots  + {c}_{n - m}{x}_{n - m} + {c}_{0} = \max \text{!} \tag{18.19a}
$$

$$
\begin{array}{l} \text{ T: }\;{\alpha }_{1,1}{x}_{1} + \cdots  + {\alpha }_{1, n - m}{x}_{n - m} + {x}_{n - m + 1}\; = {\beta }_{1}, \\  \end{array} \tag{18.19b}
$$

显然,系数向量 ${\underline{\mathbf{\alpha }}}_{n - m + i}\left( {i = 1,\cdots , m}\right)$ 是第 $i$ 个单位向量.

为了将其改变成另一个规范形, 从而达到另一个极端点, 只需用相应的基逆矩阵乘方程组 (18.19b). (注意如下事实: 如果 ${\mathbf{A}}_{B}$ 表示一新的基,则向量 $\underline{\mathbf{x}}$ 的坐标在新的基中可以表示成 ${\mathbf{A}}_{B}^{-1}\underline{\mathbf{x}}$ . 如果已知新的基逆矩阵,则从最初的表通过简单相乘就可以得到任意列和目标函数.) 单纯形法可以这样修改, 使得在每一步而不用通过新表就能确定基逆. 从每个表中只要计算为找出新的主元所需要的元就够了. 如果变量数远大于约束数 $\left( {n > {3m}}\right)$ ,那么修改单纯形法的计算量相当小,并有较好的精度. 修改单纯形表的一般形式示于表 18.7.

表 18.7

<table><tr><td/><td>${x}_{1}$</td><td>...</td><td>${x}_{n - m}$</td><td>${x}_{n - m + 1}$</td><td>...</td><td>${x}_{n}$</td><td/><td>${x}_{q}$</td></tr><tr><td>${x}_{1}^{B}$</td><td/><td/><td/><td>${a}_{1, n - m + 1}$</td><td>...</td><td>${a}_{1, n}$</td><td>${b}_{1}$</td><td>${r}_{1}$</td></tr><tr><td>$\vdots$</td><td/><td/><td/><td>$\vdots$</td><td/><td>$\vdots$</td><td>$\vdots$</td><td>$\vdots$</td></tr><tr><td>${x}_{m}^{B}$</td><td/><td/><td/><td>${a}_{m, n - m + 1}$</td><td>...</td><td>${a}_{m, n}$</td><td>${b}_{m}$</td><td>${r}_{m}$</td></tr><tr><td/><td>${c}_{1}$</td><td>...</td><td>${c}_{n - m}$</td><td>${c}_{n - m + 1}$</td><td>...</td><td>${c}_{n}$</td><td>$- {c}_{0}$</td><td>${c}_{q}$</td></tr></table>

表中的符号意义如下:

${x}_{1}^{B},\cdots ,{x}_{m}^{B}$ : 现时基变量 (如同在第一步中的 ${x}_{n - m + 1},\cdots ,{x}_{n}$ 一样);

${c}_{1},\cdots ,{c}_{n}$ : 目标函数的系数 (与基变量相关的系数为零);

${b}_{1},\cdots ,{b}_{m}$ : 现时规范形的右端;

${c}_{0}$ : 目标函数在极端点 $\left( {{x}_{1}^{B},\cdots ,{x}_{m}^{B}}\right)  = \left( {{b}_{1},\cdots ,{b}_{m}}\right)$ 的取值; ${\mathbf{A}}^{ * } = \left( \begin{matrix} {a}_{1, n - m + 1} & \cdots & {a}_{1, n} \\  \vdots & & \vdots \\  {a}_{m, n - m + 1} & \cdots & {a}_{m, n} \end{matrix}\right)$ : 现时基逆, ${\mathbf{A}}^{ * }$ 的列是对应现时规范形的 ${x}_{n - m + 1},\cdots ,{x}_{n}$ 的列; $\underline{r} = {\left( {r}_{1},\cdots ,{r}_{m}\right) }^{\mathrm{T}}$ : 现时主列.

###### 2. 修正单纯形的步骤

a) 当系数 ${c}_{j}\left( {j = 1,\cdots , n}\right)$ 中至少有一个是正的,则相应的单纯形表不是最优的. 当某个 ${c}_{q} > 0$ 时,选择相应的 $q$ 列为主列.

b) 用 ${\mathbf{A}}^{ * }$ 与原系数矩阵 (18.19b) 的第 $q$ 列相乘,计算出主列 $\underline{r}$ ,并将此新的向量作为表的最后一个列向量. 第 $k$ 个主行向量由类似于单纯形算法 (18.17) 中的方式确定.

c) 新表通过一系列转换步骤 (18.16a $\sim  {18.16}\mathrm{\;d}$ ) 算出,这里 ${a}_{iq}$ 形式上用 ${r}_{i}$ 代替, 并且标号限于 $n - m + 1 \leq  j \leq  n$ . 删除列 $\widetilde{\underline{r}},{x}_{q}$ 成为基变量. 对于 $j = 1,\cdots , n - m$ , 结果是 ${\widetilde{c}}_{j} = {c}_{j} + {\underline{\mathbf{\alpha }}}_{j}^{\mathrm{T}}\underline{\widetilde{\mathbf{c}}}$ ,其中 $\underline{\widetilde{\mathbf{c}}} = {\left( {\widetilde{c}}_{n - m + 1},\cdots ,{\widetilde{c}}_{n}\right) }^{\mathrm{T}}$ ,而 ${\mathbf{\alpha }}_{j}$ 是 (18.19b) 的系数矩阵的第 $j$ 列.

考虑第 1184 页 18.1.2 中例子的规范形. 我们希望把 ${x}_{4}$ 变成基. 相应的主列 $\underline{r} = {\underline{\alpha }}_{4}$ 放置到表的最后一列 (表 18.8(a))(初始时 ${\mathbf{A}}^{ * }$ 是单位矩阵).

对于 $j = 1,3,4$ ,我们得到 ${\widetilde{c}}_{j} = {c}_{j} - 3{\alpha }_{2j} : \left( {{c}_{1},{c}_{3},{c}_{4}}\right)  = \left( {2,4,0}\right)$ . 这样确定的极端点 $\underline{x} = \left( {0,2,0,1,0,2,8}\right)$ 对应于第 1184 页图 18.4 中的点 ${P}_{7}$ . 下一个主列可以选在 $j = 3 = q$ .

表 18.8(a)$1 : 1$

<table><tr><td/><td>${x}_{1}$</td><td>${x}_{3}$</td><td>${x}_{4}$</td><td>${x}_{2}$</td><td>${x}_{5}$</td><td>${x}_{6}$</td><td>${x}_{7}$</td><td/><td>${x}_{4}$</td><td/></tr><tr><td>${x}_{2}$</td><td/><td/><td/><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>-1</td><td/></tr><tr><td>${x}_{5}$</td><td/><td/><td/><td>$\underline{0}$</td><td>1</td><td>$\underline{0}$</td><td>$\underline{0}$</td><td>$\underline{1}$</td><td>$\underline{\underline{1}}$</td><td/></tr><tr><td>${x}_{6}$</td><td/><td/><td/><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>$\underline{0}$</td><td/></tr><tr><td>${x}_{7}$</td><td/><td/><td/><td>0</td><td>0</td><td>0</td><td>1</td><td>5</td><td>-3</td><td/></tr><tr><td/><td>-1</td><td>1</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-3</td><td>$\underline{3}$</td><td/></tr></table>

表 18.8(b)$2 : 2$

<table><tr><td/><td>${x}_{1}$</td><td>${x}_{3}$</td><td>${x}_{4}$</td><td>${x}_{2}$</td><td>${x}_{5}$</td><td>${x}_{6}$</td><td>${x}_{7}$</td><td/><td>${x}_{3}$</td><td/></tr><tr><td>${x}_{2}$</td><td/><td/><td/><td>1</td><td>1</td><td>0</td><td>0</td><td>2</td><td>$\underline{0}$</td><td/></tr><tr><td>${x}_{4}$</td><td/><td/><td/><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>-1</td><td/></tr><tr><td>${x}_{6}$</td><td/><td/><td/><td>$\underline{0}$</td><td>$\underline{0}$</td><td>$\underline{1}$</td><td>0</td><td>2</td><td>2</td><td>2</td></tr><tr><td>${x}_{7}$</td><td/><td/><td/><td>0</td><td>3</td><td>0</td><td>1</td><td>8</td><td>2</td><td>8</td></tr><tr><td/><td>2</td><td>$\underline{4}$</td><td>-3</td><td>0</td><td>-3</td><td>0</td><td>0</td><td>-6</td><td>$\underline{4}$</td><td/></tr></table>

向量 $\underline{r}$ 由

$$
\underline{\mathbf{r}} = \left( {{r}_{1},\cdots ,{r}_{m}}\right)  = {\mathbf{A}}^{ * }{\underline{\mathbf{\alpha }}}_{3} = \left( \begin{matrix} 1 & 1 & 0 & 0 \\  0 & 1 & 0 & 0 \\  0 & 0 & 1 & 0 \\  0 & 3 & 0 & 1 \end{matrix}\right) \left( \begin{matrix} 1 \\   - 1 \\  2 \\  5 \end{matrix}\right)  = \left( \begin{matrix} 0 \\   - 1 \\  2 \\  2 \end{matrix}\right)
$$

确定, 并将之放到第二个表 (表 18.8(b)) 的最后一列. 用类似于第 1187 页 18.1.3.2 中所示的方法继续做下去. 如果想回到原先的方法, 则非基变量所对应的初始列构成的矩阵必须乘以 ${\mathbf{A}}^{ * }$ ,并且只保留这些列.

##### 18.1.3.5 线性规划中的对偶性

###### 1. 对应

对于任意一个线性规划问题 (原始问题), 可以指定另一个线性规划问题 (对偶问题):对偶问题

原始问题

$$
\text{OF:}f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{c}}}_{1}^{\mathrm{T}}{\underline{\mathbf{x}}}_{1} + {\underline{\mathbf{c}}}_{2}^{\mathrm{T}}{\underline{\mathbf{x}}}_{2} = \max \text{!} \tag{18.20a}
$$

$$
\text{CT:}{\mathbf{A}}_{1,1}{\underline{\mathbf{x}}}_{1} + {\mathbf{A}}_{1,2}{\underline{\mathbf{x}}}_{2} \leq  {\underline{\mathbf{b}}}_{1}\text{,}
$$

$$
{\mathbf{A}}_{2,1}{\underline{\mathbf{x}}}_{1} + {\mathbf{A}}_{2,2}{\underline{\mathbf{x}}}_{2} = {\underline{\mathbf{b}}}_{2}, \tag{18.20b}
$$

${\underline{\mathbf{x}}}_{1} \geq  \underline{\mathbf{0}},\;{\underline{\mathbf{x}}}_{2}$ 自由.

对偶问题

$$
{\mathbf{{OF}}}^{ * } : g\left( \underline{\mathbf{u}}\right)  = {\underline{\mathbf{b}}}_{1}^{\mathrm{T}}{\underline{\mathbf{u}}}_{1} + {\underline{\mathbf{b}}}_{2}^{\mathrm{T}}{\underline{\mathbf{u}}}_{2} = \min ! \tag{18.21a}
$$

$$
{\mathbf{{CT}}}^{ * } : {\mathbf{A}}_{1,1}^{\mathrm{T}}{\underline{\mathbf{u}}}_{1} + {\mathbf{A}}_{2,1}^{\mathrm{T}}{\underline{\mathbf{u}}}_{2} \geq  {\underline{\mathbf{c}}}_{1},
$$

$$
{\mathbf{A}}_{1,2}^{\mathrm{T}}{\underline{\mathbf{u}}}_{1} + {\mathbf{A}}_{2,2}^{\mathrm{T}}{\underline{\mathbf{u}}}_{2} = {\underline{\mathbf{c}}}_{2}, \tag{18.21b}
$$

$$
{\underline{\mathbf{u}}}_{1} \geq  \underline{\mathbf{0}},\;{\underline{\mathbf{u}}}_{2}\text{自由.}
$$

一个问题的目标函数的系数构成另一个问题约束的右端向量. 每个自由变量对应于一个等式, 而带限制符号的变量则对应于另一个问题的一个不等式.

###### 2. 对偶性定理对偶性定理

a) 如果两个问题都有可行解,即 $M \neq  \varnothing ,{M}^{ * } \neq  \varnothing$ (这里 $M$ 和 ${M}^{ * }$ 分别表示原问题和对偶问题的可行集), 那么

$$
f\left( \underline{\mathbf{x}}\right)  \leq  g\left( \underline{\mathbf{u}}\right) ,\;\forall \underline{\mathbf{x}} \in  M,\;\underline{\mathbf{u}} \in  {M}^{ * }, \tag{18.22a}
$$

并且两个问题都有最优解.

b) 点 $\underline{x} \in  M$ 和 $\underline{u} \in  {M}^{ * }$ 是相应问题的最优解,当且仅当

$$
f\left( \underline{\mathbf{x}}\right)  = g\left( \underline{\mathbf{u}}\right) . \tag{18.22b}
$$

c) 如果 $f\left( \underline{x}\right)$ 在 $M$ 上没有上界,或 $g\left( \underline{u}\right)$ 在 ${M}^{ * }$ 上没有下界,那么 ${M}^{ * } = \varnothing$ 或 $M = \varnothing$ ,即对偶问题没有可行解.

d) 点 $\underline{x} \in  M$ 和 $\underline{u} \in  {M}^{ * }$ 是相应问题的最优点,当且仅当

$$
{\underline{\mathbf{u}}}_{1}^{\mathrm{T}}\left( {{\mathbf{A}}_{1,1}{\underline{\mathbf{x}}}_{1} + {\mathbf{A}}_{1,2}{\underline{\mathbf{x}}}_{2} - {\underline{\mathbf{b}}}_{1}}\right)  = 0\;\text{ 和 }\;{\underline{\mathbf{x}}}_{1}^{\mathrm{T}}\left( {{\mathbf{A}}_{1,1}^{\mathrm{T}}{\underline{\mathbf{u}}}_{1} + {\mathbf{A}}_{2,1}^{\mathrm{T}}{\underline{\mathbf{u}}}_{2} - {\underline{\mathbf{c}}}_{1}}\right)  = 0. \tag{18.22c}
$$

使用上面最后两个方程,从对偶问题的非降秩最优解 $\underline{u}$ ,通过求解如下线性方程组可以找到原问题的最优解 $\underline{x}$ :

$$
{\mathbf{A}}_{2,1}{\underline{\mathbf{x}}}_{1} + {\mathbf{A}}_{2,2}{\underline{\mathbf{x}}}_{2} - {\underline{\mathbf{b}}}_{2} = \underline{\mathbf{0}}, \tag{18.23a}
$$

$$
{\left( {\mathbf{A}}_{1,1}{\underline{\mathbf{x}}}_{1} + {\mathbf{A}}_{1,2}{\underline{\mathbf{x}}}_{2} - {\underline{\mathbf{b}}}_{1}\right) }_{i} = \underline{\mathbf{0}}\text{ 当 }{u}_{i} > 0, \tag{18.23b}
$$

$$
{x}_{i} = 0\text{ 当 }{\left( {\mathbf{A}}_{1,1}^{\mathrm{T}}{\underline{\mathbf{u}}}_{1} + {\mathbf{A}}_{2,1}^{\mathrm{T}}{\underline{\mathbf{u}}}_{2} - {\underline{\mathbf{c}}}_{1}\right) }_{i} \neq  0. \tag{18.23c}
$$

对偶问题也可以用单纯形法进行求解.

###### 3. 对偶问题的应用

在如下情形下, 借助对偶问题求解可能有某些优点:

a) 如果能简单地找出对偶问题的规范形, 则从原问题切换到对偶问题.

b) 如果原问题的约束数量相比变量数大得多, 则可使用修正单纯形法处理对偶问题.

考虑第 1184 页 18.1.2 中例子的原问题.

原问题

$$
\text{OF:}f\left( \underline{\mathbf{x}}\right)  = 2{x}_{1} + 3{x}_{2} + 4{x}_{3} = \max \text{!}
$$

$$
\text{CT:}\; - {x}_{1} - {x}_{2} - {x}_{3} \leq   - 1\text{,}
$$

$$
{x}_{2} \leq  2,
$$

$$
- {x}_{1}\; + 2{x}_{3} \leq  2,
$$

$$
2{x}_{1} - 3{x}_{2} + 2{x}_{3} \leq  2,
$$

$$
{x}_{1},{x}_{2},{x}_{3} \geq  0.
$$

对偶问题

$$
{\mathbf{{OF}}}^{ * } : g\left( \underline{\mathbf{u}}\right)  =  - {u}_{1} + 2{u}_{2} + 2{u}_{3} + 2{u}_{4} = \min !
$$

$$
\text{CT*:} - {u}_{1} - {u}_{3} + 2{u}_{4} \geq  2\text{,}
$$

$$
- {u}_{1} + {u}_{2}\; - 3{u}_{4} \geq  3,
$$

$$
- {u}_{1}\; + 2{u}_{3} + 2{u}_{4} \geq  4,
$$

$$
{u}_{1},{u}_{2},{u}_{3},{u}_{4} \geq  0.
$$

如果对偶问题是在引入松弛变量后采用单纯形法进行求解,则得到最优解 ${\underline{\mathbf{u}}}^{ * } =$ $\left( {0,7,2/3,4/3}\right)$ ,并且 $g\left( {\underline{\mathbf{u}}}^{ * }\right)  = {18}$ . 求解系统 ${\left( \mathbf{A}\underline{\mathbf{x}} - \underline{\mathbf{b}}\right) }_{i} = 0$ ,这里 ${u}_{i} > 0$ ,即 ${x}_{2} = 2, - {x}_{1} + 2{x}_{3} = 2,2{x}_{1} - 3{x}_{2} + 2{x}_{3} = 2$ ,得到原问题的解 ${\underline{x}}^{ * } = \left( {2,2,2}\right)$ ,$f\left( {\underline{x}}^{ * }\right)  = {18}.$

#### 18.1.4 特殊线性规划问题

##### 18.1.4.1 运输问题

###### 1. 建模

$m$ 个生产者 ${E}_{1},\cdots ,{E}_{m}$ 生产一种产品,各家生产的数量是 ${a}_{1},\cdots ,{a}_{m}$ ,产品需要运输到 $n$ 个消费者 ${V}_{1},\cdots ,{V}_{n}$ ,其需求分别是 ${b}_{1},\cdots ,{b}_{n}$ . 从生产者 ${E}_{i}$ 到消费者 ${V}_{j}$ 的单位运输成本是 ${c}_{ij}$ . 从 ${E}_{i}$ 到 ${V}_{j}$ 运输的产品数量是 ${x}_{ij}$ 件. 最优运输方案是使运输成本最小. 假定这个系统是平衡的, 即供给等于需求:

$$
\mathop{\sum }\limits_{{i = 1}}^{n}{a}_{i} = \mathop{\sum }\limits_{{j = 1}}^{n}{b}_{j} \tag{18.24}
$$

首先构建成本矩阵 $\mathbf{C}$ 和分布矩阵 $\mathbf{X}$ 如下:

$$
\mathbf{C} = \left( \begin{matrix} {c}_{1,1} & \cdots & {c}_{1, n} \\  \vdots & & \vdots \\  {c}_{m,1} & \cdots & {c}_{m, n} \end{matrix}\right) \begin{matrix} E : \\  {E}_{1} \\  \vdots \\  {E}_{m} \end{matrix} \tag{18.25a}
$$

$$
V : {V}_{1}\cdots {V}_{n}
$$

$$
\sum  :
$$

$$
\mathbf{X} = \left( \begin{matrix} {x}_{1,1} & \cdots & {x}_{1, n} \\  \vdots & & \vdots \\  {x}_{m,1} & \cdots & {x}_{m, n} \end{matrix}\right) \begin{matrix} {a}_{1} \\  \vdots \\  {a}_{m} \end{matrix} \tag{18.25b}
$$

$$
\sum  : \;{b}_{1}\;\cdots \;{b}_{n}
$$

如果条件 (18.24) 不满足, 则需区分两种情形:

a) 如果 $\sum {a}_{i} > \sum {b}_{j}$ ,则引入虚构消费者 ${V}_{n + 1}$ ,其需求为 ${b}_{n + 1} = \sum {a}_{i} - \sum {b}_{j}$ , 运输成本为 ${c}_{i, n + 1} = 0$ .

b) 如果 $\sum {a}_{i} < \sum {b}_{j}$ ,则引入虚构生产者 ${E}_{m + 1}$ ,其产能为 ${a}_{n + 1} = \sum {b}_{j} - \sum {a}_{i}$ , 运输成本为 ${c}_{m + 1, j} = 0$ .

为了确定最优方案, 应该求解如下规划问题:

$$
\text{OF:}f\left( \mathbf{X}\right)  = \mathop{\sum }\limits_{{i = 1}}^{m}\mathop{\sum }\limits_{{j = 1}}^{n}{c}_{ij}{x}_{ij} = \min \text{!} \tag{18.26a}
$$

$$
\text{CT:}\mathop{\sum }\limits_{{j = 1}}^{n}{x}_{ij} = {a}_{i}\;\left( {i = 1,\cdots , m}\right) ,
$$

$$
\mathop{\sum }\limits_{{i = 1}}^{m}{x}_{ij} = {b}_{j}\;\left( {j = 1,\cdots , n}\right) ,{x}_{ij} \geq  0. \tag{18.26b}
$$

该问题的极小出现在可行集的某个顶点. 在 $m + n$ 个原始约束中有 $m + n - 1$ 个线性无关的约束,从而在非退化情形下,解含有 $m + n - 1$ 个正分量 ${x}_{ij}$ . 为了确定最优解, 使用下列所谓的运输算法.

###### 2. 基本可行解的确定

使用西北角规则可以确定初始基本可行解:

a) 选择 ${x}_{11} = \min \left\{  {{a}_{1},{b}_{1}}\right\}$ .(18.27a)

b) 如果 ${a}_{1} > {b}_{1}$ ,则删去 $\mathbf{X}$ 的第 1 列.(18.27b)

如果 ${a}_{1} < {b}_{1}$ ,则删去 $\mathbf{X}$ 的第 1 行.(18.27c)

如果 ${a}_{1} = {b}_{1}$ ,则或者删去 $\mathbf{X}$ 的第 1 行,或者删去 $\mathbf{X}$ 剩余的第 1 列.(18.27d)

如果只有一行而有几列, 则删去一列. 同样的的操作也适用于行.

c) ${a}_{1}$ 用 ${a}_{1} - {x}_{11}$ 替代, ${b}_{1}$ 用 ${b}_{1} - {x}_{11}$ 替代,并且对缩减了的分布矩阵 $\mathbf{X}$ 的左上角顶重复此操作.

在 a) 中得到的变量是基变量, 所有其余变量都是取零值的非基变量.

$$
\mathbf{X} = \left( \begin{array}{llll} {x}_{1,1} & {x}_{1,2} & {x}_{1,3} & {x}_{1,4} \\  {x}_{2,1} & {x}_{2,2} & {x}_{2,3} & {x}_{2,4} \\  {x}_{3,1} & {x}_{3,2} & {x}_{3,3} & {x}_{3,4} \end{array}\right) \begin{array}{l} \sum  : \\  {a}_{1} = 9 \\  {a}_{2} = {10} \\  {a}_{3} = 3 \end{array}
$$

$$
\sum  : \;{b}_{1} = 4\;{b}_{2} = 6\;{b}_{3} = 5\;{b}_{4} = 7
$$

![01936af3-1230-7a0e-9a4a-8542777881ce_17_616_638_407_195_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_17_616_638_407_195_0.jpg)

使用西北角规则确定初始极端点:

第 1 步 第 2 步

还有别的考虑运输成本方法也可以找出初始基本解 (例如见 [18.15] 中的沃格尔 (Vogel) 近似法), 并且通常会得到更好的初始解.

###### 3. 采用单纯形法求解运输问题的解

如果采用通常的单纯形法求解运输问题, 则会产生含有大量零元的十分庞大的表 $\left( {\left( {m + n}\right)  \times  \left( {m \cdot  n}\right) }\right)$ : 在每一列中仅有两个元等于 1. 于是就需要构造简化表,下面的步骤对应于单纯形步骤中仅涉及理论单纯形表的非零元. 成本数据矩阵包含目标函数的系数. 基变量在迭代过程中变换为非基变量, 而成本矩阵相应的元在每一步中都需要修改. 下面通过一个例子说明此方法.

a) 从成本矩阵 $\mathbf{C}$ 确定修改的成本矩阵 $\widetilde{\mathbf{C}}$ :

$$
{\widetilde{c}}_{ij} = {c}_{ij}{p}_{i} + {q}_{j}\;\left( {i = 1,\cdots , m;\;j = 1,\cdots , n}\right) , \tag{18.28a}
$$

这里要求

${\widetilde{c}}_{ij} = 0$ ,如果(i, j)对应的 ${x}_{ij}$ 是现时基变量.(18.28b)

$C$ 中对应于基变量的元打上标记,并以 ${p}_{1} = 0$ 代入. 其余量 ${p}_{i}$ 和 ${q}_{j}$ 也称作潜在乘子或单纯形乘子,这些量的确定应该使得 ${p}_{i},{q}_{j}$ 和带标记的成本 ${c}_{ij}$ 之和为零:

$$
\mathbf{C} = \left( \begin{matrix} \left( 5\right) & \left( 3\right) & 2 & 7 \\  8 & \left( 2\right) & \left( 1\right) & \left( 1\right) \\  0 & 2 & 6 & \left( 3\right)  \end{matrix}\right) \;\begin{array}{l} {p}_{1} = 0 \\  {p}_{2} = 1 \\  {p}_{3} =  - 1 \end{array}
$$

$$
{q}_{1} =  - 5\;{q}_{2} =  - 3\;{q}_{3} =  - 2\;{q}_{4} =  - 2
$$

$$
\Rightarrow  \widetilde{\mathbf{C}} = \left( \begin{matrix} 0 & 0 & 0 & 5 \\  4 & 0 & 0 & 0 \\  3 &  - 2 & 3 & 0 \end{matrix}\right) . \tag{18.28c}
$$

b) 数值

$$
{\widetilde{c}}_{pq} = \mathop{\min }\limits_{{i, j}}\left\{  {\widetilde{c}}_{ij}\right\}   \tag{18.28d}
$$

必须确定. 如果 ${\widetilde{c}}_{pq} > 0$ ,则分布 $\mathbf{X}$ 是最优的; 否则,就选 ${x}_{pq}$ 作为一新的基变量. 在我们的例子中, ${\widetilde{c}}_{pq} = {\widetilde{c}}_{32} =  - 2$ .

c) 在 $\widetilde{\mathbf{C}}$ 中,给 ${\widetilde{c}}_{pq}$ 以及与基变量相关的成本项打上标记,如果 $\widetilde{\mathbf{C}}$ 包含至多有一个标记元的行或列, 则删去这些行或列. 对剩余矩阵重复这一操作, 直到不再需要进一步的删除操作.

$$
\widetilde{\mathbf{C}} = \left( \begin{matrix} \left( 0\right) & \left( 0\right) & 0 & 5 \\  4 & \left( 0\right) & \left( 0\right) & \left( 0\right) \\  3 & \left( {-2}\right) & 3 & \left( 0\right)  \end{matrix}\right) . \tag{18.28e}
$$

d) 与剩下的带标记的元 ${\widetilde{c}}_{ij}$ 相关的元 ${x}_{ij}$ 形成一个回路. 新的基变量 ${\widetilde{x}}_{pq}$ 被调整到正值 $\delta$ . 与带标记元相关的其余变量 ${\widetilde{c}}_{ij}$ 由约束确定. 在实践中,从回路第二元减去 $\delta$ ,或将 $\delta$ 加到回路第二元. 为了保持这些变量非负,量值 $\delta$ 必须选为

$$
\delta  = {x}_{rs} = \min \left\{  {{x}_{ij} : {\widetilde{x}}_{ij} = {x}_{ij} - \delta }\right\}  , \tag{18.28f}
$$

其中 ${x}_{rs}$ 将是非基变量. 在这个例子中, $\delta  = \min \{ 1,3\}  = 1$ .

$$
\Rightarrow  \widetilde{\mathbf{X}} = \left( \begin{array}{llll} 4 & 5 & & \\   & & 5 & 5 \\   & 1 & & 2 \end{array}\right) ,\;f\left( \underline{x}\right)  = {53}. \tag{18.28g}
$$

![01936af3-1230-7a0e-9a4a-8542777881ce_18_593_1657_445_250_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_18_593_1657_445_250_0.jpg)

然后,取 $\mathbf{X} = \widetilde{\mathbf{X}}$ ,重复上述程序.

$$
\mathbf{C} = \left( \begin{matrix} \left( 5\right) & \left( 3\right) & 2 & 7 \\  8 & 2 & \left( 1\right) & \left( 1\right) \\  9 & \left( 2\right) & 6 & \left( 3\right)  \end{matrix}\right) \begin{array}{l} {p}_{1} = 0 \\  {p}_{2} = 3 \\  {p}_{3} = 1 \end{array}
$$

$$
{q}_{1} =  - 5\;{q}_{2} =  - 3\;{q}_{3} =  - 4\;{q}_{4} =  - 4
$$

$$
\Rightarrow  \widetilde{\mathbf{C}} = \left( \begin{matrix} \left( 0\right) & \left( 0\right) & \left( {-2}\right) & 3 \\  6 & 2 & \left( 0\right) & \left( 0\right) \\  5 & \left( 0\right) & 3 & \left( 0\right)  \end{matrix}\right)  \tag{18.28h}
$$

$$
\widetilde{\mathbf{X}} = \left( \begin{matrix} 4 & 5 - \delta &  \leftarrow  & \delta & \\   & & &  \uparrow  & \\   \downarrow  & & 5 - \delta &  \leftarrow  & 5 + \delta \\   & & & &  \uparrow  \\  1 + \delta &  \rightarrow  & & & 2 - \delta  \end{matrix}\right)
$$

$$
\overset{\delta  = 2}{ \Rightarrow  }\widetilde{\mathbf{X}} = \left( \begin{matrix} 4 & 3 & 2 & \\   & & 3 & 7 \\   & 3 & &  \end{matrix}\right) ,\;f\left( \mathbf{X}\right)  = {49}. \tag{18.28i}
$$

下一个矩阵 $\widetilde{\mathbf{C}}$ 不包含任何负元,故 $\widetilde{\mathbf{X}}$ 是最优解.

##### 18.1.4.2 配置问题

**通过一个例子说明问题.**

现有 $n$ 份销售合同要分给 $n$ 个公司,使得每家公司恰好收到一份合同. 为此必须作出分配安排使得总成本最低,这里第 $i$ 个公司负担第 $j$ 个合同的费用是 ${c}_{ij}$ . 配置问题是一种特殊的运输问题,这里 $m = n,{a}_{i} = {b}_{j} = 1,\forall i, j$ :

$$
\text{OF:}f\left( \underline{\mathbf{x}}\right)  = \mathop{\sum }\limits_{{i = 1}}^{n}\mathop{\sum }\limits_{{j = 1}}^{n}{c}_{ij}{x}_{ij} = \min \text{!} \tag{18.29a}
$$

$$
\text{CT:}\mathop{\sum }\limits_{{j = 1}}^{n}{x}_{ij} = 1\left( {i = 1,\cdots , n}\right) \text{,}
$$

$$
\mathop{\sum }\limits_{{i = 1}}^{n}{x}_{ij} = 1\left( {j = 1,\cdots , n}\right) ,\;{x}_{ij} \in  \{ 0,1\} . \tag{18.29b}
$$

每个可行分布矩阵在其每一行和每一列恰有一个 1 , 所有其余元均为零. 然而在这样维度的一般运输问题中,一个非退化基本解会有 ${2n} - 1$ 个正变量. 因此,该分配问题的基本可行解是高度退化的,具有 $n - 1$ 个等于零的基变量. 从可行分布矩阵 $\mathbf{X}$ 出发,分配问题可以借助一般的运输算法求解. 这样做是非常耗时的. 但是,由于基本可行解的高度退化特征, 配置问题可以通过非常有效的匈牙利(Hungarian) 方法求解 (见 [18.11]).

##### 18.1.4.3 分配问题

同样通过一个例子来说明问题.

$m$ 个产品 ${E}_{1},\cdots ,{E}_{m}$ 需要生产数量分别为 ${a}_{1},\cdots ,{a}_{m}$ . 每一种产品可以在 $n$ 台机器 ${M}_{1},\cdots ,{M}_{n}$ 的任一台上生产. 在机器 ${M}_{j}$ 上生产一件产品 ${E}_{i}$ 需要耗时 ${b}_{ij}$ 和成本 ${c}_{ij}$ . 机器 ${}_{j}$ 的时间容量是 ${b}_{j}$ . 用 ${x}_{ij}$ 表示机器 ${M}_{j}$ 生产产品 ${E}_{i}$ 的数量. 总的生产成本应该达到最小. 这个分配问题的一般模型如下:

$$
\text{OF:}f\left( \underline{\mathbf{x}}\right)  = \mathop{\sum }\limits_{{i = 1}}^{m}\mathop{\sum }\limits_{{j = 1}}^{n}{c}_{ij}{x}_{ij} = \min \text{!} \tag{18.30a}
$$

$$
\text{CT:}\mathop{\sum }\limits_{{j = 1}}^{m}{x}_{ij} = {a}_{i}\left( {i = 1,\cdots , m}\right) \text{,}
$$

$$
\mathop{\sum }\limits_{{i = 1}}^{n}{b}_{ij}{x}_{ij} \leq  {b}_{j}\left( {j = 1,\cdots , n}\right) ,\;{x}_{ij} \geq  0,\;\forall i, j. \tag{18.30b}
$$

分配问题是运输问题的推广,它可以用单纯形法求解. 如果所有 ${b}_{ij} = 1$ ,则可以在引入虚构产品 ${E}_{m + 1}$ (参见第 1194 页 18.1.4.1) 后使用更有效的运输算法 (参见第 1195 页 18.1.4.1).

##### 18.1.4.4 游路问题

假定有 $n$ 个地方 ${O}_{1},\cdots ,{O}_{n}$ . 从 ${O}_{i}$ 到 ${O}_{j}$ 的旅行时间是 ${c}_{ij}$ . 这里 ${c}_{ij} \neq  {c}_{ji}$ 是可能的. 现在要确定游客恰好一次通过每个地方并最终返回出发点所需要的最短旅程.

与配置问题相类似,在时间矩阵 $C$ 的每行每列中恰好选择一个元,使得所选元之和最小. 数值求解这个问题的难点在于带标记元需要按照如下方式排序:

$$
{c}_{{i}_{1},{i}_{2}},{c}_{{i}_{2},{i}_{3}},\cdots ,{c}_{{i}_{n},{i}_{n + 1}}\text{,这里}i \neq  j\text{时}{i}_{k} \neq  {i}_{j}\text{,并且}{i}_{n + 1} = {i}_{1}\text{.} \tag{18.31}
$$

游路问题可以用分枝法和限界法求解.

##### 18.1.4.5 调度问题

$n$ 种不同产品在 $m$ 台不同的机器上按照相关产品订单进行加工. 在任何时间只能有一种产品在一台机器上加工. 每种产品在每台机器上的加工时间假定是已知的. 一种给定产品不在加工过程而处于等待加工, 以及机器出现空闲都有可能.

要求确定加工作业的最优调度, 这里目标函数选择为全部加工完成的时间, 或者加工作业中总的等待时间, 或者总的机器闲置时间. 在无等待时间或闲置时间的情形下, 往往选择完成全部加工时间之和作为目标函数.

### 18.2 非线性优化问题

#### 18.2.1 问题的提法、理论基础

##### 18.2.1.1 问题的提法

###### 1. 非线性优化问题

非线性优化问题的一般形式是

$$
f\left( \underline{\mathbf{x}}\right)  = \min !,\;\underline{\mathbf{x}} \in  {\mathbb{R}}^{n}\text{满足如下约束条件:} \tag{18.32a}
$$

$$
{g}_{i}\left( \underline{\mathbf{x}}\right)  \leq  0,\;i \in  I = \{ 1,\cdots , m\} ,\;{h}_{j}\left( \underline{\mathbf{x}}\right)  = 0,\;j \in  J = \{ 1,\cdots , r\} , \tag{18.32b}
$$

这里函数 $f,{g}_{i},{h}_{j}$ 中至少有一个是非线性的. 可行解集是

$$
M = \left\{  {\underline{\mathbf{x}} \in  {\mathbb{R}}^{n} : {g}_{i}\left( \underline{\mathbf{x}}\right)  \leq  0, i \in  I,{h}_{j}\left( \underline{\mathbf{x}}\right)  = 0, j \in  J}\right\}  . \tag{18.33}
$$

问题是要确定极小点.

###### 2. 极小点

点 ${\underline{\mathbf{x}}}^{ * } \in  M$ 称作全局极小点,是指它满足 $f\left( {\underline{\mathbf{x}}}^{ * }\right)  \leq  f\left( \underline{\mathbf{x}}\right) ,\forall \underline{\mathbf{x}} \in  M$ . 如果这个关系仅对于 ${\underline{x}}^{ * }$ 的某个邻域 $U$ 中的点 $\underline{x}$ 成立,则 ${\underline{x}}^{ * }$ 称作局部极小点. 由于等式约束 ${h}_{j}\left( \underline{\mathbf{x}}\right)  = 0$ 可以用两个不等式约束表达:

$$
- {h}_{j}\left( \underline{\mathbf{x}}\right)  \leq  0,\;{h}_{j}\left( \underline{\mathbf{x}}\right)  \leq  0, \tag{18.34}
$$

故可以假定集合 $J$ 是空的, $J = \varnothing$ .

##### 18.2.1.2 最优性条件

###### 1. 特殊方向

a) 可行方向锥 $\underline{x} \in  M$ 处的可行方向锥定义为

$$
Z\left( \underline{\mathbf{x}}\right)  = \left\{  {\underline{\mathbf{d}} \in  {\mathbb{R}}^{n} : \exists \bar{\alpha } > 0\text{ 使得 }\underline{\mathbf{x}} + \alpha \underline{\mathbf{d}} \in  M,0 \leq  \alpha  \leq  \bar{\alpha }}\right\}  ,\;\underline{\mathbf{x}} \in  M, \tag{18.35}
$$

其中 $\underline{d}$ 表示方向. 如果 $\underline{d} \in  Z\left( \underline{x}\right)$ ,那么射线 $\underline{x} + \alpha \underline{d}$ 上的每个点当 $\alpha$ 充分小时都属于 $M$ .

b) 下降方向 点 $\underline{x}$ 处的下降方向是指一向量 $\underline{d} \in  \mathbb{R}$ ,存在 $\bar{\alpha } > 0$ 使得

$$
f\left( {\underline{\mathbf{x}} + \alpha \underline{\mathbf{d}}}\right)  < f\left( \underline{\mathbf{x}}\right) ,\;\forall \alpha  \in  \left( {0,\bar{\alpha }}\right) . \tag{18.36}
$$

显然在极小点不存在可行下降方向. 如果 $f$ 可微,则当 $\nabla f{\left( \underline{\mathbf{x}}\right) }^{\mathrm{T}}\underline{\mathbf{d}} < 0$ 时, $\underline{\mathbf{d}}$ 是下降方向. 在这里 $\nabla$ 表示梯度算子,故 $\nabla f\left( \underline{x}\right)$ 表示标量值函数 $f$ 在 $\underline{x}$ 处的梯度.

###### 2. 最优性必要条件

如果 $f$ 可微并且 ${\underline{x}}^{ * }$ 是一局部极小点,那么

$$
\nabla f{\left( {\underline{\mathbf{x}}}^{ * }\right) }^{\mathrm{T}}\underline{\mathbf{d}} \geq  0,\;\forall \underline{\mathbf{d}} \in  \bar{Z}\left( {\underline{\mathbf{x}}}^{ * }\right) . \tag{18.37a}
$$

特别地,若 ${\underline{\mathbf{x}}}^{ * }$ 是 $M$ 的内点,那么

$$
\nabla f\left( {\underline{\mathbf{x}}}^{ * }\right)  = \underline{\mathbf{0}}. \tag{18.37b}
$$

###### 3. 拉格朗日函数和鞍点

最优性条件 (18.37a, 18.37b) 应该翻译成包含约束的更实用的形式. 根据对于具有等式约束问题的拉格朗日乘子法 (参见第 611 页 6.2.5.6), 构造所谓的拉格朗日函数:

$$
L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = f\left( \underline{\mathbf{x}}\right)  + \mathop{\sum }\limits_{{i = 1}}^{m}{u}_{i}{g}_{i}\left( \underline{\mathbf{x}}\right)  = f\left( \underline{\mathbf{x}}\right)  + {\underline{\mathbf{u}}}^{\mathrm{T}}g\left( \underline{\mathbf{x}}\right) ,\;\underline{\mathbf{x}} \in  {\mathbb{R}}^{n},\;\underline{\mathbf{u}} \in  {\mathbb{R}}_{ + }^{m}. \tag{18.38}
$$

点 $\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{u}}}^{ * }}\right)  \in  {\mathbb{R}}^{n} \times  {\mathbb{R}}_{ + }^{m}$ 称作 $L$ 的鞍点,是指

$$
L\left( {{\underline{\mathbf{x}}}^{ * },\underline{\mathbf{u}}}\right)  \leq  L\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{u}}}^{ * }}\right)  \leq  L\left( {\underline{\mathbf{x}},{\underline{\mathbf{u}}}^{ * }}\right) ,\;\forall \underline{\mathbf{x}} \in  {\mathbb{R}}^{n},\;\underline{\mathbf{u}} \in  {\mathbb{R}}_{ + }^{m}. \tag{18.39}
$$

###### 4. 全局库恩-塔克条件

如果存在 ${\underline{\mathbf{u}}}^{ * } \in  {\mathbb{R}}_{ + }^{m}$ ,即 ${\underline{\mathbf{u}}}^{ * } \geq  \underline{\mathbf{0}}$ 使得 $\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{u}}}^{ * }}\right)$ 是 $L$ 的鞍点,则点 ${\underline{\mathbf{x}}}^{ * }$ 满足全局库恩-塔克条件. 至于库恩-塔克条件的证明, 参见第 893 页 12.5.6.

###### 5. 最优性充分条件

如果点 $\left( {{\underline{x}}^{ * },{\underline{u}}^{ * }}\right)  \in  {\mathbb{R}}^{n} \times  {\mathbb{R}}_{ + }^{m}$ 是 $L$ 的鞍点,那么 ${\underline{x}}^{ * }$ 是(18.32a,18.32b)的全局极小点. 如果函数 $f$ 和 ${g}_{i}$ 可微,则可以推导出局部最优性条件.

###### 6. 局部库恩-塔克条件

如果存在数 ${u}_{i} \geq  0, i \in  {I}_{0}\left( {\underline{\mathbf{x}}}^{ * }\right)$ 使得

$$
- \nabla f\left( {\underline{\mathbf{x}}}^{ * }\right)  = \mathop{\sum }\limits_{{i \in  {I}_{0}\left( {\underline{\mathbf{x}}}^{ * }\right) }}{u}_{i}\nabla {g}_{i}\left( {\underline{\mathbf{x}}}^{ * }\right) , \tag{18.40a}
$$

其中

$$
{I}_{0}\left( \underline{\mathbf{x}}\right)  = \left\{  {i \in  \{ 1,\cdots , m\}  : {g}_{i}\left( \underline{\mathbf{x}}\right)  = 0}\right\}   \tag{18.40b}
$$

是 $\underline{x}$ 处主动约束的标号集. ${\underline{x}}^{ * }$ 也称作库恩-塔克平稳点.

这就意味着在几何上,如果负梯度 $- \nabla f\left( {\underline{x}}^{ * }\right)$ 位于由 ${\underline{x}}^{ * }$ 处主动约束 (即 $i \in$ $\left. {{I}_{0}\left( {\underline{\mathbf{x}}}^{ * }\right) }\right)$ 对应的诸梯度 $\nabla {g}_{i}\left( {\underline{\mathbf{x}}}^{ * }\right)$ 所张成的锥中 (图 18.5),则 ${\underline{\mathbf{x}}}^{ * }$ 满足库恩-塔克条件.

![01936af3-1230-7a0e-9a4a-8542777881ce_23_578_612_490_329_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_23_578_612_490_329_0.jpg)

图 18.5

局部库恩-塔克条件 (18.40a, 18.40b) 的如下等价表述也是经常使用的:如果存在 ${\underline{\mathbf{u}}}^{ * } \in  {\mathbb{R}}_{ + }^{m}$ 使得

$$
g\left( {\underline{\mathbf{u}}}^{ * }\right)  \leq  0, \tag{18.41a}
$$

$$
{u}_{i}{g}_{i}\left( {\underline{\mathbf{u}}}^{ * }\right)  = 0,\;i = 1,\cdots , m, \tag{18.41b}
$$

$$
\nabla f\left( {\underline{\mathbf{x}}}^{ * }\right)  + \mathop{\sum }\limits_{{i = 1}}^{m}{u}_{i}\nabla {g}_{i}\left( {\underline{\mathbf{x}}}^{ * }\right)  = 0, \tag{18.41c}
$$

那么 ${\underline{\mathbf{x}}}^{ * } \in  {\mathbb{R}}^{n}$ 满足局部库恩-塔克条件.

###### 7. 最优性必要条件和库恩-塔克条件

如果 ${\underline{x}}^{ * } \in  M$ 是(18.32a,18.32b)的局部极小点,并且可行集在 ${\underline{x}}^{ * }$ 处满足正则性条件: $\exists \underline{\mathbf{d}} \in  {\mathbb{R}}^{n}$ 使得 $\nabla {g}_{i}{\left( {\underline{\mathbf{x}}}^{ * }\right) }^{\mathrm{T}}\underline{\mathbf{d}} < 0,\forall i \in  {I}_{0}\left( {\underline{\mathbf{x}}}^{ * }\right)$ ,那么 ${\underline{\mathbf{x}}}^{ * }$ 满足库恩-塔克条件.

##### 18.2.1.3 优化中的对偶性

###### 1. 对偶问题

采用相关的拉格朗日函数 (18.32a, 18.32b), 构造极大问题, 即 (18.32a, 18.32b) 的所谓对偶问题:

$$
L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = \max !,\;\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  \in  {M}^{ * }, \tag{18.42a}
$$

其中

$$
{M}^{ * } = \left\{  {\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  \in  {\mathbb{R}}^{n} \times  {\mathbb{R}}_{ + }^{m} : L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = \mathop{\min }\limits_{{\underline{\mathbf{z}} \in  {\mathbb{R}}^{n}}}L\left( {\underline{\mathbf{z}},\underline{\mathbf{u}}}\right) }\right\}  . \tag{18.42b}
$$

###### 2. 对偶性定理

如果 ${\underline{\mathbf{x}}}_{1} \in  M$ ,并且 $\left( {{\underline{\mathbf{x}}}_{2},{\underline{\mathbf{u}}}_{2}}\right)  \in  {M}^{ * }$ ,那么

a) $L\left( {{\underline{\mathbf{x}}}_{2},{\underline{\mathbf{u}}}_{2}}\right)  \leq  f\left( {\underline{\mathbf{x}}}_{1}\right)$ .

b) 如果 $L\left( {{\underline{\mathbf{x}}}_{2},{\underline{\mathbf{u}}}_{2}}\right)  = f\left( {\underline{\mathbf{x}}}_{1}\right)$ ,则 ${\underline{\mathbf{x}}}_{1}$ 是(18.32a,18.32b)的极小点,而 $\left( {{\underline{\mathbf{x}}}_{2},{\underline{\mathbf{u}}}_{2}}\right)$ 是(18.42a,18.42b)的极大点.

#### 18.2.2 特殊非线性优化问题

##### 18.2.2.1 凸优化

###### 1. 凸问题

如果函数 $f$ 和 ${g}_{i}$ 是凸函数,那么优化问题

$$
f\left( \underline{\mathbf{x}}\right)  = \max !\text{,其中}\underline{\mathbf{x}}\text{满足}{g}_{i}\left( \underline{\mathbf{x}}\right)  \leq  0\left( {i = 1,\cdots , m}\right)  \tag{18.43}
$$

称作凸问题. 特别地, $f$ 和 ${g}_{i}$ 可以是线性函数. 对于凸问题,下列论断成立:

a) $f$ 在 $M$ 上的局部极小也是全局极小.

b) 如果 $M$ 非空且有界,则 (18.43) 至少有一个解.

c) 如果 $f$ 是严格凸的,则 (18.43) 至多有一个解.

###### 2. 最优性条件

a) 如果 $f$ 有连续偏导数, ${\underline{\mathbf{x}}}^{ * } \in  M$ ,并且满足

$$
{\left( \underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{ * }\right) }^{\mathrm{T}}\nabla f\left( {\underline{\mathbf{x}}}^{ * }\right)  \geq  0,\;\forall \underline{\mathbf{x}} \in  M, \tag{18.44}
$$

那么 ${\underline{x}}^{ * }$ 是 (18.43) 的解,

b) 斯莱特(Slater)条件是可行集 $M$ 的正则性条件. 如果存在 $\underline{x} \in  M$ 使得对于每个非放射线性函数 ${g}_{i}$ 有 ${g}_{i}\left( \underline{\mathbf{x}}\right)  < 0$ ,则斯莱特条件满足.

c) 如果斯莱特条件满足,则 ${\underline{x}}^{ * }$ 是 (18.43) 的极小点当且仅当存在 ${\underline{u}}^{ * } \geq  \underline{0}$ 使得 $\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{u}}}^{ * }}\right)$ 是拉格朗日函数的鞍点. 此外,如果函数 $f$ 和 ${g}_{i}$ 可微,则 ${\underline{\mathbf{x}}}^{ * }$ 是 (18.43) 的解当且仅当存在 ${\underline{x}}^{ * }$ 满足局部库恩-塔克条件.

d) 在凸规划问题中函数 $f$ 和 ${g}_{i}$ 可微的情形下,对偶问题 (18.42a,18.42b) 可以很容易表述为

$$
L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = \max !,\;\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  \in  {M}^{ * }, \tag{18.45a}
$$

$$
{M}^{ * } = \left\{  {\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  \in  {\mathbb{R}}^{n} \times  {\mathbb{R}}_{ + }^{m} : \nabla \underline{\mathbf{x}}L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = \underline{\mathbf{0}}}\right\}  . \tag{18.45b}
$$

这里 $L$ 的梯度只相对于 $\underline{x}$ 进行计算.

e) 对于凸规划问题, 还成立如下的强对偶性定理:

如果 $M$ 满足斯莱特条件,并且 ${\underline{\mathbf{x}}}^{ * } \in  M$ 是 (18.43) 的解,那么存在 ${\underline{\mathbf{u}}}^{ * } \in  {\mathbb{R}}_{ + }^{m}$ . 使得 $\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{u}}}^{ * }}\right)$ 是(18.45a,18.45b)的解. 并且

$$
f\left( {\underline{\mathbf{x}}}^{ * }\right)  = \mathop{\min }\limits_{{\underline{\mathbf{x}} \in  M}}f\left( \underline{\mathbf{x}}\right)  = \mathop{\max }\limits_{{\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  \in  {M}^{ * }}}L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = L\left( {{\underline{\mathbf{x}}}^{ * },{\underline{\mathbf{u}}}^{ * }}\right) . \tag{18.46}
$$

##### 18.2.2.2 二次优化

###### 1. 问题的提法

二次优化问题的形式如下:

$$
f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} + {\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}} = \min !,\;\underline{\mathbf{x}} \in  M \subset  {\mathbb{R}}^{n}, \tag{18.47a}
$$

$$
M = {M}_{1} : M = \left\{  {\underline{\mathbf{x}} \in  {\mathbb{R}}^{n} : \mathbf{A}\underline{\mathbf{x}} \leq  \underline{\mathbf{b}},\underline{\mathbf{x}} \geq  \underline{\mathbf{0}}}\right\}  . \tag{18.47b}
$$

这里 $\mathbf{C}$ 是对称(n, n)矩阵, $\underline{\mathbf{p}} \in  {\mathbb{R}}^{n},\mathbf{A}$ 是(m, n)矩阵,而 $\underline{\mathbf{b}} \in  {\mathbb{R}}^{m}$ . 可行集 $M$ 也可以写成下列形式:

$$
M = {M}_{\mathrm{{II}}} : M = \left\{  {\underline{\mathbf{x}} \in  {\mathbb{R}}^{n} : \mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}},\underline{\mathbf{x}} \geq  \underline{\mathbf{0}}}\right\}  , \tag{18.48a}
$$

$$
M = {M}_{\mathrm{{III}}} : M = \left\{  {\underline{\mathbf{x}} \in  {\mathbb{R}}^{n} : \mathbf{A}\underline{\mathbf{x}} \leq  \underline{\mathbf{b}}}\right\}  . \tag{18.48b}
$$

###### 2. 拉格朗日函数和库恩-塔克条件

问题 (18.47a,18.47b) 的拉格朗日函数是

$$
L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} + {\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}} + {\underline{\mathbf{u}}}^{\mathrm{T}}\left( {\mathbf{A}\underline{\mathbf{x}} - \underline{\mathbf{b}}}\right) . \tag{18.49}
$$

引入记号:

$$
\underline{\mathbf{v}} = \frac{\partial L}{\partial \underline{\mathbf{x}}} = \underline{\mathbf{p}} + 2\mathbf{C}\underline{\mathbf{x}} + {\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}},\;\underline{\mathbf{y}} =  - \frac{\partial L}{\partial \underline{\mathbf{u}}} =  - \mathbf{A}\underline{\mathbf{x}} + \underline{\mathbf{b}}, \tag{18.50}
$$

则库恩-塔克条件如下:

情形 I 情形 II

a) $\mathbf{A}\underline{\mathbf{x}} + \underline{\mathbf{y}} = \underline{\mathbf{b}}$ , a) $\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}$ ,

b) ${2C}\underline{\mathbf{x}} - \underline{\mathbf{y}} + {\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} =  - \underline{\mathbf{p}}$ , b) ${2C}\underline{\mathbf{x}} - \underline{\mathbf{y}} + {\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} =  - \underline{\mathbf{p}}$ ,

c) $\underline{x} \geq  \underline{0},\underline{v} \geq  \underline{0},\underline{y} \geq  \underline{0},\underline{u} \geq  \underline{0}$ , c) $\underline{x} \geq  \underline{0},\underline{v} \geq  \underline{0}$ ,

d) ${\underline{\mathbf{x}}}^{\mathrm{T}}\underline{\mathbf{v}} + {\underline{\mathbf{y}}}^{\mathrm{T}}\underline{\mathbf{u}} = 0$ . d) ${\underline{\mathbf{x}}}^{\mathrm{T}}\underline{\mathbf{v}} = 0$ .

情形 III

a) $\mathbf{A}\underline{\mathbf{x}} + \underline{\mathbf{y}} = \underline{\mathbf{b}}$ ,(18.51a)

b) ${2C}\underline{\mathbf{x}} + {\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} =  - \underline{\mathbf{p}}$ ,(18.51b)

c) $\underline{\mathbf{\alpha }} \geq  \underline{\mathbf{0}},\underline{\mathbf{y}} \geq  \underline{\mathbf{0}}$ ,(18.51c)

d) ${\underline{\mathbf{y}}}^{\mathrm{T}}\underline{\mathbf{u}} = 0$ .(18.51d)

###### 3. 凸性

函数 $f\left( \underline{\mathbf{x}}\right)$ 是 (严格) 凸的,当且仅当矩阵 $\mathbf{C}$ 是半正定 (正定) 的. 有关凸优化问题的每个结果都可用于带半正定矩阵 $C$ 的二次问题; 特别地,斯莱特条件总是成立的,从而点 ${\underline{x}}^{ * }$ 为最优点的必要且充分条件是,存在点 $\left( {{\underline{x}}^{ * },\underline{y},\underline{u},\underline{v}}\right)$ 满足相应的局部库恩-塔克条件组.

###### 4. 对偶问题

如果 $C$ 是正定的,那么(18.47a,18.47b)的对偶问题(18.45a,18.45b)可以表达为

$$
L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  = \max !,\;\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  \in  {M}^{ * }, \tag{18.52a}
$$

其中

$$
{M}^{ * } = \left\{  {\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)  \in  {\mathbb{R}}^{n} \times  {\mathbb{R}}_{ + }^{m} : \underline{\mathbf{x}} =  - \frac{1}{2}{C}^{-1}\left( {{\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} + \underline{\mathbf{p}}}\right) }\right\}  . \tag{18.52b}
$$

如果表达式 $\underline{\mathbf{x}} =  - \frac{1}{2}{\mathbf{C}}^{-1}\left( {{\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} + \underline{\mathbf{p}}}\right)$ 代入对偶目标函数 $L\left( {\underline{\mathbf{x}},\underline{\mathbf{u}}}\right)$ ,于是得到等价的问题:

$$
\varphi \left( \underline{\mathbf{u}}\right)  =  - \frac{1}{4}{\underline{\mathbf{u}}}^{\mathrm{T}}\mathbf{A}{\mathbf{C}}^{-1}{\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} - {\left( \frac{1}{2}\mathbf{A}{\mathbf{C}}^{-1}\underline{\mathbf{p}} + \underline{\mathbf{b}}\right) }^{\mathrm{T}}\underline{\mathbf{u}} - \frac{1}{4}{\underline{\mathbf{p}}}^{\mathrm{T}}{\mathbf{C}}^{-1}\underline{\mathbf{p}} = \max !,\;\underline{\mathbf{u}} \geq  \underline{\mathbf{0}}.
$$

(18.53)

因此,如果 ${\underline{\mathbf{x}}}^{ * } \in  M$ 是(18.47a,18.47b)的解,那么 (18.53) 有解 ${\underline{\mathbf{u}}}^{ * } \geq  \underline{\mathbf{0}}$ ,并且

$$
f\left( {\underline{\mathbf{x}}}^{ * }\right)  = \varphi \left( {\underline{\mathbf{u}}}^{ * }\right) . \tag{18.54}
$$

问题 (18.53) 可以用如下等价的形式替代:

$$
\psi \left( \underline{\mathbf{u}}\right)  = {\underline{\mathbf{u}}}^{\mathrm{T}}\mathbf{E}\underline{\mathbf{u}} + {\underline{\mathbf{h}}}^{\mathrm{T}}\underline{\mathbf{u}} = \min !,\;\text{ 约束为 }\underline{\mathbf{u}} \geq  \underline{\mathbf{0}}, \tag{18.55a}
$$

这里

$$
\mathbf{E} = \frac{1}{4}\mathbf{A}{\mathbf{C}}^{-1}{\mathbf{A}}^{\mathrm{T}},\;\underline{\mathbf{h}} = \frac{1}{2}\mathbf{A}{\mathbf{C}}^{-1}\underline{\mathbf{p}} + \underline{\mathbf{b}}. \tag{18.55b}
$$

#### 18.2.3 二次优化问题的解法

##### 18.2.3.1 沃尔夫方法

###### 1. 问题的提法和求解原理

沃尔夫 (Wolfe) 方法用于求解如下特殊类型的二次问题:

$$
f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} + {\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}} = \min !,\;\text{ 约束为 }\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}},\underline{\mathbf{x}} \geq  \underline{\mathbf{0}}. \tag{18.56}
$$

假定 $\mathbf{C}$ 是正定的. 基本思想是确定与问题 (18.56) 相关的库恩-塔克条件组成的系统

$$
\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}} \tag{18.57a}
$$

$$
2\mathbf{C}\underline{\mathbf{x}} - \underline{\mathbf{v}} + {\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} =  - \underline{\mathbf{p}}, \tag{18.57b}
$$

$$
\underline{x} \geq  \underline{0},\underline{v} \geq  \underline{0} \tag{18.57c}
$$

$$
{\underline{\mathbf{x}}}^{\mathrm{T}}\underline{\mathbf{v}} = 0 \tag{18.58}
$$

的解 $\left( {{\underline{x}}^{ * },{\underline{u}}^{ * },{\underline{v}}^{ * }}\right)$ . 关系式(18.57a,18.57b,18.57c)表示一个线性方程组,共有 $m + n$ 个方程和 ${2n} + m$ 个变量. 由于 (18.58),必然有 ${x}_{i} = 0$ 或者 ${v}_{i} = 0\left( {i = 1,\cdots , n}\right)$ . 因此 (18.57a,18.57b,18.57c) 和 (18.58) 的每个解至多有 $n + m$ 个非零分量. 从而它必定是(18.57a,18.57b,18.57c)的基本解.

###### 2. 求解过程

首先,我们确定系统 $\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}$ 的一个可行基本解 (顶点) $\underline{\overline{\mathbf{x}}}$ . 属于 $\underline{\overline{\mathbf{x}}}$ 的基变量的指标构成集合 ${I}_{B}$ . 为了找出系统(18.57a,18.57b,18.57c)的同时也满足(18.58)的解, 我们把问题表达成:

$$
- \mu  = \min !\;\left( {\mu  \in  \mathbb{R}}\right) ; \tag{18.59}
$$

$$
\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}, \tag{18.60a}
$$

$$
{2C}\underline{x} - \underline{v} + {A}^{\mathrm{T}}\underline{u} - \mu \underline{q} =  - \underline{p},\;\underline{q} = {2C}\underline{\bar{x}} + \underline{p}, \tag{18.60b}
$$

$$
\underline{\mathbf{x}} \geq  \underline{\mathbf{0}},\underline{\mathbf{v}} \geq  \underline{\mathbf{0}},\mu  \geq  0 \tag{18.60c}
$$

$$
{\underline{\mathbf{x}}}^{\mathrm{T}}\underline{\mathbf{v}} = 0. \tag{18.61}
$$

如果 $\left( {\underline{\mathbf{x}},\underline{\mathbf{v}},\underline{\mathbf{u}},\mu }\right)$ 是这个问题同时满足(19.57a,19.57b,19.57c)和(18.58)的解,那么 $\mu  = 0$ . 向量 $\left( {\underline{\mathbf{x}},\underline{\mathbf{v}},\underline{\mathbf{u}},\mu }\right)  = \left( {\underline{\overline{\mathbf{x}}},\underline{\mathbf{0}},\underline{\mathbf{0}},1}\right)$ 是系统(18.60a,18.60b,18.60c)的已知可行解, 并且它也满足 (18.61). 与此基本解相关的基由系数矩阵

$$
\left( \begin{matrix} \mathbf{A} & \mathbf{0} & \mathbf{0} & \underline{\mathbf{0}} \\  2\mathbf{C} &  - \mathbf{I} & {\mathbf{A}}^{\mathrm{T}} &  - \underline{\mathbf{q}} \end{matrix}\right)  \tag{18.62}
$$

(这里 $\mathbf{I},\mathbf{0},\underline{\mathbf{0}}$ 分别表示相应维数的单位矩阵、零矩阵、零向量) 的某些列构成:

a) $m$ 个列属于 ${x}_{i}, i \in  {I}_{B}$ ,

b) $n - m$ 个列属于 ${v}_{i}, i \notin  {I}_{B}$ ,

c) 所有 $m$ 个列都属于 ${u}_{i}$ ,

d) 先删最后一列, 然后删去 b) 或 c) 中一适当的列.

如果 $\underline{\mathbf{q}} = \underline{\mathbf{0}}$ ,则根据 $\mathrm{d})$ 互换是不可能的. 于是, $\underline{\mathbf{x}}$ 已经是解了. 现在第 1 张单纯形表就可以构建出来了. 目标函数的极小将通过单纯形法求解, 不过这里要加上一个附加的规则,即保证满足关系 ${\underline{\mathbf{x}}}^{\mathrm{T}}\underline{\mathbf{v}} = 0$ : 变量 ${x}_{i}$ 和 ${v}_{i}\left( {i = 1,\cdots , n}\right)$ 必须不能同时是基变量.

在系数矩阵 $\mathbf{C}$ 正定的情形下,考虑到此附加规则,单纯形法提供问题 (18.59), (18.60a,18.60b,18.60c),(18.61) 的一个满足 $\mu  = 0$ 的解. 在 $\mathbf{C}$ 为正半定矩阵情形下,由于限制了主元的选择,有可能发生: 尽管 $\mu  > 0$ ,在无强加的附加规则下,不可能再有交换步骤. 在这种情形下, $\mu$ 再也无法进一步减少了.

$$
f\left( \underline{\mathbf{x}}\right)  = {x}_{1}^{2} + 4{x}_{2}^{2} - {10}{x}_{1} - {32}{x}_{2} = \min !,\;{x}_{1} + 2{x}_{2} + {x}_{3} = 7,\;2{x}_{1} + {x}_{2} + {x}_{4} = 8.
$$

$$
\mathbf{A} = \left( \begin{array}{llll} 1 & 2 & 1 & 0 \\  2 & 1 & 0 & 1 \end{array}\right) ,\;\underline{\mathbf{b}} = \left( \begin{array}{l} 7 \\  8 \end{array}\right) ,\;\mathbf{C} = \left( \begin{array}{llll} 1 & 0 & 0 & 0 \\  0 & 4 & 0 & 0 \\  0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \end{array}\right) ,\;\underline{\mathbf{p}} = \left( \begin{matrix}  - {10} \\   - {32} \\  0 \\  0 \end{matrix}\right) .
$$

在这种情形下, $\mathbf{C}$ 是半正定的. $\mathbf{A}\underline{\mathbf{x}} = \underline{\mathbf{b}}$ 的一个可行基本解是 $\underline{\overline{\mathbf{x}}} = {\left( 0,0,7,8\right) }^{\mathrm{T}}$ , $\underline{\mathbf{q}} = 2\mathbf{C}\underline{\overline{\mathbf{x}}} + \underline{\mathbf{p}} = {\left( -{10}, - {32},0,0\right) }^{\mathrm{T}}$ . 基向量的选择是: a) $\left( \begin{matrix} \mathbf{A} \\  2\mathbf{C} \end{matrix}\right)$ 的第 3,4 列; b) $\left( \begin{matrix} 0 \\   - I \end{matrix}\right)$ 的第 1,2 列; c) $\left( \begin{matrix} 0 \\  {A}^{\mathrm{T}} \end{matrix}\right)$ 的列; d) 列 $\left( \begin{matrix} \underline{0} \\   - \underline{q} \end{matrix}\right)$ 代替 $\left( \begin{matrix} 0 \\   - I \end{matrix}\right)$ 的第 1 列. 基矩阵由这些列构成, 并计算基矩阵逆 (参见第 1179 页 18.1). 用基矩阵逆乘矩阵 (18.62) 和向量 $\left( \begin{matrix} \underline{0} \\   - \underline{p} \end{matrix}\right)$ ,就得到第 1 个单纯形表 (表 18.9).

表 18.9

<table><tr><td/><td>${x}_{1}$</td><td>${x}_{2}$</td><td>${v}_{1}$</td><td>${v3}$</td><td>U4</td><td/></tr><tr><td>${x}_{3}$</td><td>1</td><td>2</td><td>0</td><td>0</td><td>0</td><td>7</td></tr><tr><td>${x}_{4}$</td><td>2</td><td>1</td><td>0</td><td>0</td><td>0</td><td>8</td></tr><tr><td>${v}_{2}$</td><td>64 10</td><td>-8</td><td>$- \frac{32}{10}$</td><td>$\frac{12}{10}$</td><td>$\frac{54}{10}$</td><td>0</td></tr><tr><td>${u}_{1}$</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>0</td></tr><tr><td>${u}_{2}$</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>0</td></tr><tr><td>$\mu$</td><td>2 10</td><td>0</td><td>1 10</td><td>1 10</td><td>$\frac{2}{10}$</td><td>1</td></tr><tr><td/><td>$- \frac{2}{10}$</td><td>0</td><td>$\frac{1}{10}$</td><td>$- \frac{1}{10}$</td><td>$- \frac{2}{10}$</td><td>-1</td></tr></table>

根据互补约束,只有 ${x}_{1}$ 可以与 ${v}_{2}$ 交换. 如此几步之后,我们就得到解 ${\underline{x}}^{ * } = (2,5/2$ , $0,3/2{)}^{\mathrm{T}}.2\mathbf{C}\underline{\mathbf{x}} - \underline{\mathbf{v}} + {\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} - \mu \underline{\mathbf{q}} =  - \underline{\mathbf{p}}$ 的后两个方程是: ${v}_{3} = {u}_{1},{v}_{4} = {u}_{2}$ . 因此, 除去变量 ${u}_{1},{u}_{2}$ 之后,问题的维数可以降低.

##### 18.2.3.2 希尔德雷思-戴索普 (Hildreth-d'Esopo) 方法

###### 1. 原理

严格凸优化问题

$$
f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} + {\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}} = \min !,\;\mathbf{A}\underline{\mathbf{x}} \leq  \underline{\mathbf{b}} \tag{18.63}
$$

的对偶问题 (参见第 1202 页 1.) 是

$$
\psi \left( \underline{\mathbf{u}}\right)  = {\underline{\mathbf{u}}}^{\mathrm{T}}\mathbf{E}\underline{\mathbf{u}} + {\underline{\mathbf{h}}}^{\mathrm{T}}\underline{\mathbf{u}} = \min !,\;\underline{\mathbf{u}} \geq  0\text{,其中} \tag{18.64a}
$$

$$
\mathbf{E} = \frac{1}{4}\mathbf{A}{\mathbf{C}}^{-1}{\mathbf{A}}^{\mathrm{T}},\;\underline{\mathbf{h}} = \frac{1}{2}\mathbf{A}{\mathbf{C}}^{-1}\underline{\mathbf{p}} + \underline{\mathbf{b}}. \tag{18.64b}
$$

矩阵 $\mathbf{E}$ 是正定的,并有正对角元 ${e}_{ii}\left( {i = 1,\cdots , m}\right)$ . 变量 $\underline{\mathbf{x}}$ 和 $\underline{\mathbf{u}}$ 满足如下关系:

$$
\underline{\mathbf{x}} =  - \frac{1}{2}{\mathbf{C}}^{-1}\left( {{\mathbf{A}}^{\mathrm{T}}\underline{\mathbf{u}} + \underline{\mathbf{p}}}\right) . \tag{18.65}
$$

###### 2. 迭代求解

对偶问题 (18.64a) 仅包含约束条件 $\underline{u} \geq  \underline{0}$ ,可以通过如下简单的迭代方法求解:

a) 代入 ${\underline{\mathbf{u}}}^{1} \geq  \underline{\mathbf{0}}$ (例如, ${\mathbf{u}}^{1} = \underline{\mathbf{0}}$ ), $k = 1$ .

b) 根据下列公式计算 ${u}_{i}^{k + 1}, i = 1,\cdots , m$ :

$$
{w}_{i}^{k + 1} =  - \frac{1}{{e}_{ii}}\left( {\mathop{\sum }\limits_{{j = 1}}^{{i - 1}}{e}_{ij}{u}_{j}^{k + 1} + \frac{{h}_{i}}{2} + \mathop{\sum }\limits_{{j = i + 1}}^{m}{e}_{ij}{u}_{j}^{k}}\right) , \tag{18.66a}
$$

$$
{u}_{i}^{k + 1} = \max \left\{  {0,{w}_{i}^{k + 1}}\right\}  . \tag{18.66b}
$$

c) 重复步骤 b),用 $k + 1$ 代替 $k$ ,直至停止规则满足,例如 $\left| {\psi \left( {\underline{\mathbf{u}}}^{k + 1}\right)  - \psi \left( {\underline{\mathbf{u}}}^{k}\right) }\right|  <$ $\varepsilon ,\varepsilon  > 0$ .

假定存在 $\underline{x}$ 使得 $\mathbf{A}\underline{x} < \underline{b}$ ,则序列 $\left\{  {\psi \left( {\underline{u}}^{k}\right) }\right\}$ 收敛于极小值 ${\psi }_{\min }$ ,而由 (18.65) 给出的序列 $\left\{  {\underline{\mathbf{x}}}^{k}\right\}$ 收敛于原问题的解 ${\underline{\mathbf{x}}}^{ * }$ . 序列 $\left\{  {\underline{\mathbf{u}}}^{k}\right\}$ 并不总是收敛的.

#### 18.2.4 数值搜索程序

使用非线性优化程序, 通过综合几种类型的优化问题的计算成本, 可以找到能接受的近似解. 它们是基于函数值的比较原理.

##### 18.2.4.1 一维搜索

几种优化方法都含有寻找实函数 $f\left( x\right)$ 在 $\left\lbrack  {a, b}\right\rbrack$ 上的极小值这样的子问题. 通常只需找出极小点 ${x}^{ * }$ 的近似 $\bar{x}$ 就够了.

###### 1. 问题的提法

函数 $f\left( x\right) , x \in  \mathbb{R}$ 称作在区间 $\left\lbrack  {a, b}\right\rbrack$ 上是单峰的,是指其在每个闭子区间 $J \subseteq$ $\left\lbrack  {a, b}\right\rbrack$ 上正好有一个局部极小点. 设 $f$ 是 $\left\lbrack  {a, b}\right\rbrack$ 上的单峰函数,而 ${x}^{ * }$ 是其全局极小点. 那么应该找到一个 $\left\lbrack  {c, d}\right\rbrack   \subseteq  \left\lbrack  {a, b}\right\rbrack$ 使得 ${x}^{ * } \in  \left\lbrack  {c, d}\right\rbrack$ ,并且 $d - c < \varepsilon ,\varepsilon  > 0$ .

###### 2. 一致搜索

选择一正整数 $n$ 使得 $\delta  = \frac{b - a}{n + 1} < \frac{\varepsilon }{2}$ ,并计算函数值 $f\left( {x}^{k}\right) ,{x}^{k} = a + {k\delta }(k =$ $1,\cdots , n)$ . 如果 $f\left( x\right)$ 是这些函数值中的最小值,则极小点 ${x}^{ * }$ 就在区间 $\left\lbrack  {x - \delta , x + \delta }\right\rbrack$ 上. 对于给定的精度, 可以估计出所需函数值的数目:

$$
n > \frac{2\left( {b - a}\right) }{\varepsilon } - 1. \tag{18.67}
$$

###### 3. 黄金分割法、斐波那契法

区间 $\left\lbrack  {a, b}\right\rbrack   = \left\lbrack  {{a}_{1},{b}_{1}}\right\rbrack$ 将被逐步缩小使得新的子区间始终包含极小点 ${x}^{ * }$ . 按如下方式确定区间 $\left\lbrack  {{a}_{1},{b}_{1}}\right\rbrack$ 中点 ${\lambda }_{1},{\mu }_{1}$ :

$$
{\lambda }_{1} = {a}_{1} + \left( {1 - \tau }\right) \left( {{b}_{1} - {a}_{1}}\right) ,\;{\mu }_{1} = {a}_{1} + \tau \left( {{b}_{1} - {a}_{1}}\right) , \tag{18.68a}
$$

其中

$$
\tau  = \frac{1}{2}\left( {\sqrt{5} - 1}\right)  \approx  {0.618}. \tag{18.68b}
$$

这对应于黄金分割. 接着我们区分两种情形:

a) 如果 $f\left( {\lambda }_{1}\right)  < f\left( {\mu }_{1}\right)$ ,则作替换 ${a}_{2} = {a}_{1},{b}_{2} = {\mu }_{1}$ 和 ${\mu }_{2} = {\lambda }_{1}$ .(18.69a)

b) 如果 $f\left( {\lambda }_{1}\right)  \geq  f\left( {\mu }_{1}\right)$ ,则作替换 ${a}_{2} = {\lambda }_{1},{b}_{2} = {b}_{1}$ 和 ${\lambda }_{2} = {\mu }_{1}$ .(18.69b)如果 ${b}_{2} - {a}_{2} \geq  \varepsilon$ ,则在区间 $\left\lbrack  {{a}_{2},{b}_{2}}\right\rbrack$ 基础上重复此一程序,这里从第 1 步已经知道了一个值,即在情形 $\mathrm{a}$ ) 下是 $f\left( {\lambda }_{2}\right)$ ,而在情形 $\mathrm{b}$ ) 下是 $f\left( {\mu }_{2}\right)$ . 为了确定包含极小点的区间 $\left\lbrack  {{a}_{n},{b}_{n}}\right\rbrack$ ,需要一起计算 $n$ 个函数值. 根据要求

$$
\varepsilon  > {b}_{n} - {a}_{n} = {\tau }^{n - 1}\left( {{b}_{1} - {a}_{1}}\right) , \tag{18.70}
$$

就可以估计出必要的步数 $n$ .

使用黄金分割方法, 与斐波那契方法相比, 至多多一个函数值要确定. 在斐波那契法中, 不再是根据黄金分割法细分区间, 而是根据斐波那契数细分区间 (参见第 501 页 5.4.1.5 以及第 1178 页 17.3.2.4, 4.).

##### 18.2.4.2 在 $n$ 维欧几里得向量空间中的极小搜索

问题 $f\left( \underline{x}\right)  = \min !,\underline{x} \in  \mathbb{R}$ 的极小点的近似搜索可以化成求解一列一维优化问题:

a) $\underline{\mathbf{x}} = {\underline{\mathbf{x}}}^{1}, k = 1$ ,其中 ${\underline{\mathbf{x}}}^{1}$ 是 ${\underline{\mathbf{x}}}^{ * }$ 的适当的初始近似.(18.71a)

b) 对于 $r = 1,\cdots , n$ ,求解一维问题:

$$
\varphi \left( {\alpha }_{r}\right)  = f\left( {{x}_{1}^{k + 1},\cdots ,{x}_{r - 1}^{k + 1},{x}_{r}^{k} + {\alpha }_{r},{x}_{r + 1}^{k},\cdots ,{x}_{n}^{k}}\right)  = \min !,\;{\alpha }_{r} \in  \mathbb{R}. \tag{18.71b}
$$

如果 ${\bar{\alpha }}_{r}$ 是第 $r$ 个一维问题的精确或近似极小点,则作替换 ${x}_{r}^{k + 1} = {x}_{r}^{k} + {\bar{\alpha }}_{r}$ .

c) 如果两个相邻的近似彼此非常接近, 即在某种向量范数下有

$$
\begin{Vmatrix}{{\underline{\mathbf{x}}}^{k + 1} - {\underline{\mathbf{x}}}^{k}}\end{Vmatrix} < {\varepsilon }_{1},\;\text{ 或 }\left| {f\left( {\underline{\mathbf{x}}}^{k + 1}\right)  - f\left( {\underline{\mathbf{x}}}^{k}\right) }\right|  < {\varepsilon }_{2}, \tag{18.71c}
$$

那么 ${\underline{x}}^{k + 1}$ 是 ${\underline{x}}^{ * }$ 的一近似. 否则的话,由 $k + 1$ 代替 $k$ 重复步骤 b). b) 中的一维问题可以利用 18.2.4.1 中给出的方法求解.

#### 18.2.5 无约束问题的解法

考虑一般的优化问题

$$
f\left( \underline{\mathbf{x}}\right)  = \min !,\;\underline{\mathbf{x}} \in  {\mathbb{R}}^{n}, \tag{18.72}
$$

这里 $f$ 是连续可微函数. 本节描述的每一种方法一般是构建一无穷序列 $\left\{  {\underline{\mathbf{x}}}^{k}\right\}   \subset  {\mathbb{R}}^{n}$ , 其聚点是一平稳点. 这个点列将从 ${\underline{x}}^{1}$ 开始,按照如下递推公式构建:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}\;\left( {k = 1,2,\cdots }\right) , \tag{18.73}
$$

即首先在 ${\underline{x}}^{k}$ 处确定一方向 ${\underline{d}}^{k}$ ,而步长 ${\alpha }_{k}$ 表示在 ${\underline{x}}^{k}$ 沿 ${\underline{d}}^{k}$ 方向离 ${\underline{x}}^{k + 1}$ 有多远. 这样的方法称作下降法, 是指

$$
f\left( {\underline{\mathbf{x}}}^{k + 1}\right)  < f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) . \tag{18.74}
$$

等式 $\nabla f\left( \underline{\mathbf{x}}\right)  = 0$ 刻画平稳点,并且可以用作迭代算法的停止规则,其中 $\nabla$ 表示梯度算子 (参见第 933 页 13.2.6.1).

##### 18.2.5.1 最速下降法

从现时点 ${\underline{x}}^{k}$ 出发,函数下降最快速的方向是

$$
{\underline{\mathbf{d}}}^{k} =  - \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) , \tag{18.75a}
$$

从而,

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\alpha }_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) . \tag{18.75b}
$$

最速下降法以 $f\left( \underline{\mathbf{x}}\right)  = f\left( {\underline{\mathbf{x}}}^{i}\right)$ 为水平线的示意图见图 18.6.

![01936af3-1230-7a0e-9a4a-8542777881ce_31_543_1081_555_301_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_31_543_1081_555_301_0.jpg)

图 18.6

步长 ${\alpha }_{k}$ 由线搜索确定,即 ${\alpha }_{k}$ 是一维问题

$$
f\left( {{\underline{\mathbf{x}}}^{k} + \alpha {\underline{\mathbf{d}}}^{k}}\right)  = \min !,\;\alpha  \geq  0 \tag{18.76}
$$

的解. 上述问题可以用 1208 页 18.2.4 给出的方法求解.

最速下降法(18.75b)收敛得相当慢. 对于序列 $\left\{  {\underline{x}}^{k}\right\}$ 的每个聚点 ${\underline{x}}^{ * }$ ,有 $\nabla f\left( {\underline{\mathbf{x}}}^{ * }\right)  = 0$ . 在二次目标函数情形下,即 $f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} + {\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}}$ ,该方法取如下特殊形式:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}, \tag{18.77a}
$$

其中

$$
{\underline{\mathbf{d}}}^{k} =  - \left( {2\mathbf{C}{\underline{\mathbf{x}}}^{k} + \underline{\mathbf{p}}}\right) ,\;\text{ 且 }\;{\alpha }_{k} = \frac{{\underline{\mathbf{d}}}^{{k}^{\mathrm{T}}}{\mathbf{d}}^{k}}{2{\underline{\mathbf{d}}}^{{k}^{\mathrm{T}}}\mathbf{C}{\underline{\mathbf{d}}}^{k}}. \tag{18.77b}
$$

##### 18.2.5.2 牛顿法的应用

假定在当前的近似点 ${\underline{x}}^{k}$ 处,函数 $f$ 由如下二次函数逼近:

$$
q\left( \underline{\mathbf{x}}\right)  = f\left( {\underline{\mathbf{x}}}^{k}\right)  + {\left( \underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  + \frac{1}{2}{\left( \underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right) \left( {\underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{k}}\right) . \tag{18.78}
$$

这里 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right)$ 是黑塞矩阵,即 $f$ 在 ${\underline{\mathbf{x}}}^{k}$ 处的二阶偏导数矩阵. 如果 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right)$ 是正定的,则 $q\left( \underline{\mathbf{x}}\right)$ 在 ${\underline{\mathbf{x}}}^{k + 1}$ 处达到绝对极小,且 $\nabla q\left( {\underline{\mathbf{x}}}^{k + 1}\right)  = 0$ ,从而得到牛顿方法:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) , \tag{18.79a}
$$

即

$$
{\underline{\mathbf{d}}}^{k} =  - {\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) ,\;\text{且}{\alpha }_{k}\text{见 (18.73).} \tag{18.79b}
$$

牛顿法收敛速度快, 但它也有如下缺点:

a) 矩阵 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{k}\right)$ 必须是正定的.

b) 该方法仅对充分好的初始点收敛.

c) 步长可能没有影响.

d) 该方法并不是一种下降法.

e) 计算逆矩阵 ${\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right)$ 的计算量相当大.

通过所谓的阻尼牛顿法可能会适当减少某些缺点 (例如 1251 页 19.2.2.2):

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\alpha }_{k}{\mathbf{H}}^{-1}\left( {\underline{\mathbf{x}}}^{k}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) , \tag{18.80}
$$

其中的松弛因子 ${\alpha }_{k}$ 比如可以通过前面给出的原则来确定 (参见第 1210 页 18.2.5.1).

##### 18.2.5.3 共轭梯度法

两个向量 ${\underline{\mathbf{d}}}^{1},{\underline{\mathbf{d}}}^{2}$ 称作相对于对称正定矩阵 $\mathbf{C}$ 是共轭向量,是指它们满足

$$
{\underline{\mathbf{d}}}^{{1}^{\mathrm{T}}}\mathbf{C}{\underline{\mathbf{d}}}^{2} = 0. \tag{18.81}
$$

如果 ${\underline{\mathbf{d}}}^{1},{\underline{\mathbf{d}}}^{2},\cdots ,{\underline{\mathbf{d}}}^{n}$ 相对于矩阵 $\mathbf{C}$ 是两两共轭的,那么凸二次问题 $q\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} +$ ${\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}},\underline{\mathbf{x}} \in  {\mathbb{R}}^{n}$ 可以通过 $n$ 步求解,为此只要从 ${\underline{\mathbf{x}}}^{1}$ 出发构建序列 ${\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}$ , 其中 ${\alpha }_{k}$ 是最优步长. 假设 $f\left( \underline{x}\right)$ 在 ${\underline{x}}^{ * }$ 的邻域内是近似二次函数,即 $C \approx  \frac{1}{2}H\left( {\underline{x}}^{ * }\right)$ , 则为二次目标函数研发的方法也可应用于更一般的函数 $f\left( \underline{x}\right)$ ,而无须明着使用矩阵 $\mathbf{H}\left( {\underline{\mathbf{x}}}^{ * }\right)$ .

共轭梯度法分如下几个步骤:

a) ${\underline{x}}^{1} \in  {\mathbb{R}}^{n},{\underline{d}}^{1} =  - \nabla f\left( {\underline{x}}^{1}\right)$ ,其中 ${\underline{x}}^{1}$ 是 ${\underline{x}}^{ * }$ 的一个适当的初始近似. (18.82)

b) ${\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}\left( {k = 1,\cdots , n}\right)$ ,其中 ${\alpha }_{k} \geq  0$ 使得 $f\left( {{\underline{\mathbf{x}}}^{k} + \alpha {\underline{\mathbf{d}}}^{k}}\right)$ 达到极小.(18.83a)

$$
{\underline{\mathbf{d}}}^{k + 1} =  - \nabla f\left( {\underline{\mathbf{x}}}^{k + 1}\right)  + {\mu }_{k}{\underline{\mathbf{d}}}^{k}\;\left( {k = 1,\cdots , n - 1}\right) , \tag{18.83b}
$$

其中

$$
{\mu }_{k} = \frac{\nabla f{\left( {\underline{\mathbf{x}}}^{k + 1}\right) }^{\mathrm{T}}\nabla f\left( {\underline{\mathbf{x}}}^{k + 1}\right) }{\nabla f{\left( {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) },\;{\underline{\mathbf{d}}}^{n + 1} =  - \nabla f\left( {\underline{\mathbf{x}}}^{n + 1}\right) . \tag{18.83c}
$$

c) 用 ${\underline{x}}^{n + 1}$ 和 ${\underline{d}}^{n + 1}$ 代替 ${\underline{x}}^{1}$ 和 ${\underline{d}}^{1}$ ,重复步骤 b).

##### 18.2.5.4 戴维顿 (Davidon)、弗莱彻 (Fletcher) 和鲍威尔 (Powell)(DFP) 方法

在 DFP 方法中,从 ${\underline{x}}^{1}$ 出发的点列根据下列公式确定:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} - {\alpha }_{k}{\mathbf{M}}_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) \;\left( {k = 1,2,\cdots }\right) , \tag{18.84}
$$

这里 ${\mathbf{M}}_{k}$ 是对称正定矩阵. 在 $f$ 为二次函数的情形下,这一方法的想法是逆黑塞矩阵由矩阵 ${\mathbf{M}}_{k}$ 逐步近似. 从对称正定矩阵 ${\mathbf{M}}_{1}$ ,例如, ${\mathbf{M}}_{1} = \mathbf{I}(\mathbf{I}$ 为单位矩阵) 出发, ${\mathbf{M}}_{k}$ 由 ${\mathbf{M}}_{k - 1}$ 加上一个 2 秩修正矩阵确定:

$$
{\mathbf{M}}_{k} = {\mathbf{M}}_{k - 1} + \frac{{\underline{\mathbf{v}}}^{k}{\underline{\mathbf{v}}}^{{k}^{\mathrm{T}}}}{{\underline{\mathbf{v}}}^{{k}^{\mathrm{T}}}{\underline{\mathbf{v}}}^{k}} - \frac{\left( {{\mathbf{M}}_{k - 1}{\underline{\mathbf{w}}}^{k}}\right) {\left( {\mathbf{M}}_{k - 1}{\underline{\mathbf{w}}}^{k}\right) }^{\mathrm{T}}}{{\underline{\mathbf{w}}}^{{k}^{\mathrm{T}}}{\mathbf{M}}_{k}{\underline{\mathbf{w}}}^{k}}, \tag{18.85}
$$

其中 ${\underline{\mathbf{v}}}^{k} = {\underline{\mathbf{x}}}^{k} - {\underline{\mathbf{x}}}^{k - 1},{\underline{\mathbf{w}}}^{k} = \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  - \nabla f\left( {\underline{\mathbf{x}}}^{k - 1}\right) \left( {k = 2,3,\cdots }\right)$ . 步长 ${\alpha }_{k}$ 从求解下列优化问题得到:

$$
f\left( {{\underline{\mathbf{x}}}^{k} - \alpha {\mathbf{M}}_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) }\right)  = \min !,\;\alpha  \geq  0. \tag{18.86}
$$

如果 $f\left( \underline{x}\right)$ 是二次函数,则 DFP 方法变成共轭梯度法,相应的初始 ${\mathbf{M}}_{1} = \mathbf{I}$ .

#### 18.2.6 演化策略

##### 18.2.6.1 演化原理

演化策略是模拟自然演化的随机优化过程的例子. 它们基于突变、重组和选择三个原理.

###### 1. 突变

从亲本 ${\underline{\mathbf{x}}}_{P}$ ,通过随机变化 $\underline{\mathbf{d}}$ 形成后裔 ${\underline{\mathbf{x}}}_{O} = {\underline{\mathbf{x}}}_{P} + \underline{\mathbf{d}}$ ,其中 $\underline{\mathbf{d}}$ 的分量是 $\left( {0,{\sigma }_{i}^{2}}\right)$ 正态分布随机变量 $Z\left( {0,{\sigma }_{i}^{2}}\right)$ ,其在每一次突变时要重新确定:

$$
\underline{\mathbf{d}} = \left( \begin{matrix} {d}_{1} \\  {d}_{2} \\  \vdots \\  {d}_{n} \end{matrix}\right)  = \left( \begin{matrix} Z\left( {0,{\sigma }_{1}^{2}}\right) \\  Z\left( {0,{\sigma }_{2}^{2}}\right) \\  \vdots \\  Z\left( {0,{\sigma }_{n}^{2}}\right)  \end{matrix}\right)  = \left( \begin{matrix} Z\left( {0,1}\right)  \cdot  {\sigma }_{1} \\  Z\left( {0,1}\right)  \cdot  {\sigma }_{2} \\  \vdots \\  Z\left( {0,1}\right)  \cdot  {\sigma }_{n} \end{matrix}\right) . \tag{18.87}
$$

在正态分布 $\underline{d}$ 情形下,小变化的概率很高,而大变化则很少出现. 这种变化受标准偏差 ${\sigma }_{i}$ 控制.

###### 2. 重组

对于有 $\mu$ 个亲本的种群,可以通过混杂随机选择的两个或更多个亲本信息获得后代. 这种重组可采取两种变化方式:

以中间形式重组 其后代作为 $\varrho$ 个随机选择的亲本加权平均,即

$$
{\underline{\mathbf{x}}}_{O} = \mathop{\sum }\limits_{{i = 1}}^{\varrho }{\alpha }_{i}{\underline{\mathbf{x}}}_{{P}_{i}},\;\mathop{\sum }\limits_{{i = 1}}^{\varrho }{\alpha }_{i} = 1,\;2 \leq  \varrho  \leq  \mu . \tag{18.88}
$$

以离散形式重组 其后代 ${\underline{x}}_{O}$ 的第 $i$ 个分量由 $\varrho$ 个亲本中随机选择的一个亲本的第 $i$ 个分量确定,即

$$
{x}_{iO} = {x}_{i{P}_{j}},\;j \in  \{ 1,\cdots ,\varrho \} ,\;i = 1,\cdots , n. \tag{18.89}
$$

###### 3. 选择

通过突变和重组,随机形成一组后代. 在随后的选择过程中,目标函数 $f\left( \underline{x}\right)$ 被作为比较个体适应性的一种度量. 最适应的个体选择作为下一代. 在某些策略下, 仅仅子孙后代才参与选择. 有些策略也会考虑亲本参与选择 (参见 [18.9]).

##### 18.2.6.2 演化算法

每一种演化策略都是基于如下算法:

a) 确定由 $\mu$ 个个体组成的适当的初始种群. 这些是第 1 代亲本 ${X}_{P}^{1} = \left\{  {{\underline{x}}_{{P}_{1}}^{1},}\right.$ $\left. {\cdots ,{\underline{\mathbf{x}}}_{{P}_{\mu }}^{1}}\right\}$ .

b) 在第 $k$ 步中,通过当前一代亲本 ${X}_{P}^{k} = \left\{  {{\underline{\mathbf{x}}}_{{P}_{1}}^{k},\cdots ,{\underline{\mathbf{x}}}_{{P}_{\lambda }}^{k}}\right\}$ 的突变和重组产生 $\lambda$ 个后代 ${X}_{O}^{k} = \left\{  {{\underline{\mathbf{x}}}_{{O}_{1}}^{k},\cdots ,{\underline{\mathbf{x}}}_{{O}_{\lambda }}^{k}}\right\}$ .

c) 通过选择得到最佳的 $\mu$ 个个体作为下一代亲本 ${X}_{P}^{k + 1} = \left\{  {{\underline{\mathbf{x}}}_{{P}_{1}}^{k + 1},\cdots ,{\underline{\mathbf{x}}}_{{P}_{\mu }}^{k + 1}}\right\}$ .

d) 重复步骤 b) 和 c) 直到满足停止规则. 这个规则可以是满足优化问题的最优判据, 或者是达到指定的代际数, 或者是超过给定的电脑时间, 等等.

##### 18.2.6.3 演化策略的分类

每一个演化策略都由一列参数刻画. 最重要的参数是种群大小 $\mu$ 、后代个数 $\lambda$ 、 参与重组的亲本个数 $\varrho$ ,以及实施突变、重组和选择的规则. 为了区分各种不同类型的策略,通常使用一种特殊的记号. 对于仅使用突变产生后代的策略,使用 $\left( {\mu  + \lambda }\right)$ 或 $\left( {\mu ,\lambda }\right)$ 策略记号. 策略 $\left( {\mu  + \lambda }\right)$ 和 $\left( {\mu ,\lambda }\right)$ 彼此的区别在于选择的类型不同. 在策略 $\left( {\mu ,\lambda }\right)$ 中,仅在子孙中选择新一代,而在策略 $\left( {\mu  + \lambda }\right)$ 中,则新一代的选择也涉及母体. 至于使用重组策略,所涉及的亲本数 $\varrho$ 会在 $\left( {\mu /\varrho  + \lambda }\right)$ 策略和 $\left( {\mu /\varrho ,\lambda }\right)$ 策略记号中体现.

##### 18.2.6.4 生成随机数

为了对演化程序做数值评估, 需要均匀和正态分布的随机变量. 均匀分布的随机变量的值可以从分节第 1100 页 16.3.5.2 中给出的方法得到. 正态分布随机变量则可以根据如下方式从均匀随机变量产生:

博克斯-穆勒 (Box-Muller) 方法 如果 ${G}_{1}$ 和 ${G}_{2}$ 是区间 $\left\lbrack  {0,1}\right\rbrack$ 上均匀分布的随机数,则如下两个方程给出两个统计独立正态分布的 $\left( {0,{\sigma }^{2}}\right)$ 随机数 ${Z}_{1}\left( {0,{\sigma }^{2}}\right)$ 和 ${Z}_{2}\left( {0,{\sigma }^{2}}\right)$ :

$$
{Z}_{1}\left( {0,{\sigma }^{2}}\right)  = \sigma \sqrt{-2\ln {G}_{1}}\cos \left( {{2\pi }{G}_{2}}\right) \text{ 和 }{Z}_{2}\left( {0,{\sigma }^{2}}\right)  = \sigma \sqrt{-2\ln {G}_{1}}\sin \left( {{2\pi }{G}_{2}}\right)
$$

(18.90)

##### 18.2.6.5 演化策略的应用

在实际中, 优化问题通常高度复制. 在这里, 1209 页 18.2.5 中描述的常规优化过程往往并不适合. 演化策略属于非微分解法, 它是基于目标函数值的比较. 这种解法对目标函数的结构要求很简单. 目标函数并不需要可微或连续. 从而这种演化策略适于相当广泛的优化问题.

演化策略的应用并不限于无约束连续优化问题. 带约束的优化问题也可处理, 这里约束是通过在目标函数中添加惩罚项进行处理 (参见第 1221 页 18.2.8 中的罚函数法和障碍函数法). 另一种应用场合是离散演化,这里 $\underline{x}$ 的部分或全部分量可能从某个离散集中取值. 一种可能的突变机制是以等概率方式用其某个相邻值取代离散分量值.

#### 18.2.6.6 (1+1)突变一选择策略

这种方法类似于 1209 页 18.2.5 中介绍的梯度法,差别在于方向 ${\underline{\mathbf{d}}}^{k}$ 是正态分布的随机向量. 种群由单个个体组成, 其在每一代只产生一个后代.

###### 1. 突变方式

在第 $k$ 代,后代从亲本加上一正态分布的随机向量得到

$$
{\underline{\mathbf{x}}}_{O}^{k} = {\underline{\mathbf{x}}}_{P}^{k} + \alpha {\underline{\mathbf{d}}}^{k}. \tag{18.91}
$$

因子 $\alpha$ 是能反映收敛速度的参数. 我们把 $\alpha$ 看作突变的步长.

###### 2. 选择方式

下一代,即第 $k + 1$ 代的新亲本的选择是比较两个个体的目标函数值,即按照

下面的公式选择:

$$
{\underline{\mathbf{x}}}_{P}^{k + 1} = \left\{  \begin{array}{ll} {\underline{\mathbf{x}}}_{O}^{k}, & f\left( {\underline{\mathbf{x}}}_{O}^{k}\right)  < f\left( {\underline{\mathbf{x}}}_{P}^{k}\right) , \\  {\underline{\mathbf{x}}}_{P}^{k}, & \text{ 其他. } \end{array}\right.  \tag{18.92}
$$

如果在达到指定的代际数时没有更好的后代, 则此程序终止. 如果这种突变多半会导致后代改善,则可以增加步长. 而如果突变导致后代的改善较小,则应该减少 $\alpha$ 值.

###### 3. 步长控制

突变步长 $\alpha$ 的选择对于演化方法的收敛性具有重要影响. 为了快速收敛通常会推荐大步长, 而在邻近最优或在目标函数的快速变化或振动区域, 则要求小步长. 最优步长依赖于所研究的问题. 步长太小会导致滞止, 而步长太大则可能引起演化过程的过调.

(1) 1/5 成功法则 在上一步中成功突变数目与突变总数之比确定成功的比值 $q$ . 如果 $q > 1/5$ ,则步长可以增加. 而如果成功比值较小,则步长 $\alpha$ 应该减少:

$$
{\alpha }_{k + 1} = \left\{  {\begin{array}{ll} c \cdot  {\alpha }_{k} & q < 1/5, \\  \frac{1}{c} \cdot  {\alpha }_{k}, & q > 1/5, \end{array}\;c = {0.8},\cdots ,{0.85}.}\right.  \tag{18.93}
$$

(2)突变步长的确定 1/5 的法则是一种粗略的选择,因而在考虑某个具体问题时并不会总是令人满意的. 在一个扩展模型中,步长 $\alpha$ 和标准偏差 ${\sigma }_{i}, i =$ $1,2,\cdots , n$ 总是在不断修正中. 这里 $\alpha$ 和 ${\sigma }_{i}$ 以等概率的方式乘以三个因子 $c,1,1/c$ 中的某一个, $c = {1.1},\cdots ,{1.5}$ . 进一步的信息见 [18.9].

##### 18.2.6.7 种群策略

上一节介绍的 $\left( {1 + 1}\right)$ 策略仅仅以十分简单的方式反映自然演化的原理. 在推广到种群模型时, 可能要考虑演化过程的进一步性质. 演化过程中的大量个体确保解空间的不同区域都会搜索到.

###### 1. $\left( {\mu  + \lambda }\right)$ 演化策略

$\left( {\mu  + \lambda }\right)$ 策略是 $\left( {1 + 1}\right)$ 策略的推广. 从当前一代的 $\mu$ 个亲本 ${X}_{P}^{k} = \left\{  {{\underline{\mathbf{x}}}_{{P}_{1}}^{k},\cdots }\right.$ , $\left. {\underline{x}}_{{P}_{\mu }}^{k}\right\}$ ,以等概率随机选择一组 $\lambda$ 个母体. 允许重复选择,甚至在 $\mu  < \lambda$ 的情形下, 这种重复选择也是必须的. 通过突变产生 $\lambda$ 个后代 ${X}_{O}^{k} = \left\{  {{\underline{\mathbf{x}}}_{{O}_{1}}^{k},\cdots ,{\underline{\mathbf{x}}}_{{O}_{\lambda }}^{k}}\right\}$ . 从候选组 ${X}_{O}^{k} \cup  {X}_{P}^{k}$ 中选择最佳的 $\mu$ 个个体进入下一代.

由于亲本也参与到选择,故种群从一代到下一代的质量不可能更差. $\left( {\lambda  + \mu }\right)$ 策略的特点是它能保持已经找出的局部最优, 这是因为远离最优点要求发生的大的突变, 但出现这种情形的概率是非常小的. 这意味着, 个体可能有无限寿命. 通过对亲本的目标函数值加上惩罚项使其一代代增加, 从而可以避免这种情形出现. 用这种方法可以模拟个体变老.

###### 2. $\left( {\mu ,\lambda }\right)$ 演化策略

与 $\left( {\mu  + \lambda }\right)$ 策略相反,其选择方式是在 $\lambda$ 个后裔中挑选 $\mu$ 个个体作为下一代, 即在这一策略中,亲本不再活下来. 因此必须有 $\lambda  > \mu$ . 后代的目标函数值可能大于亲本的目标函数值. 这一程序可以从局部最优点开始.

选择压力 参与选择的个体与种群大小之比定义为选择压力 $S$ :

$$
S = \left\{  {\begin{array}{ll} \frac{\lambda  + \mu }{\mu }, & \text{ 对于 }\left( {\lambda  + \mu }\right) \text{ 策略,} \\  \frac{\lambda }{\mu }, & \text{ 对于 }\left( {\lambda ,\mu }\right) \text{ 策略,} \end{array}\;1 \leq  S < \infty .}\right.  \tag{18.94}
$$

如果选择压力接近于 1,则这种选择方式几乎没有影响. 大量的后代,即 $\lambda  \gg  \mu$ 会导致很大的选择压力, 因为当前个体集合中只有少数几个会存活到下一代.

###### 3. 带重组的 $\left( {\mu /\varrho  + \lambda }\right)$ 和 $\left( {\mu /\varrho ,\lambda }\right)$ 演化策略

借助于重组概念, 建立了种群个体之间的某些关系, 从而后代中混合了几个亲本的信息. 为了产生后代,从一组亲本 ${X}_{P}^{k}$ 中以等概率方式选择 $\varrho$ 个亲本. 假定 $\lambda$ 个后代中的每个成员,都是从 $\varrho$ 个亲本中独立选择的. 后代是所选亲本的离散或中间重组. 用这种方法产生的后代再经突变, 并进入选择过程.

在前面描述的 $\left( {\mu  + \lambda }\right)$ 或 $\left( {\mu ,\lambda }\right)$ 策略中,每一个体都是一系列突变应用于第 1 代亲本中一个成员的结果. 因此, 仅通过多代的突变就可能是一种比较一般的演化步骤. 但采用重组方式则可能会出现多种更一般的演化方式, 尤其是当亲本彼此相隔遥远, 其后代就会具有新的特性.

###### 4. 带更多个种群的演化策略

上述的演化原理形式上可以扩展到多种群情形. 这就是说, 现在不再是种群个体间的竞争, 而是种群之间的竞争. 因此, 这种演化过程包含两个层级, 并用扩展的记号表示为: $\left\lbrack  {{\mu }_{2}/{\varrho }_{2} + {\lambda }_{2}\left( {{\mu }_{1}/{\varrho }_{1} + {\lambda }_{1}}\right) }\right\rbrack$ . 从一组 ${\mu }_{2}$ 个种群亲本,通过 ${\varrho }_{2}$ 个种群的重组,产生一组 ${\lambda }_{2}$ 个种群后代,这里的重组对于每个种群后代而言都是随机选取的. 在这 ${\lambda }_{2}$ 个种群后代中,使用 $\left( {{\mu }_{1}/{\varrho }_{1} + {\lambda }_{1}}\right)$ 或 $\left( {{\mu }_{1}/{\varrho }_{1},{\lambda }_{1}}\right)$ 策略进行优化. 在达到给定代际数之后, 基于适当准则选择出最佳种群. 种群中最佳个体的目标函数值或种群的均值可以作为种群比较的判据.

#### 18.2.7 不等式类型约束下问题的梯度法

如果问题

$$
f\left( \underline{\mathbf{x}}\right)  = \min !,\;\text{约束条件为}{g}_{i}\left( \underline{\mathbf{x}}\right)  \leq  0\text{,} \tag{18.95}
$$

需要采用如下类型的迭代法求解:

$$
{\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}\;\left( {k = 1,2,\cdots }\right) , \tag{18.96}
$$

那么由于有界可行集, 必须考虑另两个附加规则:

(1) 方向 ${\underline{d}}^{k}$ 必须是 ${\underline{x}}^{k}$ 处的可行下降方向.

(2) 步长 ${\alpha }_{k}$ 必须使得 ${\underline{\mathbf{x}}}^{k + 1}$ 在 $M$ 中.

基于公式 (18.96) 的各种方法的差别仅在于构造方向 ${\underline{\mathbf{d}}}^{k}$ 的不同. 为了确保序列 $\left\{  {\underline{\mathbf{x}}}^{k}\right\}   \subset  M$ 的可行性, ${\alpha }_{k}^{\prime }$ 和 ${\alpha }_{k}^{\prime \prime }$ 按如下方式确定:

${\alpha }_{k}^{\prime }$ 从 $f\left( {{\underline{\mathbf{x}}}^{k} + \alpha {\underline{\mathbf{d}}}^{k}}\right)  = \min !,\alpha  > 0$ 确定.

$$
{\alpha }_{k}^{\prime \prime } = \left\{  {\alpha  \in  \mathbb{R} : {\underline{\mathbf{x}}}^{k} + \alpha {\underline{\mathbf{d}}}^{k} \in  M}\right\}  . \tag{18.97}
$$

然后, 我们得到

$$
{\alpha }_{k} = \min \left\{  {{\alpha }_{k}^{\prime },{\alpha }_{k}^{\prime \prime }}\right\}  . \tag{18.98}
$$

如果在某一步 $k$ 没有可行方向 ${\underline{\mathbf{d}}}^{k}$ ,则 ${\underline{\mathbf{x}}}^{k}$ 是平稳点.

##### 18.2.7.1 可行方向方法

###### 1. 方向搜索程序

点 ${\underline{x}}^{k}$ 处的可行下降方向 ${\underline{d}}^{k}$ 可以通过求解下列优化问题予以确定:

$$
\sigma  = \min ! \tag{18.99}
$$

$$
\nabla {g}_{i}{\left( {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\underline{\mathbf{d}} \leq  \sigma ,\;i \in  {I}_{0}\left( {\underline{\mathbf{x}}}^{k}\right) , \tag{18.100a}
$$

$$
\nabla f{\left( {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\underline{\mathbf{d}} \leq  \sigma , \tag{18.100b}
$$

$$
\parallel \underline{\mathbf{d}}\parallel  \leq  1 \tag{18.100c}
$$

如果 $\sigma  < 0$ ,则 (18.100a) 确保该方向搜索程序结果 $\underline{d} = {\underline{d}}^{k}$ 的可行性,而 (18.100b) 确保 ${\underline{\mathbf{d}}}^{k}$ 的下降性质. 根据规格化条件 (18.100c),该方向搜索程序所得可行集是有界的. 如果 $\sigma  = 0$ ,则 ${\underline{x}}^{k}$ 是平稳点,因为在 ${\underline{x}}^{k}$ 没有可行的下降方向.

由(18.100a,18.100b,18.100c)定义的方向搜索程序有可能引起序列 $\left\{  {\underline{\mathbf{x}}}^{k}\right\}$ 的锯齿形行为,而为避免这样的行为发生,只需将标号集 ${I}_{0}\left( {\underline{\mathbf{x}}}^{k}\right)$ 代之以

$$
{I}_{{\varepsilon }_{k}}\left( {\underline{\mathbf{x}}}^{k}\right)  = \left\{  {i \in  \{ 1,\cdots , m\}  :  - {\varepsilon }_{k} \leq  {g}_{i}\left( {\underline{\mathbf{x}}}^{k}\right)  \leq  0}\right\}  ,\;{\varepsilon }_{k} \geq  0, \tag{18.101}
$$

即代之以在 ${\underline{x}}^{k}$ 处的所谓 ${\varepsilon }_{k}$ 主动约束. 于是从 ${\underline{x}}^{k}$ 出发的局部下降方向被排除,并且越来越接近由 ${\varepsilon }_{k}$ 主动约束组成的 $M$ 的边界 (图 18.7).

![01936af3-1230-7a0e-9a4a-8542777881ce_38_441_1206_769_142_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_38_441_1206_769_142_0.jpg)

图 18.7

如果 $\sigma  = 0$ 是(18.100a,18.100b,18.100c)在这样修正后的解,那么仅当 ${I}_{0}\left( {\underline{\mathbf{x}}}^{k}\right)  = {I}_{{\varepsilon }_{k}}\left( {\underline{\mathbf{x}}}^{k}\right)$ 时, ${\underline{\mathbf{x}}}^{k}$ 是平稳点. 否则, ${\varepsilon }_{k}$ 必须减少,从而方向搜索程序必须重复下去.

###### 2. 线性约束的特殊情形

如果 ${g}_{i}\left( \underline{\mathbf{x}}\right)$ 是线性的,即 ${g}_{i}\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{a}}}_{i}^{\mathrm{T}}\underline{\mathbf{x}} - {b}_{i}$ ,则可以建立一种比较简单的方向搜索程序:

$$
\sigma  = \nabla f{\left( {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\underline{\mathbf{d}} = \min !, \tag{18.102}
$$

其中

$$
\nabla {\underline{\mathbf{a}}}_{i}^{\mathrm{T}}\underline{\mathbf{d}} \leq  0,\;i \in  {I}_{0}\left( {\underline{\mathbf{x}}}^{k}\right) \;\text{ 或 }\;i \in  {I}_{{\varepsilon }_{k}}\left( {\underline{\mathbf{x}}}^{k}\right) , \tag{18.103a}
$$

$$
\parallel \underline{\mathbf{d}}\parallel  \leq  1 \tag{18.103b}
$$

选择不同范数 $\parallel \underline{\mathbf{d}}\parallel  = \max \left\{  \left| {d}_{i}\right| \right\}   \leq  1$ 或 $\parallel \underline{\mathbf{d}}\parallel  = \sqrt{{\underline{\mathbf{d}}}^{\mathrm{T}}\underline{\mathbf{d}}} \leq  1$ 的影响示于图 18.8(a), (b).

![01936af3-1230-7a0e-9a4a-8542777881ce_39_573_491_498_243_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_39_573_491_498_243_0.jpg)

图 18.8

在某种意义上,范数 $\parallel \underline{\mathbf{d}}\parallel  = \parallel \underline{\mathbf{d}}{\parallel }_{2} = \sqrt{{\underline{\mathbf{d}}}^{\mathrm{T}}\underline{\mathbf{d}}}$ 是最佳选择,因为方向搜索程序所得到的方向 ${\underline{\mathbf{d}}}^{k}$ 与 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 形成最小夹角. 在这种情形下,方向搜索程序并不是线性的,从而要求更大的计算量. 如果选择范数 $\parallel \underline{\mathbf{d}}\parallel  = \parallel \underline{\mathbf{d}}{\parallel }_{\infty } = \max \left\{  \left| {d}_{i}\right| \right\}   \leq  1$ ,则得到一组线性约束 $- 1 \leq  {d}_{i} \leq  1\left( {i = 1,\cdots , n}\right)$ ,从而方向搜索程序,例如,可以通过单纯形法求解.

为了确保这种可行方向方法对于二次优化问题 $f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{C}\underline{\mathbf{x}} + {\underline{\mathbf{p}}}^{\mathrm{T}}\underline{\mathbf{x}} = \min !$ , $A\underline{x} \leq  \underline{b}$ ,能够在有穷步内得到解决,可以利用如下的共轭条件来实施方向搜索程序: 如果在某一步成立 ${\alpha }_{k - 1} = {\alpha }_{k - 1}^{\prime }$ ,即 ${\underline{x}}^{k}$ 是一 “内” 点,则在方向搜索程序中加上

条件

$$
{\underline{\mathbf{d}}}^{k - {1}^{\mathrm{T}}}\mathbf{C}\underline{\mathbf{d}} = 0. \tag{18.104}
$$

此外,前面各步骤中相应的的条件均保留不变. 如果在往后的某一步有 ${\alpha }_{k} = {\alpha }_{k}^{\prime \prime }$ ,则条件 (18.104) 就去掉.

$f\left( \underline{\mathbf{x}}\right)  = {x}_{1}^{2} + 4{x}_{2}^{2} - {10}{x}_{1} - {32}{x}_{2} = \min !,{g}_{1}\left( \underline{\mathbf{x}}\right)  =  - {x}_{1} \leq  0,{g}_{2}\left( \underline{\mathbf{x}}\right)  =  - {x}_{2} \leq  0,$ ${g}_{3}\left( \underline{\mathbf{x}}\right)  = {x}_{1} + 2{x}_{2} - 7 \leq  0,\;{g}_{4}\left( \underline{\mathbf{x}}\right)  = 2{x}_{1} + {x}_{2} - 8 \leq  0.$

第 1 步: 从 ${\underline{\mathbf{x}}}^{1} = {\left( 3,0\right) }^{\mathrm{T}}$ 出发, $\nabla f\left( {\underline{\mathbf{x}}}^{1}\right)  = {\left( -4, - {32}\right) }^{\mathrm{T}},\;{I}_{0}\left( {\underline{\mathbf{x}}}^{1}\right)  = \{ 2\}$ .

方向搜索程序: $\left\{  \begin{array}{l}  - 4{d}_{1} - {32}{d}_{2} = \min ! \\   - {d}_{2} \leq  0,\parallel \underline{\mathbf{d}}{\parallel }_{\infty } \leq  1 \end{array}\right\}   \Rightarrow  {\underline{\mathbf{d}}}^{1} = {\left( 1,1\right) }^{\mathrm{T}}$ .

最小化常数: ${\alpha }_{k}^{\prime } =  - \frac{{\underline{\mathbf{d}}}^{{k}^{\mathrm{T}}}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right) }{2{\underline{\mathbf{d}}}^{{k}^{\mathrm{T}}}\mathbf{C}{\underline{\mathbf{d}}}^{k}}$ ,其中 $\mathbf{C} = \left( \begin{array}{ll} 1 & 0 \\  0 & 4 \end{array}\right)$ .

最大可行步长: ${\alpha }_{k}^{\prime \prime } = \min \left\{  {\frac{-{g}_{i}\left( {\underline{\mathbf{x}}}^{k}\right) }{{\underline{\mathbf{a}}}_{i}^{\mathrm{T}}{\underline{\mathbf{d}}}^{k}} : i\text{满足}{\underline{\mathbf{a}}}_{i}^{\mathrm{T}}{\underline{\mathbf{d}}}^{k} > 0}\right\}  ,{\alpha }_{1}^{\prime } = \frac{18}{5},{\alpha }_{1}^{\prime \prime } =$$\frac{2}{3} \Rightarrow  {\alpha }_{1} = \min \left\{  {\frac{18}{5},\frac{2}{3}}\right\}   = \frac{2}{3},{\underline{\mathbf{x}}}^{2} = {\left( \frac{11}{3},\frac{2}{3}\right) }^{\mathrm{T}}.$

第 2 步: $\nabla f\left( {\underline{\mathbf{x}}}^{2}\right)  = {\left( -\frac{8}{3}, - \frac{80}{3}\right) }^{\mathrm{T}},\;{I}_{0}\left( {\underline{\mathbf{x}}}^{2}\right)  = \{ 4\}$ .

方向搜索程序: $\left\{  \begin{matrix}  - \frac{8}{3}{d}_{1} - \frac{80}{3}{d}_{2} = \min ! \\  2{d}_{1} + {d}_{2} \leq  0,\parallel \underline{\mathbf{d}}{\parallel }_{\infty } \leq  1 \end{matrix}\right\}   \Rightarrow  {\underline{\mathbf{d}}}^{2} = {\left( -\frac{1}{2},1\right) }^{\mathrm{T}},{\alpha }_{2}^{\prime } =$

$$
\frac{152}{51},{\alpha }_{2}^{\prime \prime } = \frac{4}{3} \Rightarrow  {\alpha }_{2} = \frac{4}{3},{\underline{x}}^{3} = {\left( 3,2\right) }^{\mathrm{T}}.
$$

第 3 步: $\nabla f\left( {\underline{\mathbf{x}}}^{3}\right)  = {\left( -4, - {16}\right) }^{\mathrm{T}},\;{I}_{0}\left( {\underline{\mathbf{x}}}^{3}\right)  = \{ 3,4\}$ .

方向搜索程序: $\left\{  \begin{matrix}  - 4{d}_{1} - {16}{d}_{2} = \min ! \\  {d}_{1} + 2{d}_{2} \leq  0,2{d}_{1} + {d}_{2} \leq  0,\parallel \underline{\mathbf{d}}{\parallel }_{\infty } \leq  1 \end{matrix}\right\}   \Rightarrow  {\underline{d}}^{3} =$

${\left( -1,\frac{1}{2}\right) }^{\mathrm{T}},{\alpha }_{3}^{\prime } = 1,{\alpha }_{3}^{\prime \prime } = 3 \Rightarrow  {\alpha }_{3} = 1,{\underline{\mathbf{x}}}^{4} = {\left( 2,\frac{5}{2}\right) }^{\mathrm{T}}.$

接下来的方向搜索程序结果是 $\sigma  = 0$ ,从而极小点是 ${\underline{x}}^{ * } = {\underline{x}}^{4}$ (图 18.9).

![01936af3-1230-7a0e-9a4a-8542777881ce_40_619_809_405_362_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_40_619_809_405_362_0.jpg)

图 18.9

##### 18.2.7.2 梯度投影方法

###### 1. 问题的提法和求解原理

假定给定凸优化问题

$$
f\left( \underline{\mathbf{x}}\right)  = \min !\text{,其中}\underline{\mathbf{x}}\text{满足}{\underline{\mathbf{a}}}_{i}^{\mathrm{T}}\underline{\mathbf{x}} \leq  {b}_{i}, i = 1,\cdots , m\text{.} \tag{18.105}
$$

点 ${\underline{\mathbf{x}}}^{k} \in  M$ 处的可行下降方向 ${\underline{\mathbf{d}}}^{k}$ 按如下方式确定:

如果 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 是可行方向,则选择 ${\underline{\mathbf{d}}}^{k} =  - \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ . 否则, ${\underline{\mathbf{x}}}^{k}$ 在 $M$ 的边界上,并且 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 指向 $M$ 外. 向量 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 通过一个线性映射投影到 $M$ 边界的一个线性流形上,该流形由 ${\underline{x}}^{k}$ 处主动约束的子集确定. 图 18.10(a) 表示投影到一棱边,而图 18.10(b) 表示投影到一个面上. 假定非降秩,即如果对于每个 $\underline{\mathbf{x}} \in  {\mathbb{R}}^{n}$ , 诸向量 ${\underline{\mathbf{a}}}_{i}, i \in  {I}_{0}\left( \underline{\mathbf{x}}\right)$ 是线性无关的,则

$$
{\underline{\mathbf{d}}}^{k} =  - {\mathbf{P}}_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  =  - \left( {I - {\mathbf{A}}_{k}^{\mathrm{T}}{\left( {\mathbf{A}}_{k}{\mathbf{A}}_{k}^{\mathrm{T}}\right) }^{-1}{A}_{k}}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  \tag{18.106}
$$

就给出这样的投影. 这里 ${\mathbf{A}}_{k}$ 由这样一些向量 ${\underline{\mathbf{a}}}_{i}$ 组成,其相应的约束构成一个子流形,而 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 正好投影到这个子流形.

![01936af3-1230-7a0e-9a4a-8542777881ce_41_463_492_718_223_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_41_463_492_718_223_0.jpg)

图 18.10

###### 2. 算法

梯度投影法由如下几个步骤组成: 从 ${\underline{x}}^{1} \in  M$ 开始,按照如下方式从 $k = 1$ 出发依次进行计算.

I: 如果 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 是可行方向,则代入 ${\underline{\mathbf{d}}}^{k} =  - \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ ,并从第 III 步继续. 否则,从向量 ${\underline{\mathbf{a}}}_{i}, i \in  {I}_{0}\left( {\underline{\mathbf{x}}}^{k}\right)$ 构造矩阵 ${\mathbf{A}}_{k}$ ,然后从第 II 步继续.

II: 代入 ${\underline{\mathbf{d}}}^{k} =  - \left( {\mathbf{I} - {\mathbf{A}}_{k}^{\mathrm{T}}{\left( {\mathbf{A}}_{k}{\mathbf{A}}_{k}^{\mathrm{T}}\right) }^{-1}{\mathbf{A}}_{k}}\right) \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ . 如果 ${\underline{\mathbf{d}}}^{k} \neq  \underline{\mathbf{0}}$ ,则从第 III 步继续. 如果 ${\underline{\mathbf{d}}}^{k} = \underline{\mathbf{0}}$ ,并且 $\underline{\mathbf{u}} =  - {\left( {\mathbf{A}}_{k}{\mathbf{A}}_{k}^{\mathrm{T}}\right) }^{-1}{\mathbf{A}}_{k}\nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  \geq  \underline{\mathbf{0}}$ ,那么 ${\underline{\mathbf{x}}}^{k}$ 是极小点. 局部库恩-塔克条件 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)  = \mathop{\sum }\limits_{{i \in  {I}_{0}\left( {\underline{\mathbf{x}}}^{k}\right) }}{u}_{i}{\underline{\mathbf{a}}}_{i} = {\mathbf{A}}_{k}^{\mathrm{T}}\underline{\mathbf{u}}$ 显然满足.

如果 $\underline{\mathbf{u}} \ngeq  \underline{\mathbf{0}}$ ,则选择一个 $i,{\underline{\mathbf{u}}}_{i} < 0$ ,删除 ${\mathbf{A}}^{k}$ 的第 $i$ 行,并继续第 II 步.

III: 计算 ${\alpha }_{k}$ 和 ${\underline{\mathbf{x}}}^{k + 1} = {\underline{\mathbf{x}}}^{k} + {\alpha }_{k}{\underline{\mathbf{d}}}^{k}$ ,并让 $k = k + 1$ 回到第 I 步继续.

###### 3. 关于算法的注释

如果 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 不是可行方向,则这个向量被映到包含 ${\underline{\mathbf{x}}}^{k}$ 的最小维子流形上. 如果 ${\underline{\mathbf{d}}}^{k} = \underline{\mathbf{0}}$ ,则 $- \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 垂直于这个子流形. 如果 $\underline{\mathbf{u}} \geq  \underline{\mathbf{0}}$ 不成立,则该子流形的维数通过删去一个主动约束而增加一维,从而有可能出现 ${\underline{\mathbf{d}}}^{k} \neq  \underline{\mathbf{0}}$ (图 18.10(b))(投影到一个 (侧) 面). 由于 ${\mathbf{A}}_{k}$ 往往是从 ${\mathbf{A}}_{k - 1}$ 通过增加或删掉一行而得到,故 ${\left( {\mathbf{A}}_{k}{\mathbf{A}}_{k}^{\mathrm{T}}\right) }^{-1}$ 的计算可以利用 ${\left( {\mathbf{A}}_{k - 1}{\mathbf{A}}_{k - 1}^{\mathrm{T}}\right) }^{-1}$ 而得到简化.

- 本页 2. 中的例子问题的求解.

第 1 步: ${\underline{\mathbf{x}}}^{1} = {\left( 3,0\right) }^{\mathrm{T}}$ .

I: $\nabla f\left( {\underline{\mathbf{x}}}^{1}\right)  = {\left( -4, - {32}\right) }^{\mathrm{T}}, - \nabla f\left( {\underline{\mathbf{x}}}^{k}\right)$ 是可行的, ${\underline{\mathbf{d}}}^{1} = {\left( 4,{32}\right) }^{\mathrm{T}}$ .

III: 如同上例,确定步长为 ${\alpha }_{1} = \frac{1}{2},{\underline{x}}^{2} = {\left( \frac{16}{5},\frac{8}{5}\right) }^{\mathrm{T}}$ .

第 2 步:

I: $\nabla f\left( {\underline{\mathbf{x}}}^{2}\right)  = {\left( -\frac{18}{5}, - \frac{96}{5}\right) }^{\mathrm{T}}$ (不可行), ${I}_{0}\left( {\underline{\mathbf{x}}}^{2}\right)  = \{ 4\} ,{\mathbf{A}}_{2} = \left( \begin{array}{ll} 2 & 1 \end{array}\right)$ .

II: ${\mathbf{P}}_{2} = \frac{1}{5}\left( \begin{matrix} 1 &  - 2 \\   - 2 & 4 \end{matrix}\right) ,{\underline{\mathbf{d}}}^{2} = \left( {-\frac{8}{25},\frac{16}{25}}\right)  \neq  \underline{\mathbf{0}}$ .

III: ${\alpha }_{2} = \frac{5}{8},{\underline{\mathbf{x}}}^{3} = {\left( 3,2\right) }^{\mathrm{T}}$ .

第 3 步:

$$
\text{I:}\nabla f\left( {\underline{\mathbf{x}}}^{3}\right)  = {\left( -4, - {16}\right) }^{\mathrm{T}}\text{(不可行),}{I}_{0}\left( {\underline{\mathbf{x}}}^{3}\right)  = \{ 3,4\} ,{\mathbf{A}}_{3} = \left( \begin{array}{ll} 1 & 2 \\  2 & 1 \end{array}\right) \text{.}
$$

$$
\text{II:}{\mathbf{P}}_{3} = \left( \begin{array}{ll} 0 & 0 \\  0 & 0 \end{array}\right) ,{\underline{\mathbf{d}}}^{3} = {\left( 0,0\right) }^{\mathrm{T}},\underline{\mathbf{u}} = {\left( \frac{28}{3}, - \frac{8}{3}\right) }^{\mathrm{T}},{u}_{2} < 0 : {\mathbf{A}}_{3} = \left( \begin{array}{ll} 1 & 2 \end{array}\right) \text{.}
$$

$$
\text{II:}{\mathbf{P}}_{3} = \frac{1}{5}\left( \begin{matrix} 4 &  - 2 \\   - 2 & 1 \end{matrix}\right) ,{\underline{\mathbf{d}}}^{3} = {\left( -\frac{16}{5},\frac{8}{5}\right) }^{\mathrm{T}}\text{.}
$$

$$
\text{III:}{\alpha }_{3} = \frac{5}{16},{\underline{\mathbf{x}}}^{4} = {\left( 2,\frac{5}{2}\right) }^{\mathrm{T}}\text{.}
$$

第 4 步:

I: $\nabla f\left( {\underline{\mathbf{x}}}^{4}\right)  = {\left( -6, - {12}\right) }^{\mathrm{T}}$ (不可行), ${I}_{0}\left( {\underline{\mathbf{x}}}^{4}\right)  = \{ 3\} ,{\mathbf{A}}_{4} = {\mathbf{A}}_{3}$ .

II: ${\mathbf{P}}_{4} = {\mathbf{P}}_{3},{\underline{\mathbf{d}}}^{4} = {\left( 0,0\right) }^{\mathrm{T}}, u = 6 \geq  0$ .

由此可知, ${\underline{x}}^{4}$ 是极小点.

#### 18.2.8 罚函数法和障碍函数法

这些方法的基本原理是通过修正目标函数将约束优化问题转换成一列无约束优化问题. 修正后的问题, 例如, 可以通过 18.2.5 给出的方法求解. 通过适当构造修正的目标函数, 这一修正问题解点列的每个聚点都是原问题的一个解.

##### 18.2.8.1 罚函数法

问题

$$
f\left( \underline{\mathbf{x}}\right)  = \min !,\;\text{ 约束条件为 }{g}_{i}\left( \underline{\mathbf{x}}\right)  \leq  0\left( {i = 1,\cdots , m}\right)  \tag{18.107}
$$

用如下一列无约束问题代替:

$$
H\left( {\underline{\mathbf{x}},{p}_{k}}\right)  = f\left( \underline{\mathbf{x}}\right)  + {p}_{k}S\left( \underline{\mathbf{x}}\right)  = \min !,\;\text{ 其中 }\underline{\mathbf{x}} \in  {\mathbb{R}}^{n},{p}_{k} > 0\left( {k = 1,2,\cdots }\right)  \tag{18.108}
$$

这里 ${p}_{k}$ 是正参数,而 $S\left( \underline{\mathbf{x}}\right)$ 满足

$$
S\left( \underline{\mathbf{x}}\right)  = \left\{  \begin{array}{ll}  = 0, & \underline{\mathbf{x}} \in  M, \\   > 0, & \underline{\mathbf{x}} \notin  M, \end{array}\right.  \tag{18.109}
$$

即让可行集 $M$ 用一 “补偿” 项 ${p}_{k}S\left( \underline{x}\right)$ 进行惩罚. 问题 (18.108) 通过一列趋于无穷的罚参数 ${p}_{k}$ 来求解. 于是

$$
\mathop{\lim }\limits_{{k \rightarrow  \infty }}H\left( {\underline{\mathbf{x}},{p}_{k}}\right)  = f\left( \underline{\mathbf{x}}\right) ,\;\underline{\mathbf{x}} \in  M. \tag{18.110}
$$

如果 ${\underline{\mathbf{x}}}^{k}$ 是第 $k$ 个罚问题的解,则

$$
H\left( {\underline{\mathbf{x}},{p}_{k}}\right)  \geq  H\left( {{\underline{\mathbf{x}}}^{k - 1},{p}_{k - 1}}\right) ,\;f\left( {\underline{\mathbf{x}}}^{k}\right)  \geq  f\left( {\underline{\mathbf{x}}}^{k - 1}\right) , \tag{18.111}
$$

并且序列 $\left\{  {\underline{x}}^{k}\right\}$ 的每个聚点 ${\underline{x}}^{ * }$ 都是 (18.107) 的解. 如果 ${\underline{x}}^{k} \in  M$ ,则 ${\underline{x}}^{k}$ 是原问题的解.

例如,如下函数是 $S\left( \underline{\mathbf{x}}\right)$ 的合适的选择:

$$
S\left( \underline{\mathbf{x}}\right)  = \mathop{\max }\limits^{r}\left\{  {0,{g}_{1}\left( \underline{\mathbf{x}}\right) ,\cdots ,{g}_{m}\left( \underline{\mathbf{x}}\right) }\right\}  \;\left( {r = 1,2,\cdots }\right)  \tag{18.112a}
$$

或

$$
S\left( \underline{\mathbf{x}}\right)  = \mathop{\sum }\limits_{{i = 1}}^{m}\mathop{\max }\limits^{r}\left\{  {0,{g}_{i}\left( \underline{\mathbf{x}}\right) }\right\}  \;\left( {r = 1,2,\cdots }\right) . \tag{18.112b}
$$

如果函数 $f\left( \underline{\mathbf{x}}\right)$ 和 ${g}_{i}\left( \underline{\mathbf{x}}\right)$ 可微,那么当 $r > 1$ 时,罚函数 $H\left( {\underline{\mathbf{x}},{p}_{k}}\right)$ 在 $M$ 的边界上也可微, 从而可以使用解析解求解辅助问题 (18.108).

图 18.11 为罚函数方法的示意图.

![01936af3-1230-7a0e-9a4a-8542777881ce_43_598_850_446_335_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_43_598_850_446_335_0.jpg)

图 18.11

$f\left( \underline{\mathbf{x}}\right)  = {x}_{1}^{2} + {x}_{2}^{2} = \min !,\;{x}_{1} + {x}_{2} \geq  1,\;H\left( {\underline{\mathbf{x}},{p}_{k}}\right)  = {x}_{1}^{2} + {x}_{2}^{2} + {p}_{k}\mathop{\max }\limits^{2}\{ 0,1 -$$\left. {{x}_{1} - {x}_{2}}\right\}$ . 最优性必要条件是

$$
\nabla H\left( {\underline{\mathbf{x}},{p}_{k}}\right)  = \left( \begin{array}{l} 2{x}_{1} - 2{p}_{k}\max \left\{  {0,1 - {x}_{1} - {x}_{2}}\right\}  \\  2{x}_{2} - 2{p}_{k}\max \left\{  {0,1 - {x}_{1} - {x}_{2}}\right\}   \end{array}\right)  = \left( \begin{array}{l} 0 \\  0 \end{array}\right) .
$$

这里 $H$ 的梯度是相对于 $\underline{x}$ 计算的. 两个方程相减得到 ${x}_{1} = {x}_{2}$ . 方程 $2{x}_{1} -$ $2{p}_{k}\max \left\{  {0,1 - 2{x}_{1}}\right\}   = 0$ 有唯一解 ${x}_{1}^{k} = {x}_{2}^{k} = \frac{{p}_{k}}{1 + 2{p}_{k}}$ . 由此让 $k \in  \infty$ 得到解${x}_{1}^{ * } = {x}_{2}^{ * } = \mathop{\lim }\limits_{{k \rightarrow  \infty }}\frac{{p}_{k}}{1 + 2{p}_{k}} = \frac{1}{2}.$

##### 18.2.8.2 障碍函数法

在障碍函数法中, 考虑如下一列修正问题:

$$
H\left( {\underline{\mathbf{x}},{q}_{k}}\right)  = f\left( \underline{\mathbf{x}}\right)  + {q}_{k}B\left( \underline{\mathbf{x}}\right)  = \min !,\;{q}_{k} > 0. \tag{18.113}
$$

这里的项 ${q}_{k}B\left( \underline{x}\right)$ 是为了避免解偏离可行集 $M$ ,因为目标函数在接近 $M$ 的边界时会无限增长. 正则性条件

$$
{M}^{0} = \left\{  {\underline{\mathbf{x}} \in  M : {g}_{i}\left( \underline{\mathbf{x}}\right)  < 0, i = 1,\cdots , m}\right\}   \neq  \varnothing ,\;\overline{{M}^{0}} = M \tag{18.114}
$$

必须满足,即 $M$ 的内点必须非空,并且要求从内部可以逼近到任意边界点,即 ${M}^{0}$ 的闭包是 $M$ . 函数 $B\left( \underline{x}\right)$ 要求在 ${M}^{0}$ 上连续,而在边界上增加到无穷大. 修正问题 (18.113) 通过一列趋于零的障碍参数 ${q}_{k}$ 来求解. 设 ${\underline{x}}^{k}$ 是第 $k$ 个问题 (18.113) 的解, 则

$$
f\left( {\underline{\mathbf{x}}}^{k}\right)  \leq  f\left( {\underline{\mathbf{x}}}^{k - 1}\right) , \tag{18.115}
$$

并且序列 $\left\{  {\underline{\mathbf{x}}}^{k}\right\}$ 的每个聚点都是 (18.107) 的解. 图 18.12 为障碍函数法的示意图. 例如, 函数

$$
B\left( \underline{\mathbf{x}}\right)  =  - \mathop{\sum }\limits_{{i = 1}}^{m} - \ln \left( {-{g}_{i}\left( \underline{\mathbf{x}}\right) }\right) ,\;\underline{\mathbf{x}} \in  {M}^{0} \tag{18.116a}
$$

或

$$
B\left( \underline{\mathbf{x}}\right)  =  - \mathop{\sum }\limits_{{i = 1}}^{m}\frac{1}{{\left\lbrack  -{g}_{i}\left( \underline{\mathbf{x}}\right) \right\rbrack  }^{r}}\;\left( {r = 1,2,\cdots }\right) ,\;\underline{\mathbf{x}} \in  {M}^{0} \tag{18.116b}
$$

是 $B\left( \underline{x}\right)$ 的合适的选择.

![01936af3-1230-7a0e-9a4a-8542777881ce_44_616_1011_413_349_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_44_616_1011_413_349_0.jpg)

图 18.12

$f\left( \underline{\mathbf{x}}\right)  = {x}_{1}^{2} + {x}_{2}^{2} = \min !,{x}_{1} + {x}_{2} \geq  1, H\left( {\underline{\mathbf{x}},{q}_{k}}\right)  = {x}_{1}^{2} + {x}_{2}^{2} + {q}_{k}\left( {-\ln \left( {{x}_{1} + {x}_{2} - 1}\right) }\right) ,$${x}_{1} + {x}_{2} > 1,\nabla H\left( {\underline{\mathbf{x}},{q}_{k}}\right)  = \left( \begin{matrix} 2{x}_{1} - {q}_{k}\frac{1}{{x}_{1} - {x}_{2} - 1} \\  2{x}_{2} - {q}_{k}\frac{1}{{x}_{1} + {x}_{2} - 1} \end{matrix}\right)  = \left( \begin{array}{l} 0 \\  0 \end{array}\right) ,{x}_{1} + {x}_{2} > 1$ . 这里 $H$ 的梯度是相对于 $\underline{x}$ 的. 两个方程相减得到 ${x}_{1} = {x}_{2},2{x}_{1} - {q}_{k}\frac{1}{2{x}_{1} - 1} = 0,{x}_{1} > \frac{1}{2} \Rightarrow  {x}_{1}^{2} - \frac{{x}_{1}}{2} - \frac{{q}_{k}}{4} =$$0,{x}_{1} > \frac{1}{2},{x}_{1}^{k} = {x}_{2}^{k} = \frac{1}{4} + \sqrt{\frac{1}{16} + \frac{{q}_{k}}{4}}, k \rightarrow  \infty ,{q}_{k} \rightarrow  0 : {x}_{1}^{ * } = {x}_{2}^{ * } = \frac{1}{2}.$

问题 (18.108) 和 (18.113) 第 $k$ 步的解并不依赖于前几步的解. 应用高阶罚函数和较小的障碍参数往往会引起 (18.108) 和 (18.113) 的数值解的收敛性问题, 例如,特别是在 (18.2.4) 的方法中,如果没有好的初始近似的话. 使用第 $k$ 个问题的解作为第 $k + 1$ 个问题的初始解,收敛行为有可能得到改善.

#### 18.2.9 割平面法

###### 1. 问题的提法和求解原理

设考虑有界区域 $M \subset  {\mathbb{R}}^{n}$ 上的问题

$$
f\left( \underline{\mathbf{x}}\right)  = {\underline{\mathbf{c}}}^{\mathrm{T}}\underline{\mathbf{x}} = \min !,\;\underline{\mathbf{c}} \in  {\mathbb{R}}^{n}, \tag{18.117}
$$

这里 $M$ 由凸函数 ${g}_{i}\left( \underline{\mathbf{x}}\right) \left( {i = 1,\cdots , m}\right)$ 以约束形式 ${g}_{i}\left( \underline{\mathbf{x}}\right)  \leq  0$ 给出. 相应于非线性但凸的目标函数 $f\left( \underline{x}\right)$ 的规划问题就可以转换成这种形式,为此只要把

$$
f\left( \underline{\mathbf{x}}\right)  - {x}_{n + 1} \leq  0,\;{\underline{\mathbf{x}}}_{n + 1} \in  \mathbb{R} \tag{18.118}
$$

看作另一个约束,并且在约束 ${\bar{g}}_{i}\left( \underline{\mathbf{x}}\right)  = {g}_{i}\left( \underline{\mathbf{x}}\right)  \leq  0$ 之下求解问题:

$$
\bar{f}\left( \overline{\underline{\mathbf{x}}}\right)  = {x}_{n + 1} = \min !,\;\forall \overline{\underline{\mathbf{x}}} = \left( {\underline{\mathbf{x}},{x}_{n + 1}}\right)  \in  {\mathbb{R}}^{n + 1}. \tag{18.119}
$$

这个方法的基本想法是通过极小点 ${\underline{x}}^{ * }$ 邻域中一凸多面体,迭代线性逼近 $M$ ,从而原规划问题转化成一列线性规划问题.

首先, 确定凸多面体

$$
{P}_{1} = \left\{  {\underline{\mathbf{x}} \in  {\mathbb{R}}^{n} : {\underline{\mathbf{a}}}_{i}^{\mathrm{T}}\underline{\mathbf{x}} \leq  {b}_{i}, i = 1,\cdots , s}\right\}  . \tag{18.120}
$$

由线性规划问题

$$
f\left( \underline{\mathbf{x}}\right)  = \min !,\;\underline{\mathbf{x}} \in  {P}_{1} \tag{18.121}
$$

相对于 $f\left( \underline{\mathbf{x}}\right)$ 确定 ${P}_{1}$ 的最优极端点 ${\underline{\mathbf{x}}}^{1}$ . 如果 ${\underline{\mathbf{x}}}^{1} \in  M$ ,则就找到原问题的最优解. 否则,确定将点 ${\underline{\mathbf{x}}}^{1}$ 和 $M$ 分离的一超平面: ${H}_{1} = \left\{  {\underline{\mathbf{x}} : {\underline{\mathbf{a}}}_{s + 1}^{\mathrm{T}}\underline{\mathbf{x}} = {b}_{s + 1},{\underline{\mathbf{a}}}_{s + 1}^{\mathrm{T}}{\underline{\mathbf{x}}}^{1} > {b}_{s + 1}}\right\}$ , 于是新的多面体包含

$$
{P}_{2} = \left\{  {\underline{\mathbf{x}} \in  {P}_{1} : {\underline{\mathbf{a}}}_{s + 1}^{\mathrm{T}}\underline{\mathbf{x}} \leq  {b}_{s + 1}}\right\}  . \tag{18.122}
$$

图 18.13 为割平面法的示意图.

![01936af3-1230-7a0e-9a4a-8542777881ce_45_604_1521_434_226_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_45_604_1521_434_226_0.jpg)

图 18.13

###### 2. 凯利 (Kelley) 方法

不同方法之间的区别在于分离平面的选取. 采用凯利方法, ${H}_{k}$ 的选取方法如下: 选择一标号 ${j}_{k}$ 使得

$$
{g}_{{j}_{k}}\left( {\underline{\mathbf{x}}}^{k}\right)  = \max \left\{  {{g}_{i}\left( {\underline{\mathbf{x}}}^{k}\right)  : i = 1,\cdots , m}\right\}  . \tag{18.123}
$$

函数 ${g}_{{j}_{k}}\left( \underline{\mathbf{x}}\right)$ 在 $\underline{\mathbf{x}} = {\underline{\mathbf{x}}}^{k}$ 的切平面为

$$
T\left( \underline{\mathbf{x}}\right)  = {g}_{{j}_{k}}\left( {\underline{\mathbf{x}}}^{k}\right)  + {\left( \underline{\mathbf{x}} - {\underline{\mathbf{x}}}^{k}\right) }^{\mathrm{T}}\nabla {g}_{{j}_{k}}\left( {\underline{\mathbf{x}}}^{k}\right) . \tag{18.124}
$$

超平面 ${H}_{k} = \left\{  {\underline{\mathbf{x}} \in  {\mathbb{R}}^{n} : T\left( \underline{\mathbf{x}}\right)  = 0}\right\}$ 把点 ${\underline{\mathbf{x}}}^{k}$ 与所有满足 ${g}_{{j}_{k}}\left( \underline{\mathbf{x}}\right)  \leq  0$ 的点 $\underline{\mathbf{x}}$ 分离开. 于是,对于第 $k + 1$ 个线性规划问题,增加一个约束条件 $T\left( \underline{\mathbf{x}}\right)  \leq  0$ . 序列 $\left\{  {\underline{\mathbf{x}}}^{k}\right\}$ 的每个聚点 ${\underline{x}}^{ * }$ 都是原问题的一个极小点. 实际应用表明,这种方法的收敛速度较低. 此外, 约束的数量总是不断增加.

### 18.3 离散动态规划

#### 18.3.1 离散动态决策模型

很大一类优化问题可以用动态规划法求解. 我们把这样的优化问题看作自然地或形式上按时间行进的过程, 并且它由依赖时间的决策所控制. 如果这一过程可以分解成有穷或可数无穷多步,则它称为离散动态规划. 本节仅讨论 $n$ 级离散过程.

##### 18.3.1.1 $n$ 级决策过程

一个 $n$ 级过程 $P$ 从 0 级初始状态 ${\underline{\mathbf{x}}}_{a} = {\underline{\mathbf{x}}}_{0}$ 开始,通过中间状态 ${\underline{\mathbf{x}}}_{1},{\underline{\mathbf{x}}}_{2},\cdots$ , ${\underline{x}}_{n - 1}$ 直到进入最终状态 ${\underline{x}}_{n} = {\underline{x}}_{e} \in  {X}_{e} \subseteq  {\mathbb{R}}_{m}$ . 状态向量 ${\underline{x}}_{j}$ 在状态空间 ${X}_{j} \subseteq  {\mathbb{R}}_{m}$ 中. 为了将状态 ${\underline{x}}_{j - 1}$ 驱动到状态 ${\underline{x}}_{j}$ ,要求找一个决策 ${\underline{u}}_{j}$ . 在状态 ${\underline{x}}_{j - 1}$ 处所有可能的决策向量 ${\underline{u}}_{j}$ 构成决策空间 ${U}_{j}\left( {\underline{x}}_{j - 1}\right)  \subseteq  {\mathbb{R}}^{s}$ . 从 ${\underline{x}}_{j - 1}$ 出发,可以通过如下变换得到下一个状态 ${\underline{x}}_{j}$ (图 18.14):

$$
{\underline{\mathbf{x}}}_{j} = {g}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,\;j = 1\left( 1\right) n. \tag{18.125}
$$

![01936af3-1230-7a0e-9a4a-8542777881ce_46_378_1498_884_176_0.jpg](images/01936af3-1230-7a0e-9a4a-8542777881ce_46_378_1498_884_176_0.jpg)

图 18.14

##### 18.3.1.2 动态规划问题

我们的目的是确定一个策略 $\left( {{\underline{\mathbf{u}}}_{1},\cdots ,{\underline{\mathbf{u}}}_{n}}\right)$ 使得过程从初始状态 ${\underline{\mathbf{x}}}_{a}$ 驱动至状态 ${\underline{\mathbf{x}}}_{e}$ ,并考虑到所有的约束,使得目标函数或费用函数 $f\left( {{f}_{1}\left( {{\underline{\mathbf{x}}}_{0},{\underline{\mathbf{u}}}_{1}}\right) ,\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},}\right. }\right.$ $\left. {\underline{\mathbf{u}}}_{n}\right)$ 达到极小. 函数 ${f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right)$ 称作阶段费用函数. 动态规划问题的标准形是

OF: $f\left( {{f}_{1}\left( {{\underline{\mathbf{x}}}_{0},{\underline{\mathbf{u}}}_{1}}\right) ,\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right)  \rightarrow  \min$ !(18.126a)

$$
\left. \begin{array}{lll} \text{ CT: } & {\underline{\mathbf{x}}}_{j} = {g}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) , & j = 1\left( 1\right) n, \\   & {\underline{\mathbf{x}}}_{0} = {\underline{\mathbf{x}}}_{a},{\underline{\mathbf{x}}}_{n} = {\underline{\mathbf{x}}}_{e} \in  {X}_{e},{\underline{\mathbf{x}}}_{j} \in  {X}_{j} \subseteq  {\mathbb{R}}^{m}, & j = 1\left( 1\right) n, \\   & {\underline{\mathbf{u}}}_{j} \in  {U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)  \subseteq  {\mathbb{R}}^{m}, & j = 1\left( 1\right) n. \end{array}\right\}   \tag{18.126b}
$$

第一种类型的约束 ${\underline{x}}_{j}$ 称作动态约束,而其余约束 ${\underline{x}}_{0},{\underline{u}}_{j}$ 则称作静态约束. 类似于 (18.126a), 也可以考虑极大问题. 满足所有约束条件的策略称作可行约束. 如果目标函数满足某些附加要求 (参见第 1227 页 18.3.3), 则可以应用动态规划法.

#### 18.3.2 离散决策模型的例子

##### 18.3.2.1 购买问题

一时间区间可以分成 $n$ 个周期,在其第 $j$ 个周期内,一工场需要某种原材料 ${v}_{j}$ 个单位. 在第 $j$ 个周期开始时能得到的这种材料的数量记作 ${x}_{j - 1}$ ,特别地, ${x}_{0} = {x}_{a}$ 是给定的. 在每个周期结束时工场将以单位价格 ${c}_{j}$ 购买待定数量 ${u}_{j}$ 个单位材料. 同时给定的储存容量 $K$ 是不能超过的,即 ${x}_{j - 1} + {u}_{j} \leq  K$ . 要求确定购买策略 $\left( {{u}_{1},\cdots ,{u}_{n}}\right)$ ,使得总费用最小. 于是我们要求解如下的动态规划问题:

$$
\text{OF:}f\left( {{u}_{1},\cdots ,{u}_{n}}\right)  = \mathop{\sum }\limits_{{j = 1}}^{n}{f}_{j}\left( {u}_{j}\right)  = \mathop{\sum }\limits_{{j = 1}}^{n}{c}_{j}{u}_{j} \rightarrow  \min \text{!} \tag{18.127a}
$$

$$
\left. \begin{matrix} \text{ CT: } & {x}_{j} = {x}_{j - 1} + {u}_{j} - {v}_{j}, & j = 1\left( 1\right) n, \\   & {x}_{0} = {x}_{a},0 \leq  {x}_{j} \leq  K, & j = 1\left( 1\right) n, \\   & {U}_{j}\left( {x}_{j - 1}\right)  = \left\{  {{u}_{j} : \max \left\{  {0,{v}_{j} - {x}_{j - 1}}\right\}  }\right. & \\   &  \leq  {u}_{j} \leq  K - {x}_{j - 1}\} , & j = 1\left( 1\right) n. \end{matrix}\right\}   \tag{18.127b}
$$

在 (18.127b) 中, 保证满足所需要求, 并且储存容量不会超过. 如果每个周期内还要支付每个单位储存费用 $\ell$ ,则在第 $j$ 周期内的中间费用是 $\left( {{x}_{j - 1} + {u}_{j} - {v}_{j}/2}\right) \ell$ , 而修正的费用函数是

$$
f\left( {{x}_{0},{u}_{1},\cdots ,{x}_{n - 1},{u}_{n}}\right)  = \mathop{\sum }\limits_{{j = 1}}^{n}\left( {{c}_{j}{u}_{j} + \left( {{x}_{j - 1} + {u}_{j} - {v}_{j}/2}\right)  \cdot  \ell }\right) . \tag{18.128}
$$

##### 18.3.2.2 背包问题

假设有 $n$ 个项目 ${A}_{1},\cdots ,{A}_{n}$ ,相应的权重和价值分别为为 ${w}_{1},\cdots ,{w}_{n}$ 和 ${c}_{1},\cdots ,{c}_{n}$ ,问题是要从中选取一些项目,使得总的权重数不超过给定上限 $W$ ,而总价值最大. 这个问题与时间无关. 我们按如下方式重新表述这个问题: 在每一阶段要作出一个有关项目 ${A}_{j}$ 选取的决策 ${u}_{j}$ ,这里若选取 ${A}_{j}$ ,则 ${u}_{j} = 1$ ,否则, ${u}_{j} = 0$ . 在每一阶段开始时能得到的容量记作 ${x}_{j - 1}$ . 从而就得到如下动态规划问题:

$$
f\left( {{u}_{1},\cdots ,{u}_{n}}\right)  = \mathop{\sum }\limits_{{j = 1}}^{n}{c}_{j}{u}_{j} \rightarrow  \min ! \tag{18.129a}
$$

$$
\left. \begin{aligned} {x}_{j} = & {x}_{j - 1} - {w}_{j}{u}_{j}, & & j = 1\left( 1\right) n, & \\  {x}_{0} = & W,0 \leq  {x}_{j} \leq  W, & & j = 1\left( 1\right) n, & \\  {u}_{j} \in  \{ 0,1\} , & & {x}_{j - 1} \geq  {w}_{j}, & & j = 1\left( 1\right) n. \\  {u}_{j} = & 0, & & {x}_{j - 1} < {w}_{j}, &  \end{aligned}\right\}   \tag{18.129b}
$$

#### 18.3.3 贝尔曼泛函方程

##### 18.3.3.1 费用函数的性质

为了叙述贝尔曼泛函方程, 费用函数必须满足两个性质.

###### 1. 可分性

函数 $f\left( {{f}_{1}\left( {{\underline{x}}_{0},{\underline{u}}_{1}}\right) ,\cdots ,{f}_{n}\left( {{\underline{x}}_{n - 1},{\underline{u}}_{n}}\right) }\right)$ 称作可分的,是指它可以由双参函数 ${H}_{1},\cdots ,{H}_{n - 1}$ 以及函数 ${F}_{1},\cdots ,{F}_{n}$ 按如下方式给出:

$$
f\left( {{f}_{1}\left( {{\underline{\mathbf{x}}}_{0},{\underline{\mathbf{u}}}_{1}}\right) ,\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right)
$$

$$
= {F}_{1}\left( {{f}_{1}\left( {{\underline{\mathbf{x}}}_{0},{\underline{\mathbf{u}}}_{1}}\right) ,\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right) ,
$$

$$
{F}_{1}\left( {{f}_{1}\left( {{\underline{\mathbf{x}}}_{0},{\underline{\mathbf{u}}}_{1}}\right) ,\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right)
$$

$$
= {H}_{1}\left( {{f}_{1}\left( {{\underline{\mathbf{x}}}_{0},{\underline{\mathbf{u}}}_{1}}\right) ,{F}_{2}\left( {{f}_{2}\left( {{\underline{\mathbf{x}}}_{1},{\underline{\mathbf{u}}}_{2}}\right) \cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right) }\right) ,
$$

......

$$
{F}_{n - 1}\left( {{f}_{n - 1}\left( {{\underline{\mathbf{x}}}_{n - 2},{\underline{\mathbf{u}}}_{n - 1}}\right) ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right)
$$

$$
= {H}_{n - 1}\left( {{f}_{n - 1}\left( {{\underline{\mathbf{x}}}_{n - 2},{\underline{\mathbf{u}}}_{n - 1}}\right) ,{F}_{n}\left( {{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right) }\right) ,
$$

$$
{F}_{n}\left( {{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right)  = {f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) . \tag{18.130}
$$

###### 2. 极小可交换性

函数 $H\left( {\widetilde{f}\left( \underline{\mathbf{a}}\right) ,\widetilde{F}\left( \underline{\mathbf{b}}\right) }\right)$ 称作极小可交换的,是指它满足

$$
\mathop{\min }\limits_{{\left( {\underline{\mathbf{a}},\underline{\mathbf{b}}}\right)  \in  A \times  B}}H\left( {\widetilde{f}\left( \underline{\mathbf{a}}\right) ,\widetilde{F}\left( \underline{\mathbf{b}}\right) }\right)  = \mathop{\min }\limits_{{\underline{\mathbf{a}} \in  A}}H\left( {\widetilde{f}\left( \underline{\mathbf{a}}\right) ,\mathop{\min }\limits_{{\underline{\mathbf{b}} \in  B}}\widetilde{F}\left( \underline{\mathbf{b}}\right) }\right) . \tag{18.131}
$$

例如,如果 $H$ 对于每个 $\underline{\mathbf{a}} \in  A$ 相对于第二变元是单调递增的,即若对于每个 $\underline{\mathbf{a}} \in  A$ ,

$$
H\left( {\widetilde{f}\left( \underline{\mathbf{a}}\right) ,\widetilde{F}\left( {\underline{\mathbf{b}}}_{1}\right) }\right)  \leq  H\left( {\widetilde{f}\left( \underline{\mathbf{a}}\right) ,\widetilde{F}\left( {\underline{\mathbf{b}}}_{2}\right) }\right) ,\;\text{ 若 }\widetilde{F}\left( {\underline{\mathbf{b}}}_{1}\right)  \leq  \widetilde{F}\left( {\underline{\mathbf{b}}}_{2}\right) , \tag{18.132}
$$

则上述可交换性就满足. 现在对于动态规划问题的费用函数,则要求满足 $f$ 的可分性以及所有函数 ${H}_{j}, j = 1\left( 1\right) n - 1$ 的极小可交换性. 以下经常出现的费用函数类型就满足这两种要求:

$$
{f}^{\text{sum }} = \mathop{\sum }\limits_{{j = 1}}^{n}{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) \text{,或者 }{f}^{\max } = \mathop{\max }\limits_{{j = 1\left( 1\right) n}}{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) , \tag{18.133}
$$

而函数 ${H}_{j}$ 分别是

$$
{H}_{j}^{\text{sum }} = {f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right)  + \mathop{\sum }\limits_{{k = j + 1}}^{n}{f}_{k}\left( {{\underline{\mathbf{x}}}_{k - 1},{\underline{\mathbf{u}}}_{k}}\right) , \tag{18.134}
$$

以及

$$
{H}_{j}^{\max } = \max \left\{  {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,\mathop{\max }\limits_{{k = j + 1\left( 1\right) n}}{f}_{k}\left( {{\underline{\mathbf{x}}}_{k - 1},{\underline{\mathbf{u}}}_{k}}\right) }\right\}  . \tag{18.135}
$$

##### 18.3.3.2 列出泛函方程

首先定义如下函数:

$$
{\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)  = \mathop{\min }\limits_{\substack{{{\underline{\mathbf{u}}}_{k} \in  {U}_{k}\left( {\underline{\mathbf{x}}}_{k - 1}\right) } \\  {k = j\left( 1\right) n} }}{F}_{j}\left( {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,}\right.
$$

$$
\left. {\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right) ,\;j = 1\left( 1\right) n, \tag{18.136}
$$

$$
{\phi }_{n + 1}\left( {\underline{\mathbf{x}}}_{n}\right)  = 0. \tag{18.137}
$$

如果没有策略 $\left( {{\underline{\mathbf{u}}}_{1},\cdots ,{\underline{\mathbf{u}}}_{n}}\right)$ 能驱动状态 ${\underline{\mathbf{x}}}_{j - 1}$ 到末状态 ${\underline{\mathbf{x}}}_{e} \in  {X}_{e}$ ,则我们置 ${\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)  = \infty$ . 使用可分性以及对于 $j = 1\left( 1\right) n$ 的极小可交换性和动态约束条件, 我们得到

$$
{\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)  = \mathop{\min }\limits_{{{\underline{\mathbf{u}}}_{j} \in  {U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right) }}{H}_{j}\left( {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,}\right.
$$

$$
\mathop{\min }\limits_{\substack{{{\underline{\mathbf{u}}}_{k} \in  {U}_{k}\left( {\underline{\mathbf{x}}}_{k - 1}\right) } \\  {k = j + 1\left( 1\right) n} }}{F}_{j + 1}\left( {{f}_{j + 1}\left( {{\underline{\mathbf{x}}}_{j},{\underline{\mathbf{u}}}_{j + 1}}\right) ,\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) )}\right) ,
$$

$$
= \mathop{\min }\limits_{{{\underline{\mathbf{u}}}_{j} \in  {U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right) }}{H}_{j}\left( {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,{\phi }_{j + 1}\left( {\underline{\mathbf{x}}}_{j}\right) }\right) ,
$$

$$
{\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)  = \mathop{\min }\limits_{{{\underline{\mathbf{u}}}_{j} \in  {U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right) }}{H}_{j}\left( {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,{\phi }_{j + 1}\left( {{g}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) }\right) }\right) . \tag{18.138}
$$

方程 (18.138),(18.136) 和 (18.137) 称作贝尔曼泛函方程. ${\phi }_{1}\left( {\underline{\mathbf{x}}}_{0}\right)$ 是费用函数的最优值.

#### 18.3.4 贝尔曼最优性原理

求解泛函方程

$$
{\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)  = \mathop{\min }\limits_{{{\underline{\mathbf{u}}}_{j} \in  {U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right) }}{H}_{j}\left( {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,{\phi }_{j + 1}\left( {\underline{\mathbf{x}}}_{j}\right) }\right)  \tag{18.139}
$$

相当于确定最优策略 $\left( {{\underline{\mathbf{u}}}_{j}^{ * },\cdots ,{\underline{\mathbf{u}}}_{n}^{ * }}\right)$ ,这一策略使得从状态 ${\underline{\mathbf{x}}}_{j - 1}$ 开始,由全过程 $P$ 的最后 $n - j + 1$ 级组成的子过程 ${P}_{j}$ 的费用函数达到极小,即

$$
{F}_{j}\left( {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}}\right) ,\cdots ,{f}_{n}\left( {{\underline{\mathbf{x}}}_{n - 1},{\underline{\mathbf{u}}}_{n}}\right) }\right)  \rightarrow  \min ! \tag{18.140}
$$

初始状态为 ${\underline{x}}_{j - 1}$ 的子过程 ${P}_{j}$ 的最优策略与已经将 $P$ 驱动至状态 ${\underline{x}}_{j - 1}$ 的前 $j - 1$ 级的决策 $\left( {{\underline{\mathbf{u}}}_{j},\cdots ,{\underline{\mathbf{u}}}_{n}}\right)$ 无关. 为了确定 ${\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)$ ,需要知道值 ${\phi }_{j + 1}\left( {\underline{\mathbf{x}}}_{j}\right)$ . 现在,如果 $\left( {{\underline{\mathbf{u}}}_{j}^{ * },\cdots ,{\underline{\mathbf{u}}}_{n}^{ * }}\right)$ 是 ${P}_{j}$ 的最优策略,则显然 $\left( {{\underline{\mathbf{u}}}_{j + 1}^{ * },\cdots ,{\underline{\mathbf{u}}}_{n}^{ * }}\right)$ 是初始状态为 ${\underline{\mathbf{x}}}_{j} = {g}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1},{\underline{\mathbf{u}}}_{j}^{ * }}\right)$ 的子过程 ${P}_{j + 1}$ 的最优策略. 这个命题在贝尔曼最优性原理中被进一步推广为贝尔曼原理.

贝尔曼原理 如果 $\left( {{\underline{\mathbf{u}}}_{1}^{ * },\cdots ,{\underline{\mathbf{u}}}_{n}^{ * }}\right)$ 是过程 $P$ 的最优策略,而 $\left( {{\underline{\mathbf{x}}}_{0}^{ * },\cdots ,{\underline{\mathbf{x}}}_{n}^{ * }}\right)$ 是相应的状态序列,则对于每个子过程 ${P}_{j}, j = 1\left( 1\right) n$ ,在初始状态 ${\underline{x}}_{j - 1}^{ * }$ 下,策略 $\left( {{\underline{\mathbf{u}}}_{j}^{ * },\cdots ,{\underline{\mathbf{u}}}_{n}^{ * }}\right)$ 也是最优的.

#### 18.3.5 贝尔曼泛函方程方法

##### 18.3.5.1 最小费用的确定

基于泛函方程 (18.136),(18.137) 和 (18.138),从 ${\phi }_{n + 1}\left( {\underline{\mathbf{x}}}_{n}\right)  = 0$ 开始,每一个值 ${\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right) \left( {{\underline{\mathbf{x}}}_{j - 1} \in  {X}_{j - 1}}\right)$ 按 $j$ 的递减顺序逐个确定. 它要求对于每一 ${\underline{\mathbf{x}}}_{j - 1} \in  {X}_{j - 1}$ , 最优问题的解都在决策空间 ${U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)$ . 对于每个 ${\underline{\mathbf{x}}}_{j - 1}$ ,存在一极小点 ${\underline{\mathbf{u}}}_{j} \in  {U}_{j}$ 作为从 ${\underline{\mathbf{x}}}_{j - 1}$ 开始的子过程 ${P}_{j}$ 的第 1 级的最优决策. 如果诸集合 ${X}_{j}$ 不是有限的或者它们太大,那么可以对于一组所选择的节点 ${\underline{x}}_{j - 1} \in  {X}_{j - 1}$ ,计算相应的 ${\phi }_{j}$ 值. 其中间值可以通过某种插值方法进行计算. ${\phi }_{1}\left( {\underline{\mathbf{x}}}_{0}\right)$ 是过程 $P$ 的费用函数的最优值. 最优策略 $\left( {{\underline{\mathbf{u}}}_{1}^{ * },\cdots ,{\underline{\mathbf{u}}}_{n}^{ * }}\right)$ 以及相应的状态 $\left( {{\underline{\mathbf{x}}}_{0}^{ * },\cdots ,{\underline{\mathbf{x}}}_{n}^{ * }}\right)$ 可以采用如下两种方式之一来确定.

##### 18.3.5.2 最优策略的确定

(1) 方式 1 在求解泛函方程中,每次计算 ${\underline{x}}_{j - 1} \in  {X}_{j - 1}$ 也要将计算值 ${\underline{u}}_{j}$ 存储起来. 在计算 ${\phi }_{1}\left( {\underline{\mathbf{x}}}_{0}\right)$ 之后,如果从 ${\underline{\mathbf{x}}}_{0} = {\underline{\mathbf{x}}}_{0}^{ * }$ 和所存储的 ${\underline{\mathbf{u}}}_{1} = {\underline{\mathbf{u}}}_{1}^{ * }$ 确定 ${\underline{\mathbf{x}}}_{1}^{ * } = {g}_{1}\left( {{\underline{\mathbf{x}}}_{0}^{ * },{\underline{\mathbf{u}}}_{1}^{ * }}\right)$ ,就得到最优策略. 从 ${\underline{\mathbf{x}}}_{1}^{ * }$ 和存起来的 ${\underline{\mathbf{u}}}_{2}^{ * }$ 得出 ${\underline{\mathbf{x}}}_{2}^{ * }$ ,等等.

(2) 方式 2 对于每个 ${\underline{\mathbf{x}}}_{j - 1} \in  {X}_{j - 1}$ ,仅存储 ${\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)$ . 在每次 ${\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)$ 知道后,就前向计算一次. 从 $j = 1$ 和 ${\underline{\mathbf{x}}}_{0} = {\underline{\mathbf{x}}}_{0}^{ * }$ 开始,通过计算泛函方程

$$
{\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}^{ * }\right)  = \mathop{\min }\limits_{{{\underline{\mathbf{u}}}_{j} \in  {U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}^{ * }\right) }}{H}_{j}\left( {{f}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1}^{ * },{\underline{\mathbf{u}}}_{j}}\right) ,{\phi }_{j + 1}\left( {{g}_{j}\left( {{\underline{\mathbf{x}}}_{j - 1}^{ * },{\underline{\mathbf{u}}}_{j}}\right) }\right) }\right)  \tag{18.141}
$$

按 $j$ 的递增顺序逐个确定 ${\underline{u}}_{j}$ . 然后得到 ${\underline{x}}_{j}^{ * } = {g}_{j}\left( {{\underline{x}}_{j - 1}^{ * },{\underline{u}}_{j}^{ * }}\right)$ . 在前向计算中,每一级都必须求解一个优化问题.

(3) 两种方式的比较 由于是前向计算, 方式 1 计算的代价要小于方式 2 所要求的代价. 然而,由于每一状态 ${\underline{\mathbf{x}}}_{j - 1}$ 下都要存储决策 ${\underline{\mathbf{u}}}_{j}$ ,从而在高维决策空间 ${U}_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)$ 情形下,这可能需要非常大的存储量,而在方式 2 中,仅需存储 ${\phi }_{j}\left( {\underline{\mathbf{x}}}_{j - 1}\right)$ . 因此常常在计算机上使用方式 2.

#### 18.3.6 泛函方程方法的应用例子

##### 18.3.6.1 最优购买策略

###### 1. 问题的提法

从第 1226 页 18.3.2.1 中的最优买入策略问题

OF: $f\left( {{u}_{1},\cdots ,{u}_{n}}\right)  = \mathop{\sum }\limits_{{j = 1}}^{n}{c}_{j}{u}_{j} \rightarrow  \min !$(18.142a)

$$
\left. \begin{matrix} \text{ CT: } & {x}_{j} = {x}_{j - 1} + {u}_{j} - {v}_{j}, & j = 1\left( 1\right) n, \\   & {x}_{0} = {x}_{a},0 \leq  j \leq  K, & j = 1\left( 1\right) n, \\   & {U}_{j}\left( {x}_{j - 1}\right)  = \left\{  {{u}_{j} : \max \left\{  {0,{v}_{j} - {x}_{j - 1}}\right\}  }\right. & \\   &  \leq  {u}_{j} \leq  K - {x}_{j - 1}\} , & j = 1\left( 1\right) n \end{matrix}\right\}   \tag{18.142b}
$$

导出泛函方程

$$
{\phi }_{n + 1}\left( {x}_{n}\right)  = 0, \tag{18.143}
$$

$$
{\phi }_{j}\left( {x}_{j - 1}\right)  = \mathop{\max }\limits_{{{u}_{j} \in  {U}_{j}\left( {x}_{j - 1}\right) }}\left( {{c}_{j}{u}_{j} + {\phi }_{j + 1}\left( {{x}_{j - 1} + {u}_{j} - {v}_{j}}\right) }\right) ,\;j = 1\left( 1\right) n. \tag{18.144}
$$

###### 2. 数值例子

$$
n = 6, K = {10},{x}_{a} = 2.\;\begin{array}{l} {c}_{1} = 4,{c}_{2} = 3,{c}_{3} = 5,{c}_{4} = 3,{c}_{5} = 4,{c}_{6} = 2, \\  {v}_{1} = 6,{v}_{2} = 7,{v}_{3} = 4,{v}_{4} = 2,{v}_{5} = 4,{v}_{6} = 3. \end{array}
$$

后向计算 对于状态 ${x}_{j - 1} = 0,1,\cdots ,{10}$ 分别确定函数值 ${\phi }_{j}\left( {x}_{j - 1}\right)$ . 现在只需对于 ${u}_{j}$ 的整数值进行极小搜索.

$$
j = 6 : \;{\phi }_{6}\left( {x}_{5}\right)  = \mathop{\min }\limits_{{{u}_{6} \in  {U}_{6}\left( {x}_{5}\right) }}{c}_{6}{u}_{6} = {c}_{6}\max \left\{  {0,{v}_{6} - {x}_{5}}\right\}   = 2\max \left\{  {0,3 - {x}_{5}}\right\}  .
$$

根据贝尔曼泛函方程方法的方式 2,只要将 ${\phi }_{6}\left( {x}_{5}\right)$ 的值写在最后一行中. 例如,确定 ${\phi }_{4}\left( 0\right)$ 为

${\phi }_{4}\left( 0\right)  = \mathop{\min }\limits_{{2 \leq  {u}_{4} \leq  {10}}}\left( {3{u}_{4} + {\phi }_{5}\left( {{u}_{4} - 2}\right) }\right)  = \min \{ {28},{27},{26},{25},{24},{25},{26},{27},{30}\}  = {24}.$

<table><tr><td/><td>${x}_{j} = 0$</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>$j = 1$</td><td/><td/><td>75</td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>2</td><td>59</td><td>56</td><td>53</td><td>50</td><td>47</td><td>44</td><td>41</td><td>38</td><td>35</td><td>32</td><td>29</td></tr><tr><td>3</td><td>44</td><td>39</td><td>34</td><td>29</td><td>24</td><td>21</td><td>18</td><td>15</td><td>12</td><td>9</td><td>6</td></tr><tr><td>4</td><td>24</td><td>21</td><td>18</td><td>15</td><td>12</td><td>9</td><td>6</td><td>4</td><td>2</td><td>0</td><td>0</td></tr><tr><td>5</td><td>22</td><td>18</td><td>14</td><td>10</td><td>6</td><td>4</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>6</td><td>6</td><td>4</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></table>

前向计算

$$
{\phi }_{1}\left( 2\right)  = {75} = \mathop{\min }\limits_{{4 \leq  {u}_{1} \leq  8}}\left( {4{u}_{1} + {\phi }_{2}\left( {{u}_{1} - 4}\right) }\right) .
$$

于是得到 ${u}_{1}^{ * } = 4$ 作为极小点,因此 ${x}_{1}^{ * } = {x}_{0}^{ * } + {u}_{1}^{ * } - {v}_{1} = 0$ . 对于 ${\phi }_{2}\left( 0\right)$ 以及后面各级重复此方法, 得到最优策略:

$$
\left( {{u}_{1}^{ * },{u}_{2}^{ * },{u}_{3}^{ * },{u}_{4}^{ * },{u}_{5}^{ * },{u}_{6}^{ * }}\right)  = \left( {4,{10},1,6,0,3}\right) .
$$

##### 18.3.6.2 背包问题

###### 1. 问题的提法

考虑第 1226 页 18.3.2.2 中给出的问题:

$$
\text{:}\;f\left( {{u}_{1},\cdots ,{u}_{n}}\right)  = \mathop{\sum }\limits_{{j = 1}}^{n}{c}_{j}{u}_{j} \rightarrow  \max \text{!} \tag{18.145a}
$$

CT:

$$
\left. \begin{array}{ll} {x}_{j} = {x}_{j - 1} - {w}_{j}{u}_{j}, & j = 1\left( 1\right) n, \\  {x}_{0} = W,0 \leq  {x}_{j} \leq  W, & j = 1\left( 1\right) n, \\  {u}_{j} \in  \{ 0,1\} ,\;{x}_{j - 1} \geq  {w}_{j}, & \\  {u}_{j} = 0,\;{x}_{j - 1} < {w}_{j}, & j = 1\left( 1\right) n. \end{array}\right\}   \tag{18.145b}
$$

由于这是一个极大问题, 故贝尔曼泛函方程现在是

$$
{\phi }_{n + 1}\left( {x}_{n}\right)  = 0,
$$

$$
{\phi }_{j}\left( {x}_{j - 1}\right)  = \mathop{\max }\limits_{{{u}_{j} \in  {U}_{j}\left( {x}_{j - 1}\right) }}\left( {{c}_{j}{u}_{j} + {\phi }_{j + 1}\left( {{x}_{j - 1} - {w}_{j}{u}_{j}}\right) }\right) ,\;j = 1\left( 1\right) n.
$$

决策只可能是 0 和 1 , 故应用泛函方程方法的方式 1 是比较切合实际的. 对于$j = n, n - 1,\cdots ,1 :$

$$
{\phi }_{j}\left( {x}_{j - 1}\right)  = \left\{  \begin{array}{ll} {c}_{j} + {\phi }_{j + 1}\left( {{x}_{j - 1} - {w}_{j}}\right) , & \text{ 如果 }{x}_{j - 1} \geq  {w}_{j}, \\  {c}_{j} + {\phi }_{j + 1}\left( {{x}_{j - 1} - {w}_{j}}\right)  > {\phi }_{j + 1}\left( {x}_{j - 1}\right) , & \\  {\phi }_{j + 1}\left( {x}_{j - 1}\right) , & \text{ 否则,} \end{array}\right.
$$

${u}_{j}\left( {x}_{j - 1}\right)  = \left\{  \begin{array}{ll} 1, & \text{ 如果 }{x}_{j - 1} \geq  {w}_{j},{c}_{j} + {\phi }_{j + 1}\left( {{x}_{j - 1} - {w}_{j}}\right)  > {\phi }_{j + 1}\left( {x}_{j - 1}\right) , \\  0, & \text{ 否则. } \end{array}\right.$

###### 2. 数值例子

$$
W = {10},\;n = 6.\;\begin{array}{l} {c}_{1} = 1,\;{c}_{2} = 2,\;{c}_{3} = 3,\;{c}_{4} = 1,\;{c}_{5} = 5,\;{c}_{6} = 4, \\  {w}_{1} = 2,\;{w}_{2} = 4,\;{w}_{3} = 6,\;{w}_{4} = 3,\;{w}_{5} = 7,\;{w}_{6} = 6. \end{array}
$$

由于权重 ${w}_{j}$ 是整数,故 ${x}_{j}$ 的可能值是 ${x}_{j} \in  \{ 0,1,\cdots ,{10}\} , j = 1\left( 1\right) n$ ,而 ${x}_{0} =$ 10. 下表中包含了每一级和每个状态 ${x}_{j - 1}$ 下的函数值 ${\phi }_{j}\left( {x}_{j - 1}\right)$ 和实际的决策 ${u}_{j}\left( {x}_{j - 1}\right)$ . 例如, ${\phi }_{6}\left( {x}_{5}\right) ,{\phi }_{3}\left( 2\right) ,{\phi }_{3}\left( 6\right)$ 和 ${\phi }_{3}\left( 8\right)$ 的计算如下:

$$
{\phi }_{6}\left( {x}_{5}\right)  = \left\{  {\begin{array}{ll} 0, & \text{ 如果 }{x}_{5} < {w}_{6} = 4, \\  {c}_{6} = 6, & \text{ 否则,} \end{array}\;{u}_{6}\left( {x}_{5}\right)  = \left\{  \begin{array}{ll} 0, & \text{ 如果 }{x}_{5} < 4, \\  0, & \text{ 否则. } \end{array}\right. }\right.
$$

${\phi }_{3}\left( 2\right)  : {x}_{2} = 2 < {w}_{3} = 3 : {\phi }_{3}\left( 2\right)  = {\phi }_{4}\left( 2\right)  = 3,{u}_{3}\left( 2\right)  = 0.$

${\phi }_{3}\left( 6\right)  : {x}_{2} > {w}_{3},{c}_{3} + {\phi }_{3}\left( {{x}_{2} - {w}_{3}}\right)  = 6 + 3 < {\phi }_{4}\left( {x}_{2}\right)  = {10} : {\phi }_{3}\left( 6\right)  = {10},{u}_{3}\left( 6\right)  = 0.$

${\phi }_{3}\left( 8\right)  : {x}_{2} > {w}_{3},{c}_{3} + {\phi }_{3}\left( {{x}_{2} - {w}_{3}}\right)  = 6 + 9 > {\phi }_{4}\left( {x}_{2}\right)  = {10} : {\phi }_{3}\left( 8\right)  = {15},{u}_{3}\left( 8\right)  = 1$ .

**最优策略是**

$$
\left( {{u}_{1}^{ * },{u}_{2}^{ * },{u}_{3}^{ * },{u}_{4}^{ * },{u}_{5}^{ * },{u}_{6}^{ * }}\right)  = \left( {0,1,1,1,0,1}\right) ,\;{\phi }_{1}\left( {10}\right)  = {19}.
$$

<table><tr><td/><td>${x}_{j} = 0$</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>$j = 1$</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td>19;0</td></tr><tr><td>2</td><td>0;0</td><td>3;0</td><td>4;1</td><td>7;1</td><td>9;0</td><td>10;1</td><td>13;1</td><td>13;1</td><td>15;0</td><td>16;0</td><td>19;1</td></tr><tr><td>3</td><td>0;0</td><td>3;0</td><td>3;0</td><td>6;1</td><td>9;1</td><td>9;0</td><td>10;0</td><td>12;1</td><td>15;1</td><td>16;1</td><td>16;0</td></tr><tr><td>4</td><td>0;0</td><td>3;1</td><td>3;1</td><td>3;1</td><td>6;0</td><td>9;1</td><td>10;1</td><td>10;1</td><td>10;1</td><td>13;0</td><td>16;1</td></tr><tr><td>5</td><td>0;0</td><td>0;0</td><td>0;0</td><td>0;0</td><td>6;0</td><td>7;1</td><td>7;1</td><td>7;1</td><td>7;1</td><td>13;1</td><td>13;1</td></tr><tr><td>6</td><td>0;0</td><td>0;0</td><td>0;0</td><td>0;0</td><td>6;1</td><td>6;1</td><td>6;1</td><td>6;1</td><td>6;1</td><td>6;1</td><td>6;1</td></tr></table>

(冯德兴 译)

