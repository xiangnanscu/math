# 16.3.4 相关和回归

相关分析根据试验数据确定总体两个或两个以上变量之间是否存在某种相关关系, 回归分析用于确定变量间相关关系的形式.

## 16.3.4.1 两个可测变量的线性相关

**1. 二维随机变量**

下述公式通常适用于连续随机变量, 但对离散变量, 很容易用相应公式进行替换. 设 $X$ 和 $Y$ 构成二维随机变量(X, Y),其联合分布函数为

$$
F\left( {x, y}\right)  = P\left( {X \leq  x, Y \leq  y}\right)  = {\int }_{-\infty }^{x}{\int }_{-\infty }^{y}f\left( {x, y}\right) \mathrm{d}x\mathrm{\;d}y, \tag{16.146a}
$$

$$
{F}_{1}\left( x\right)  = P\left( {X \leq  x, Y < \infty }\right) ,\;{F}_{2}\left( y\right)  = P\left( {X < \infty , Y \leq  y}\right) . \tag{16.146b}
$$

随机变量 $X$ 和 $Y$ 称为相互独立,如果

$$
F\left( {x, y}\right)  = {F}_{1}\left( x\right)  \cdot  {F}_{2}\left( y\right)  \tag{16.147}
$$

成立. 由其联合密度函数 $f\left( {x, y}\right)$ 确定、对应于 $X$ 和 $Y$ 的基本统计量如下:

**(1) 期望**

$$
{\mu }_{X} = E\left( X\right)  = {\int }_{-\infty }^{\infty }{\int }_{-\infty }^{\infty }{xf}\left( {x, y}\right) \mathrm{d}x\mathrm{\;d}y, \tag{16.148a}
$$

$$
{\mu }_{Y} = E\left( Y\right)  = {\int }_{-\infty }^{\infty }{\int }_{-\infty }^{\infty }{yf}\left( {x, y}\right) \mathrm{d}x\mathrm{\;d}y. \tag{16.148b}
$$

**(2) 方差**

$$
{\sigma }_{X}^{2} = E\left( {\left( X - {\mu }_{X}\right) }^{2}\right) , \tag{16.149a}
$$

$$
{\sigma }_{Y}^{2} = E\left( {\left( Y - {\mu }_{Y}\right) }^{2}\right) . \tag{16.149b}
$$

**(3) 协方差**

$$
{\sigma }_{XY} = E\left( {\left( {X - {\mu }_{X}}\right) \left( {Y - {\mu }_{Y}}\right) }\right) . \tag{16.150}
$$

**(4) 相关系数**

$$
{\rho }_{XY} = \frac{{\sigma }_{XY}}{{\sigma }_{X}{\sigma }_{Y}}. \tag{16.151}
$$

假定上述任一期望值都存在. 协方差也可由下述公式计算

$$
{\sigma }_{XY} = E\left( {XY}\right)  - {\mu }_{X}{\mu }_{Y},\;\text{ 其中 }E\left( {XY}\right)  = {\int }_{-\infty }^{\infty }{\int }_{-\infty }^{\infty }{xyf}\left( {x, y}\right) \mathrm{d}x\mathrm{\;d}y. \tag{16.152}
$$

相关系数是对 $X$ 和 $Y$ 线性相关关系的度量,原因如下:

若 ${\rho }_{XY}^{2} = 1$ ,则所有的点(X, Y)以概率 1 位于一条直线上. 若 $X$ 和 $Y$ 是独立随机变量,则其协方差等于 $0,{\rho }_{XY} = 0$ . 由 ${\rho }_{XY} = 0$ ,并不能推出 $X$ 和 $Y$ 独立, 但当它们服从密度函数为

$$
f\left( {x, y}\right)  = \frac{1}{{2\pi }{\sigma }_{X}{\sigma }_{Y}\sqrt{1 - {\rho }_{XY}^{2}}}\exp
$$

$$
\cdot  \left\lbrack  {-\frac{1}{2\left( {1 - {\rho }_{XY}^{2}}\right) }\left( {\frac{{\left( x - {\mu }_{X}\right) }^{2}}{{\sigma }_{X}^{2}} - 2\frac{{\rho }_{XY}\left( {x - {\mu }_{X}}\right) \left( {y - {\mu }_{Y}}\right) }{{\sigma }_{X}{\sigma }_{Y}} + \frac{{\left( y - {\mu }_{Y}\right) }^{2}}{{\sigma }_{Y}^{2}}}\right) }\right\rbrack
$$

(16.153)

的二维正态分布时,则由 ${\rho }_{XY} = 0$ 可得到 $X$ 和 $Y$ 独立.

**2. 两个变量的独立性检验**

在实践中经常遇到问题: 当 ${\rho }_{XY} = 0$ 时,随机变量 $X$ 和 $Y$ 是否可视为相互独立? 其中样本容量为 $n$ ,来自于二维正态分布总体,且有测量数据 $\left( {{x}_{i},{y}_{i}}\right) (i =$ $1,2,\cdots , n)$ . 检验方式如下.

**(1) 提出假设** $H : {\rho }_{XY} = 0$ .

**(2) 确定显著性水平** $\alpha$ ,由 1463 页表 21.20 查出 $t$ 分布的分位数 ${t}_{\alpha , m}$ ,其中 $m = n - 2$ .

**(3) 计算经验相关系数** ${r}_{xy}$ 和检验统计量 (样本函数)

$$
t = \frac{{r}_{xy}\sqrt{n - 2}}{\sqrt{1 - {r}_{xy}^{2}}} \tag{16.154a}
$$

且

$$
{r}_{xy} = \frac{\mathop{\sum }\limits_{{i = 1}}^{n}\left( {{x}_{i} - \bar{x}}\right) \left( {{y}_{i} - \bar{y}}\right) }{\sqrt{\mathop{\sum }\limits_{{i = 1}}^{n}{\left( {x}_{i} - \bar{x}\right) }^{2}\mathop{\sum }\limits_{{i = 1}}^{n}{\left( {y}_{i} - \bar{y}\right) }^{2}}}. \tag{16.154b}
$$

**(4) 若** $\left| t\right|  \geq  {t}_{\alpha , m}$ ,则拒绝假设.

## 16.3.4.2 两个可测变量的线性回归

**1. 确定回归直线**

如果说通过相关系数可探寻变量 $X$ 和 $Y$ 之间的相关关系,那么,下一个问题就是寻找其函数关系式 $Y = f\left( X\right)$ . 这时通常考虑线性关系.

在最简单的线性回归情形下,假设对于任意定值 $x$ ,总体中随机变量 $Y$ 服从正态分布, 且期望为

$$
E\left( Y\right)  = a + {bx} \tag{16.155}
$$

方差为 ${\sigma }^{2}$ ,与 $x$ 相互独立. (16.155) 即指随机变量 $Y$ 的均值线性依赖于定值 $x$ . 总体的参数 $a, b$ 和 ${\sigma }^{2}$ 通常未知,可根据样本数据 $\left( {{x}_{i},{y}_{i}}\right) \left( {i = 1,2,\cdots , n}\right)$ 运用最小二乘法近似估计. 最小二乘法要求

$$
\mathop{\sum }\limits_{{i = 1}}^{n}{\left\lbrack  {y}_{i} - \left( a + b{x}_{i}\right) \right\rbrack  }^{2} = \min ! \tag{16.156}
$$

成立, 从而可得估计值

$$
\widetilde{b} = \frac{\mathop{\sum }\limits_{{i = 1}}^{n}\left( {{x}_{i} - \bar{x}}\right) \left( {{y}_{i} - \bar{y}}\right) }{\mathop{\sum }\limits_{{i = 1}}^{n}{\left( {x}_{i} - \bar{x}\right) }^{2}},\;\widetilde{a} = \bar{y} - \widetilde{b}\bar{x},\;{\widetilde{\sigma }}^{2} = \frac{n - 1}{n - 2}{s}_{y}^{2}\left( {1 - {r}_{xy}^{2}}\right)  \tag{16.157a}
$$

且.

$$
\bar{x} = \frac{1}{n}\mathop{\sum }\limits_{{i = 1}}^{n}{x}_{i},\;\bar{y} = \frac{1}{n}\mathop{\sum }\limits_{{i = 1}}^{n}{y}_{i},\;{s}_{y}^{2} = \frac{1}{n - 1}\mathop{\sum }\limits_{{i = 1}}^{n}{\left( {y}_{i} - \bar{y}\right) }^{2}. \tag{16.157b}
$$

(16.154b) 给出了经验相关系数 ${r}_{xy}$ . 系数 $\widetilde{a}$ 和 $\widetilde{b}$ 称为回归系数. 直线 $y\left( x\right)  = \widetilde{a} + \widetilde{b}x$ 称为回归直线.

**2. 回归系数的置信区间**

当确定了回归系数 $\widetilde{a}$ 和 $\widetilde{b}$ 后,下一个问题就是,如何较好地近似估计理论值 $a$ 和 $b$ . 故检验变量形如

$$
{t}_{b} = \left( {\widetilde{b} - b}\right) \frac{{s}_{x}\sqrt{n - 2}}{{s}_{y}\sqrt{1 - {r}_{xy}^{2}}} \tag{16.158a}
$$

和

$$
{t}_{a} = \left( {\widetilde{a} - a}\right) \frac{{s}_{x}\sqrt{n - 2}}{{s}_{y}\sqrt{1 - {r}_{xy}^{2}}}\frac{\sqrt{n}}{\sqrt{\mathop{\sum }\limits_{{i = 1}}^{n}{x}_{i}^{2}}}. \tag{16.158b}
$$

这是服从自由度为 $m = n - 2$ 的 $t$ 分布的随机变量的实现. 给定显著性水平 $\alpha$ ,查 1463 页表 21.20 可得分位数 ${t}_{\alpha /2;m}$ ,对于 $t = {t}_{a}$ 和 $t = {t}_{b}$ ,由于 $P\left( {\left| t\right|  < {t}_{\alpha /2;m}}\right)  =$ $1 - \alpha$ 成立,故

$$
\left| {\widetilde{b} - b}\right|  < {t}_{\alpha /2;n - 2}\frac{{s}_{y}\sqrt{1 - {r}_{xy}^{2}}}{{s}_{x}\sqrt{n - 2}}, \tag{16.159a}
$$

$$
\left| {\widetilde{a} - a}\right|  < {t}_{\alpha /2;n - 2}\frac{{s}_{y}\sqrt{1 - {r}_{xy}^{2}} \cdot  \sqrt{\mathop{\sum }\limits_{{i = 1}}^{n}{x}_{i}^{2}}}{{s}_{x}\sqrt{n - 2} \cdot  \sqrt{n}}. \tag{16.159b}
$$

回归直线 $y = a + {bx}$ 的置信域,可由式 (16.159a,16.159b) 所给出的 $a, b$ 的置信区间确定 (参见文献 [16.4], [16.26]).

## 16.3.4.3 多元回归

**1. 函数关系**

设变量 ${X}_{1},{X}_{2},\cdots ,{X}_{n}$ 和 $Y$ 之间存在函数关系,该关系可用理论回归函数

$$
y = f\left( {{x}_{1},{x}_{2},\cdots ,{x}_{n}}\right)  = \mathop{\sum }\limits_{{j = 0}}^{s}{a}_{j}{g}_{j}\left( {{x}_{1},{x}_{2},\cdots ,{x}_{n}}\right)  \tag{16.160}
$$

描述. 函数 ${g}_{j}\left( {{x}_{1},{x}_{2},\cdots ,{x}_{n}}\right)$ 是关于 $n$ 个独立变量的已知函数. (16.160) 中的系数 ${a}_{j}$ 是线性组合中的常数乘子. 式 (16.160) 也称为线性回归,虽然 ${g}_{j}$ 可是任意函数.

| 函数 $f\left( {{x}_{1},{x}_{2}}\right)  = {a}_{0} + {a}_{1}{x}_{1} + {a}_{2}{x}_{2} + {a}_{3}{x}_{1}^{2} + {a}_{4}{x}_{2}^{2} + {a}_{5}{x}_{1}{x}_{2}$ 是关于两个变量的完全二次多项式,其中 ${g}_{0} = 1,{g}_{1} = {x}_{1},{g}_{2} = {x}_{2},{g}_{3} = {x}_{1}^{2},{g}_{4} = {x}_{2}^{2},{g}_{5} = {x}_{1}{x}_{2}$ ,是理论线性回归函数的一个实例.

**2. 向量形式的记法**

在多元情形, 以向量

$$
\underline{\mathbf{x}} = {\left( {x}_{1},{x}_{2},\cdots ,{x}_{n}\right) }^{\mathrm{T}} \tag{16.161}
$$

的形式记公式很方便. 此时, (16.160) 可记为

$$
y = f\left( \underline{\mathbf{x}}\right)  = \mathop{\sum }\limits_{{j = 0}}^{s}{a}_{j}{g}_{j}\left( \underline{\mathbf{x}}\right) . \tag{16.162}
$$

**3. 正则方程组及求解**

由于随机测量存在误差, 理论关系式 (16.160) 不能由测量值

$$
\left( {{\underline{\mathbf{x}}}^{\left( i\right) },{f}_{i}}\right) \;\left( {i = 1,2,\cdots , N}\right)  \tag{16.163a}
$$

确定. 以

$$
y = \widetilde{f}\left( \underline{\mathbf{x}}\right)  = \mathop{\sum }\limits_{{j = 0}}^{s}{\widetilde{a}}_{j}{g}_{j}\left( \underline{\mathbf{x}}\right)  \tag{16.163b}
$$

的形式求其解,系数 ${\widetilde{a}}_{j}$ 作为理论系数 ${a}_{j}$ 的估计值,可通过最小二乘法 (参见第 1097 页 16.3.4.2, 1.) 由方程

$$
\mathop{\sum }\limits_{{i = 1}}^{N}{\left\lbrack  {f}_{i} - \widetilde{f}\left( {\underline{\mathbf{x}}}^{\left( i\right) }\right) \right\rbrack  }^{2} = \min ! \tag{16.163c}
$$

确定. 引入记号

$$
\underline{\widetilde{\mathbf{a}}} = \left( \begin{matrix} {\widetilde{a}}_{0} \\  {\widetilde{a}}_{1} \\  \vdots \\  {\widetilde{a}}_{s} \end{matrix}\right) ,\;\underline{\mathbf{f}} = \left( \begin{matrix} {f}_{1} \\  {f}_{2} \\  \vdots \\  {f}_{N} \end{matrix}\right) ,\;\mathbf{G} = \left( \begin{matrix} {g}_{0}\left( {\underline{\mathbf{x}}}^{\left( 1\right) }\right) & {g}_{1}\left( {\underline{\mathbf{x}}}^{\left( 1\right) }\right) & \cdots & {g}_{s}\left( {\underline{\mathbf{x}}}^{\left( 1\right) }\right) \\  {g}_{0}\left( {\underline{\mathbf{x}}}^{\left( 2\right) }\right) & {g}_{1}\left( {\underline{\mathbf{x}}}^{\left( 2\right) }\right) & \cdots & {g}_{s}\left( {\underline{\mathbf{x}}}^{\left( 2\right) }\right) \\  \vdots & \vdots &  \ddots  & \vdots \\  {g}_{0}\left( {\underline{\mathbf{x}}}^{\left( N\right) }\right) & {g}_{1}\left( {\underline{\mathbf{x}}}^{\left( N\right) }\right) & \cdots & {g}_{s}\left( {\underline{\mathbf{x}}}^{\left( N\right) }\right)  \end{matrix}\right)
$$

(16.163d)

由 (16.163c) 可得到所谓正则方程组

$$
{G}^{\mathrm{T}}G\widetilde{\underline{a}} = {G}^{\mathrm{T}}\underline{f} \tag{16.163e}
$$

用来确定 $\underline{\widetilde{a}}$ . 矩阵 ${\mathbf{G}}^{\mathrm{T}}\mathbf{G}$ 对称,故楚列斯基方法 (参见第 1245 页 19.2.1.2) 特别适用于求解式 (16.163e).

I 根据下表中列出的样本数据, 试确定回归函数 (16.164) 的系数:

$$
\widetilde{f}\left( {{x}_{1},{x}_{2}}\right)  = {a}_{0} + {a}_{1}{x}_{1} + {a}_{2}{x}_{2}. \tag{16.164}
$$

<table><tr><td>

${x}_{1}$

</td><td>

5

</td><td>

3

</td><td>

5

</td><td>

3

</td></tr><tr><td>

${x}_{2}$

</td><td>

0.5

</td><td>

0.5

</td><td>

0.3

</td><td>

0.3

</td></tr><tr><td>

$f\left( {{x}_{1},{x}_{2}}\right)$

</td><td>

1.5

</td><td>

3.5

</td><td>

6.2

</td><td>

3.2

</td></tr></table>

由 (16.163d) 可推出

$$
\widetilde{\underline{\mathbf{a}}} = \left( \begin{matrix} {\widetilde{a}}_{0} \\  {\widetilde{a}}_{1} \\  {\widetilde{a}}_{2} \end{matrix}\right) ,\;\underline{\mathbf{f}} = \left( \begin{matrix} {1.5} \\  {3.5} \\  {6.2} \\  {3.2} \end{matrix}\right) ,\;\mathbf{G} = \left( \begin{matrix} 1 & 5 & {0.5} \\  1 & 3 & {0.5} \\  1 & 5 & {0.3} \\  1 & 3 & {0.3} \end{matrix}\right)  \tag{16.165}
$$

且 (16.163e) 式为

$$
4{\widetilde{a}}_{0} + {16}{\widetilde{a}}_{1} + {1.6}{\widetilde{a}}_{2} = {14.4},\;{\widetilde{a}}_{0} = {7.0},
$$

$$
{16}{\widetilde{a}}_{0} + {68}{\widetilde{a}}_{1} + {6.4}{\widetilde{a}}_{2} = {58.6},\;\text{即}{\widetilde{a}}_{1} = {0.25}\text{,} \tag{16.166}
$$

$$
{1.6}{\widetilde{a}}_{0} + {6.4}{\widetilde{a}}_{1} + {0.68}{\widetilde{a}}_{2} = {5.32},\;{\widetilde{a}}_{2} =  - {11}.
$$

4. 注

**(1) 为确定回归系数,使用插值** $\widetilde{f}\left( {\underline{\mathbf{x}}}^{\left( i\right) }\right)  = {f}_{i}\left( {i = 1,2,\cdots , N}\right)$ ,即

$$
G\underline{\widetilde{a}} = \underline{f}. \tag{16.167}
$$

当 $s < N$ 时,(16.167) 是超定方程组,可用豪斯霍尔德法求其解 (参见第 1280 页 19.6.2.2). 用 ${\mathbf{G}}^{\mathrm{T}}$ 乘以 (16.167) 式则得到 (16.163e),也称为高斯变换. 若矩阵 $\mathbf{G}$ 的列线性无关,即矩阵 $\mathbf{G}$ 的秩等于 $s + 1$ ,则正则方程组 (16.163e) 有唯一解,这与由豪斯霍尔德法所得到的结果 (16.167) 一致.

**(2) 在多元情形下,也可以使用** $t$ 分布确定回归系数的置信区间,与 $({16.159}\mathrm{a}$ , 16.159b) 类似.

**(3) 借助于** $F$ 分布 (参见第 1075 页 16.2.4.7),使用所谓等价检验分析 (16.163b) 式也是可行的. 检验可判断形如 (16.163b) 但有较少项的解是否为理论回归函数 (16.160) 的充分逼近 (参见文献 [16.9]).
