# 4.6.2 特殊特征值问题

## 4.6.2.1 特征多项式

特征值方程 (4.194) 产生一个齐次方程组, 它仅当

$$
\det \left( {\mathbf{A} - \lambda \mathbf{I}}\right)  = 0 \tag{4.195a}
$$

时有非平凡解 $\underline{\mathbf{x}} \neq  \underline{\mathbf{0}}$ . 展开行列式 $\det \left( {\mathbf{A} - \lambda \mathbf{I}}\right)$ 得到

$$
\det \left( {\mathbf{A} - \lambda \mathbf{I}}\right)  = \left| \begin{matrix} {a}_{11} - \lambda & {a}_{12} & {a}_{13} & \cdots & {a}_{1n} \\  {a}_{21} & {a}_{22} - \lambda & {a}_{23} & \cdots & {a}_{2n} \\  \vdots & \vdots & \vdots & & \vdots \\  {a}_{n1} & {a}_{n2} & {a}_{n3} & \cdots & {a}_{nn} - \lambda  \end{matrix}\right|
$$

$$
= {P}_{n}\left( \lambda \right)  = {\left( -1\right) }^{n}{\lambda }^{n} + {a}_{n - 1}{\lambda }^{n - 1} + \cdots  + {a}_{1}\lambda  + {a}_{0} = 0. \tag{4.195b}
$$

因此特征值行列式等价于一个多项式方程. 这个方程称为特征方程,多项式 ${P}_{n}\left( \lambda \right)$ 称为特征多项式. 它的根是矩阵 $\mathbf{A}$ 的特征值. 对于任意 $n$ 阶方阵 $\mathbf{A}$ ,下列命题成立.

情形 1: 因为 $n$ 次多项式有 $n$ 个根 (若考虑它们的重数),所以矩阵 ${\mathbf{A}}_{\left( n, n\right) }$ 恰有 $n$ 个特征值 ${\lambda }_{1},{\lambda }_{2},\cdots ,{\lambda }_{n}$ . 实对称矩阵的特征值都是实数,在其他情形特征值也可能是复数.

情形 2: 如果所有 $n$ 个特征值互异,那么矩阵 ${\mathbf{A}}_{\left( n, n\right) }$ 恰有 $n$ 个线性无关的特征向量 ${\underline{x}}_{i}$ ,它们是方程组 (4.194) 当 $\lambda  = {\lambda }_{i}$ 时的解.

情形 3: 如果在特征值中 ${\lambda }_{i}$ 的重数是 ${n}_{i}$ ,并且矩阵 ${\mathbf{A}}_{\left( n, n\right) } - {\lambda }_{i}\mathbf{I}$ 的秩等于 ${r}_{i}$ ,那么对应于 ${\lambda }_{i}$ 的线性无关的特征向量的个数等于所谓系数矩阵的零化度 $n - {r}_{i}$ . 不等式 $1 \leq  n - {r}_{i} \leq  {n}_{i}$ 成立,即对于实或复方阵 ${\mathbf{A}}_{\left( n, n\right) }$ 存在至少 1 个、至多 $n$ 个实或复的线性无关的特征向量.

$\square \mathrm{A}$ :

$$
\left( \begin{matrix} 2 &  - 3 & 1 \\  3 & 1 & 3 \\   - 5 & 2 &  - 4 \end{matrix}\right)
$$

$$
\det \left( {\mathbf{A} - \lambda \mathbf{I}}\right)  = \left| \begin{matrix} 2 - \lambda &  - 3 & 1 \\  3 & 1 - \lambda & 3 \\   - 5 & 2 &  - 4 - \lambda  \end{matrix}\right|  =  - {\lambda }^{3} - {\lambda }^{2} + {2\lambda } = 0.
$$

特征值是 ${\lambda }_{1} = 0,{\lambda }_{2} = 1,{\lambda }_{3} =  - 2$ . 特征向量由对应的线性齐次方程组确定:

- ${\lambda }_{1} = 0$ :

$$
2{x}_{1} - 3{x}_{2} + {x}_{3} = 0,
$$

$$
3{x}_{1} + {x}_{2} + 3{x}_{3} = 0,
$$

$$
- 5{x}_{1} + 2{x}_{2} - 4{x}_{3} = 0.
$$

用 (例如) 选主元法求得: ${x}_{1}$ 任意, ${x}_{2} = \frac{3}{10}{x}_{1},{x}_{3} =  - 2{x}_{1} + 3{x}_{2} =  - \frac{11}{10}{x}_{1}$ . 若取

${x}_{1} = {10}$ ,则特征向量是

$$
{\underline{\mathbf{x}}}_{1} = {C}_{1}\left( \begin{matrix} {10} \\  3 \\   - {11} \end{matrix}\right)
$$

其中 ${C}_{1} \neq  0$ 是任意常数.

- ${\lambda }_{2} = 1$ : 对应的齐次方程组产生: ${x}_{3}$ 任意, ${x}_{2} = 0,{x}_{1} = 3{x}_{2} - {x}_{3} =  - {x}_{3}$ . 若取 ${x}_{3} = 1$ ,则特征向量是

$$
{\underline{\mathbf{x}}}_{2} = {C}_{2}\left( \begin{matrix}  - 1 \\  0 \\  1 \end{matrix}\right)
$$

其中 ${C}_{2} \neq  0$ 是任意常数.

- ${\lambda }_{3} =  - 2$ : 对应的齐次方程组产生: ${x}_{2}$ 任意, ${x}_{1} = \frac{4}{3}{x}_{2},{x}_{3} =  - 4{x}_{1} + 3{x}_{2} =$ $- \frac{7}{3}{x}_{2}$ . 若取 ${x}_{2} = 3$ ,则特征向量是

$$
{\underline{\mathbf{x}}}_{3} = {C}_{3}\left( \begin{matrix} 4 \\  3 \\   - 7 \end{matrix}\right)
$$

其中 ${C}_{3} \neq  0$ 是任意常数.

II $\mathrm{B}$ :

$$
\left( \begin{matrix} 3 & 0 &  - 1 \\  1 & 4 & 1 \\   - 1 & 0 & 3 \end{matrix}\right)
$$

$$
\det \left( {\mathbf{A} - \lambda \mathbf{I}}\right)  = \left| \begin{matrix} 3 - \lambda & 0 &  - 1 \\  1 & 4 - \lambda & 1 \\   - 1 & 0 & 3 - \lambda  \end{matrix}\right|  =  - {\lambda }^{3} + {10}{\lambda }^{2} - {32\lambda } + {32} = 0.
$$

特征值是 ${\lambda }_{1} = 2,{\lambda }_{2} = {\lambda }_{3} = 4$ .

- ${\lambda }_{1} = 2$ : 我们求得: ${x}_{3}$ 任意, ${x}_{2} =  - {x}_{3},{x}_{1} = {x}_{3}$ ,并且取 (例如) ${x}_{3} = 1$ . 于是对

应的特征向量是

$$
{\underline{\mathbf{x}}}_{1} = {C}_{1}\left( \begin{matrix} 1 \\   - 1 \\  1 \end{matrix}\right)
$$

其中 ${C}_{1} \neq  0$ 是任意常数.

- ${\lambda }_{2} = {\lambda }_{3} = 4$ : 我们得到: ${x}_{3},{x}_{3}$ 任意, ${x}_{1} =  - {x}_{3}$ . 存在两个线性无关的特征向量,例如,当 ${x}_{2} = 1,{x}_{3} = 0$ 及 ${x}_{2} = 0,{x}_{3} = 1$ 时,

$$
{\underline{\mathbf{x}}}_{2} = {C}_{2}\left( \begin{array}{l} 0 \\  1 \\  0 \end{array}\right) ,\;{\underline{\mathbf{x}}}_{3} = {C}_{3}\left( \begin{matrix}  - 1 \\  0 \\  1 \end{matrix}\right) ,
$$

其中 ${C}_{2} \neq  0,{C}_{3} \neq  0$ 是任意常数.

## 4.6.2.2 实对称矩阵、相似变换

在对于实对称矩阵 $\mathbf{A}$ 的特殊特征值问题 (4.194) 情形,下列命题成立. 1. 与特征值问题有关的性质

(1) 特征值的个数 矩阵 $\mathbf{A}$ 恰有 $n$ 个实特征值 ${\lambda }_{i}\left( {i = 1,2,\cdots , n}\right)$ ,这里计数要考虑它们的重数.

(2) 特征向量的正交性 对应于不同的特征值 ${\lambda }_{i} \neq  {\lambda }_{j}$ 的特征向量 ${\underline{\mathbf{x}}}_{i}$ 和 ${\underline{\mathbf{x}}}_{j}$ 互相正交,即对于 ${\underline{x}}_{i}$ 和 ${\underline{x}}_{j}$ 的标量积有

$$
{\underline{\mathbf{x}}}_{i}^{\mathrm{T}}{\underline{\mathbf{x}}}_{j} = \left( {{\underline{\mathbf{x}}}_{i},{\underline{\mathbf{x}}}_{j}}\right)  = 0. \tag{4.196}
$$

(3) 有 $p$ 重特征值的矩阵 对于重数为 $p$ 的特征值 $\left( {\lambda  = {\lambda }_{1} = {\lambda }_{2} = \cdots  = {\lambda }_{p}}\right)$ , 存在 $p$ 个线性无关的特征向量 ${\underline{\mathbf{x}}}_{1},{\underline{\mathbf{x}}}_{2},\cdots ,{\underline{\mathbf{x}}}_{p}$ . 由 (4.194),它们所有非平凡线性组合也是对应于 $\lambda$ 的特征向量. 应用格拉姆-施密特正交化方法,我们可以从这些组合中选取 $p$ 个使它们互相正交.

综而言之: $\mathbf{A}$ 恰有 $n$ 个是实正交特征向量.

- $\mathbf{A} = \left( \begin{array}{lll} 0 & 1 & 1 \\  1 & 0 & 1 \\  1 & 1 & 0 \end{array}\right) ,\det \left( {\mathbf{A} - \lambda \mathbf{I}}\right)  =  - {\lambda }^{3} + {3\lambda } + 2 = 0$ . 特征值是 ${\lambda }_{1} = {\lambda }_{2} =  - 1$

及 ${\lambda }_{3} = 2$ .

- ${\lambda }_{1} = {\lambda }_{2} =  - 1$ : 由对应的齐次方程组得到: ${x}_{1}$ 任意, ${x}_{2}$ 任意, ${x}_{3} =  - {x}_{1} - {x}_{2}$ . 首先取 ${x}_{1} = 1,{x}_{2} = 0$ ,然后取 ${x}_{1} = 0,{x}_{2} = 1$ ,我们得到线性无关的特征向量 ${\underline{x}}_{1} = {C}_{1}\left( \begin{matrix} 1 \\  0 \\   - 1 \end{matrix}\right)$ 和 ${\underline{x}}_{2} = {C}_{2}\left( \begin{matrix} 0 \\  1 \\   - 1 \end{matrix}\right)$ ,其中 ${C}_{1} \neq  0$ 和 ${C}_{2} \neq  0$ 是任意常数. - ${\lambda }_{3} = 2$ : 我们得到 ${x}_{1}$ 任意, ${x}_{2} = {x}_{1},{x}_{3} = {x}_{1}$ ,并且取 (例如) ${x}_{1} = 1$ ,得到特征向量 ${\underline{\mathbf{x}}}_{3} = {C}_{3}\left( \begin{array}{l} 1 \\  1 \\  1 \end{array}\right)$ ,其中 ${C}_{3} \neq  0$ 是任意常数. 矩阵 $\mathbf{A}$ 对称,所以对应于不同的特征值的特征向量正交.

(4) 格拉姆-施密特正交化方法 设 ${V}_{n}$ 是任意 $n$ 维欧氏向量空间. 设向量 ${\underline{\mathbf{x}}}_{1},{\underline{\mathbf{x}}}_{2},\cdots ,{\underline{\mathbf{x}}}_{n} \in  {V}_{n}$ 线性无关,那么存在正交向量组 ${\underline{\mathbf{y}}}_{1},{\underline{\mathbf{y}}}_{2},\cdots ,{\underline{\mathbf{y}}}_{n} \in  {V}_{n}$ ,它们可以由向量 ${\underline{x}}_{i}$ 得到如下:

$$
{\underline{\mathbf{y}}}_{1} = {\underline{\mathbf{x}}}_{1},\;{\underline{\mathbf{y}}}_{k} = {\underline{\mathbf{x}}}_{k} - \mathop{\sum }\limits_{{i = 1}}^{{k - 1}}\frac{\left( {\underline{\mathbf{x}}}_{k},{\underline{\mathbf{y}}}_{i}\right) }{\left( {\underline{\mathbf{y}}}_{i},{\underline{\mathbf{y}}}_{i}\right) }\;\left( {k = 2,3,\cdots , n}\right) . \tag{4.197}
$$

注 (1) 此处 $\left( {{\underline{\mathbf{x}}}_{k},{\underline{\mathbf{y}}}_{i}}\right)  = {\underline{\mathbf{x}}}_{k}^{\mathrm{T}}{\underline{\mathbf{y}}}_{i}$ 是向量 ${\underline{\mathbf{x}}}_{k}$ 和 ${\underline{\mathbf{y}}}_{i}$ 的标量积.

(2) 对应于正交向量组 ${\underline{y}}_{1},{\underline{y}}_{2},\cdots ,{\underline{y}}_{n}$ ,我们得到正交组 ${\underline{\widetilde{x}}}_{1},{\underline{\widetilde{x}}}_{2},\cdots ,{\underline{\widetilde{x}}}_{n}$ ,其中 ${\underline{\widetilde{x}}}_{1} = \frac{{\underline{y}}_{1}}{\begin{Vmatrix}{\underline{y}}_{1}\end{Vmatrix}},{\underline{\widetilde{x}}}_{2} = \frac{{\underline{y}}_{2}}{\begin{Vmatrix}{\underline{y}}_{2}\end{Vmatrix}},\cdots ,{\underline{\widetilde{x}}}_{n} = \frac{{\underline{y}}_{2}}{\begin{Vmatrix}{\underline{y}}_{n}\end{Vmatrix}},\begin{Vmatrix}{\underline{y}}_{i}\end{Vmatrix} = \sqrt{\left( {\underline{y}}_{i},{\underline{y}}_{i}\right) }$ 是向量 ${\underline{y}}_{i}$ 的欧氏模. - ${\underline{\mathbf{x}}}_{1} = \left( \begin{array}{l} 0 \\  1 \\  1 \end{array}\right) ,{\underline{\mathbf{x}}}_{2} = \left( \begin{array}{l} 1 \\  0 \\  1 \end{array}\right) ,{\underline{\mathbf{x}}}_{3} = \left( \begin{array}{l} 1 \\  1 \\  0 \end{array}\right)$ . 由此可得

$$
{\underline{\mathbf{y}}}_{1} = {\underline{\mathbf{x}}}_{1} = \left( \begin{array}{l} 0 \\  1 \\  1 \end{array}\right) \;\text{ 和 }\;{\underline{\widetilde{\mathbf{x}}}}_{1} = \frac{1}{\sqrt{2}}\left( \begin{array}{l} 0 \\  1 \\  1 \end{array}\right) ;
$$

$$
{\underline{\mathbf{y}}}_{2} = {\underline{\mathbf{x}}}_{2} - \frac{\left( {\underline{\mathbf{x}}}_{2},{\underline{\mathbf{y}}}_{1}\right) }{\left( {\underline{\mathbf{y}}}_{1},{\underline{\mathbf{y}}}_{1}\right) }{\underline{\mathbf{y}}}_{1} = \left( \begin{matrix} 1 \\   - 1/2 \\  1/2 \end{matrix}\right) \;\text{ 和 }\;{\underline{\widetilde{\mathbf{x}}}}_{2} = \frac{1}{\sqrt{6}}\left( \begin{matrix} 2 \\   - 1 \\  1 \end{matrix}\right) ;
$$

${\underline{\mathbf{y}}}_{3} = {\underline{\mathbf{x}}}_{3} - \frac{\left( {\underline{\mathbf{x}}}_{3},{\underline{\mathbf{y}}}_{1}\right) }{\left( {\underline{\mathbf{y}}}_{1},{\underline{\mathbf{y}}}_{1}\right) }{\underline{\mathbf{y}}}_{1} - \frac{\left( {\underline{\mathbf{x}}}_{3},{\underline{\mathbf{y}}}_{2}\right) }{\left( {\underline{\mathbf{y}}}_{2},{\underline{\mathbf{y}}}_{2}\right) }{\underline{\mathbf{y}}}_{2} = \left( \begin{matrix} 2/3 \\  2/3 \\   - 2/3 \end{matrix}\right) \;$ 和 $\;{\widetilde{\underline{\mathbf{x}}}}_{3} = \frac{1}{\sqrt{3}}\left( \begin{matrix} 1 \\  1 \\   - 1 \end{matrix}\right) .$

2. 主轴变换、相似变换

对于每个实对称矩阵 $\mathbf{A}$ ,存在正交矩阵 $\mathbf{U}$ 和对角矩阵 $\mathbf{D}$ 满足

$$
\mathbf{A} = \mathbf{U}\mathbf{D}{\mathbf{U}}^{\mathrm{T}}. \tag{4.198}
$$

$\mathbf{D}$ 的对角元素是 $\mathbf{A}$ 的特征值,且 $\mathbf{U}$ 的列是对应的规范化特征向量. 由 (4.198) 显然有

$$
\mathbf{D} = {\mathbf{U}}^{\mathrm{T}}\mathbf{A}\mathbf{U}. \tag{4.199}
$$

(4.199) 称作主轴变换. 这样将 $\mathbf{A}$ 归结为对角矩阵 (还可参见第 362 页 4.1.2,2.).

如果方阵 $\mathbf{A}$ (不必对称) 通过正则方阵 $\mathbf{G}$ 被变换为

$$
{\mathbf{G}}^{-1}\mathbf{A}\mathbf{G} = \widetilde{\mathbf{A}}, \tag{4.200}
$$

那么称它是相似变换. 矩阵 $\mathbf{A}$ 和 $\widetilde{\mathbf{A}}$ 称为相似,并且它们有下列性质:

(1) 矩阵 $\mathbf{A}$ 和 $\widetilde{\mathbf{A}}$ 有相同的特征值,即相似变换不影响特征值.

(2) 如果 $\mathbf{A}$ 对称且 $\mathbf{G}$ 正交,那么 $\widetilde{\mathbf{A}}$ 对称,还有

$$
\widetilde{\mathbf{A}} = {\mathbf{G}}^{\mathrm{T}}\mathbf{A}\mathbf{G},\;\text{ 以及 }{\mathbf{G}}^{\mathrm{T}}\mathbf{G} = \mathbf{I}. \tag{4.201}
$$

关系式 (4.201) 称为正交相似变换. 在此术语下,(4.199) 表明实对称矩阵 $\mathbf{A}$ 可以被变换为与某个实对角矩阵 $\mathbf{D}$ 正交相似.

## 4.6.2.3 二次型的主轴变换

1. 实二次型定义

变量 ${x}_{1},{x}_{2},\cdots ,{x}_{n}$ 的实二次型有形式:

$$
Q = \mathop{\sum }\limits_{{i = 1}}^{n}\mathop{\sum }\limits_{{j = 1}}^{n}{a}_{ij}{x}_{i}{x}_{j} = {\underline{\mathbf{x}}}^{\mathrm{T}}\mathbf{A}\underline{\mathbf{x}}, \tag{4.202}
$$

其中 $\underline{\mathbf{x}} = {\left( {x}_{1},{x}_{2},\cdots ,{x}_{n}\right) }^{\mathrm{T}}$ 是实变量向量,矩阵 $\mathbf{A}$ 是实对称矩阵.

如果型 $Q$ 除当 ${x}_{1} = {x}_{2} = \cdots  = {x}_{n} = 0$ 情形取值零外只取正值或只取负值, 那么它分别称为正定的或负定的.

型 $Q$ 称为半正定的或半负定的,如果它所取的非零值仅是正的或仅是负的,并且当非零向量也可能取值零.

实二次型称为不定的,如果它取正值也取负值. 依据 $Q$ 的性状,与它相关的实对称矩阵称为正定的、负定的、半正定的或不定的.

2. 实正定二次型, 性质

(1) 在实正定二次型 $Q$ 中,对应的实对称矩阵 $\mathbf{A}$ 的主对角元都是正的,即有

$$
{a}_{ii} > 0\;\left( {i = 1,2,\cdots , n}\right) . \tag{4.203}
$$

(4.203) 表述了正定矩阵的一个很重要的性质.

(2)实二次型 $Q$ 是正定的,当且仅当对应的实对称矩阵 $\mathbf{A}$ 的所有特征值是正的.

(3) 设对应于实二次型 $Q = {\underline{x}}^{\mathrm{T}}\mathbf{A}\underline{x}$ 的矩阵 $\mathbf{A}$ 的秩等于 $r$ ,那么二次型可以通过线性变换

$$
\underline{x} = C\underline{\widetilde{x}} \tag{4.204}
$$

化为纯二次项之和, 即所谓标准形

$$
Q = {\widetilde{\underline{\mathbf{x}}}}^{\mathrm{T}}\mathbf{K}\widetilde{\underline{\mathbf{x}}} = \mathop{\sum }\limits_{{i = 1}}^{r}{p}_{i}{\widetilde{x}}_{i}^{2}, \tag{4.205}
$$

其中 ${p}_{i} = \left( {\operatorname{sign}{\lambda }_{i}}\right) {k}_{i}$ ,并且 ${k}_{1},{k}_{2},\cdots ,{k}_{r}$ 是任意预先给定的正常数.

注 对于任何将秩为 $r$ 的实二次型变换为标准形 (4.205) 的非奇异变换 (4.204), 标准形中正系数个数 $p$ 和负系数个数 $q = r - p$ 是不变的 (西尔维斯特惯性定理). 值 $p$ 称为二次型的惯性指数.

3. 标准形的生成

应用变换 (4.205) 的一个实用方法是从主轴变换 (4.199) 得来的. 首先通过正交矩阵 $\mathbf{U}$ 实施坐标系的旋转,这里 $\mathbf{U}$ 的各列是 $\mathbf{A}$ 的特征向量 (即新坐标系的轴的方向是特征向量的方向). 这给出型

$$
Q = {\widetilde{\underline{\mathbf{x}}}}^{\mathrm{T}}\mathbf{L}\widetilde{\underline{\mathbf{x}}} = \mathop{\sum }\limits_{{i = 1}}^{r}{\lambda }_{i}{\widetilde{x}}_{i}^{2}. \tag{4.206}
$$

这里 $\mathbf{L}$ 是对角元为 $\mathbf{A}$ 的特征值的对角矩阵. 然后通过对角矩阵 $\mathbf{D}$ 实施伸缩,这里 $\mathbf{D}$ 的对角元是 ${d}_{i} = \sqrt{\frac{{k}_{i}}{\left| {\lambda }_{i}\right| }}$ . 于是整个变换由矩阵

$$
\mathbf{C} = \mathbf{U}\mathbf{D} \tag{4.207}
$$

给出, 并且我们得到

$$
Q = {\underline{\widetilde{\mathbf{x}}}}^{\mathrm{T}}\mathbf{A}\underline{\widetilde{\mathbf{x}}} = {\left( \mathbf{U}\mathbf{D}\underline{\widetilde{\mathbf{x}}}\right) }^{\mathrm{T}}\mathbf{A}\left( {\mathbf{U}\mathbf{D}\underline{\widetilde{\mathbf{x}}}}\right)  = {\underline{\widetilde{\mathbf{x}}}}^{\mathrm{T}}\left( {{\mathbf{D}}^{\mathrm{T}}{\mathbf{U}}^{\mathrm{T}}\mathbf{A}\mathbf{U}\mathbf{D}}\right) \underline{\widetilde{\mathbf{x}}}
$$

$$
= {\widetilde{\underline{\mathbf{x}}}}^{\mathrm{T}}{\mathbf{D}}^{\mathrm{T}}\mathbf{L}\mathbf{D}\widetilde{\underline{\mathbf{x}}} = {\widetilde{\underline{\mathbf{x}}}}^{\mathrm{T}}\mathbf{K}\widetilde{\underline{\mathbf{x}}}. \tag{4.208}
$$

注 二次型的主轴变换在二阶曲线和曲面的的分类中起着本质性作用 (参见第 277 页 3.5.2.11 及第 306 页 3.5.3.14).

4. 若尔当标准形

设 $\mathbf{A}$ 是任意 $n$ 阶实或复矩阵,那么存在非奇异矩阵 $\mathbf{T}$ 使得

$$
{\mathbf{T}}^{-1}\mathbf{A}\mathbf{T} = \mathbf{J}, \tag{4.209}
$$

其中 $\mathbf{J}$ 称为 $\mathbf{A}$ 的若尔当矩阵或若尔当标准形. 若尔当矩阵有 (4.210) 形式的分块对角结构,其中 $\mathbf{J}$ 的元素 ${\mathbf{J}}_{j}$ 称为若尔当块:

$$
\mathbf{J} = \left( \begin{matrix} {\mathbf{J}}_{1} & & & & \\   & {\mathbf{J}}_{2} & & & \mathbf{O} \\   & &  \ddots  & & \\  \mathbf{O} & & & {\mathbf{J}}_{k - 1} & \\   & & & & {\mathbf{J}}_{k} \end{matrix}\right) . \tag{4.210}
$$

$$
\mathbf{J} = \left( \begin{matrix} {\lambda }_{1} & & & & \\   & {\lambda }_{2} & & & \mathbf{O} \\   & &  \ddots  & & \\  \mathbf{O} & & & {\lambda }_{n - 1} & \\   & & & & {\lambda }_{n} \end{matrix}\right) . \tag{4.211}
$$

它们有下列结构:

(1) 如果 $\mathbf{A}$ 只有单特征值 ${\lambda }_{j}$ ,那么 ${\mathbf{J}}_{j} = {\lambda }_{j}$ ,并且 $k = n$ ,即 $\mathbf{J}$ 是对角矩阵(4.211).

(2) 如果 ${\lambda }_{j}$ 是重数为 ${p}_{j}$ 的特征值,那么存在一个或多个 (4.212) 形式的块:

$$
{\mathbf{J}}_{j} = \left( \begin{matrix} {\lambda }_{j} & 1 & & & \\   & {\lambda }_{j} & 1 & & \mathbf{O} \\   & &  \ddots  &  \ddots  & \\  \mathbf{O} & & & {\lambda }_{j} & 1 \\   & & & & {\lambda }_{j} \end{matrix}\right) , \tag{4.212}
$$

这里所有这样的块的大小之和等于 ${p}_{j}$ ,并且 $\mathop{\sum }\limits_{{j = 1}}^{k}{p}_{j} = n$ . 若尔当块的精确结构取决于特征矩阵 $\mathbf{A} - \lambda \mathbf{I}$ 的初等因子的结构.

进一步的信息见 [4.18], [19.3](第 1 卷).

## 4.6.2.4 对于特征值的数值计算的建议

(1) 特征值可以作为特征方程 (4.195b) 的根计算. 为了求出它们必须确定矩阵 $\mathbf{A}$ 的特征多项式的系数 ${a}_{i}\left( {i = 0,1,2,\cdots , n - 1}\right)$ . 但是我们必须避开这些计算方法, 因为这些方法是极不稳定的,也就是说,多项式系数 ${a}_{i}$ 的微小变化会导致根 ${\lambda }_{j}$ 的大的变化.

(2) 有许多解对称矩阵特征值问题的算法. 它们可区分为两种类型 (见 [4.7]):

a) 变换方法, 例如, 雅可比方法、豪斯霍尔德三对角化、QR 算法.

b) 迭代法, 例如, 向量迭代、瑞利-里茨算法、逆迭代、兰乔斯方法、对分法. 作为例子我们在此讨论米泽斯乘幂法.

(3) 米泽斯乘幂法 设 $\mathbf{A}$ 是实对称矩阵,并且只有唯一主特征值. 迭代法确定这个特征值及相应的特征向量. 设主特征值记作 ${\lambda }_{1}$ ,于是

$$
\left| {\lambda }_{1}\right|  > \left| {\lambda }_{2}\right|  \geq  \left| {\lambda }_{3}\right|  \geq  \cdots  \geq  \left| {\lambda }_{n}\right| . \tag{4.213}
$$

设 ${\underline{\mathbf{x}}}_{1},{\underline{\mathbf{x}}}_{2},\cdots ,{\underline{\mathbf{x}}}_{n}$ 是相应的线性无关的特征向量,那么

a) $\mathbf{A}{\underline{\mathbf{x}}}_{i} = {\lambda }_{i}{\underline{\mathbf{x}}}_{i}\left( {i = 1,2,\cdots , n}\right)$ .(4.214)

b) 每个元素 $\underline{x} \in  {\mathbb{R}}^{n}$ 可以表示为这些特征向量 ${\underline{x}}_{i}$ 的线性组合:

$$
\underline{\mathbf{x}} = {c}_{1}{\underline{\mathbf{x}}}_{1} + {c}_{2}{\underline{\mathbf{x}}}_{2} + \cdots  + {c}_{n}{\underline{\mathbf{x}}}_{n}\;\left( {{c}_{i}\text{ 是常数; }i = 1,2,\cdots , n}\right) . \tag{4.215}
$$

在 (4.215) 两边用 $\mathbf{A}$ 乘 $k$ 次,那么应用 (4.214) 得到

$$
{\mathbf{A}}^{k}\underline{\mathbf{x}} = {c}_{1}{\lambda }_{1}^{k}{\underline{\mathbf{x}}}_{1} + {c}_{2}{\lambda }_{2}^{k}{\underline{\mathbf{x}}}_{2} + \cdots  + {c}_{n}{\lambda }_{n}^{k}{\underline{\mathbf{x}}}_{n}
$$

$$
= {\lambda }_{1}^{k}\left( {{c}_{1}{\underline{\mathbf{x}}}_{1} + {c}_{2}{\left( \frac{{\lambda }_{2}}{{\lambda }_{1}}\right) }^{k}{\underline{\mathbf{x}}}_{2} + \cdots  + {c}_{n}{\left( \frac{{\lambda }_{n}}{{\lambda }_{1}}\right) }^{k}{\underline{\mathbf{x}}}_{n}}\right) . \tag{4.216}
$$

由此关系式和 (4.213) 可见当 $k \rightarrow  \infty$ 时,

$$
\frac{{\mathbf{A}}^{k}\underline{\mathbf{x}}}{{\lambda }_{1}^{k}{c}_{1}} \rightarrow  {\underline{\mathbf{x}}}_{1},\;\text{ 即 }\;{\mathbf{A}}^{k}\underline{\mathbf{x}} \approx  {c}_{1}{\lambda }_{1}^{k}{\underline{\mathbf{x}}}_{1}. \tag{4.217}
$$

这是下列迭代程序的基础:

步骤 1 选择任意初始向量 ${\underline{\mathbf{x}}}^{\left( 0\right) } \in  {\mathbb{R}}^{n}$ .

步骤 2 迭代计算

$$
{\underline{\mathbf{x}}}^{\left( k + 1\right) } = \mathbf{A}{\underline{\mathbf{x}}}^{k}\;\left( {k = 0,1,2,\cdots ;{\underline{\mathbf{x}}}^{\left( 0\right) }\text{ 给定 }}\right) . \tag{4.218}
$$

由 (4.218) 并且注意 (4.217) 可得到

$$
{\underline{\mathbf{x}}}^{\left( k\right) } = {\mathbf{A}}^{k}{\underline{\mathbf{x}}}^{\left( 0\right) } \approx  {c}_{1}{\lambda }_{1}^{k}{\underline{\mathbf{x}}}_{1}. \tag{4.219}
$$

步骤 3 由 (4.218) 和 (4.219) 得到

$$
{\underline{\mathbf{x}}}^{\left( k + 1\right) } = \mathbf{A}{\underline{\mathbf{x}}}^{\left( k\right) } = \mathbf{A}\left( {{\mathbf{A}}^{k}{\underline{\mathbf{x}}}^{\left( 0\right) }}\right) ,
$$

$$
\mathbf{A}\left( {{\mathbf{A}}^{k}{\underline{\mathbf{x}}}^{\left( 0\right) }}\right)  \approx  \mathbf{A}\left( {{c}_{1}{\lambda }_{1}^{k}{\underline{\mathbf{x}}}_{1}}\right)  = {c}_{1}{\lambda }_{1}^{k}\left( {\mathbf{A}{\underline{\mathbf{x}}}_{1}}\right) ,
$$

$$
{c}_{1}\left( {{\lambda }_{1}^{k}\mathbf{A}{\underline{\mathbf{x}}}_{1}}\right)  = {\lambda }_{1}\left( {{c}_{1}{\lambda }_{1}^{k}{\underline{\mathbf{x}}}_{1}}\right)  \approx  {\lambda }_{1}{\underline{\mathbf{x}}}^{\left( k\right) },
$$

因此,

$$
{\underline{\mathbf{x}}}^{\left( k + 1\right) } \approx  {\lambda }_{1}{\underline{\mathbf{x}}}^{\left( k\right) }, \tag{4.220}
$$

这就是说,对于大的 $k$ 值相继向量 ${\underline{\mathbf{x}}}^{\left( k + 1\right) }$ 和 ${\underline{\mathbf{x}}}^{\left( k\right) }$ 近似地相差一个因子 ${\lambda }_{1}$ .

步骤 4 关系式 (4.219) 和 (4.220) 蕴涵对于 ${\underline{x}}_{1}$ 和 ${\lambda }_{1}$ 有

$$
{\underline{\mathbf{x}}}_{1} \approx  {\underline{\mathbf{x}}}^{\left( k + 1\right) },\;{\lambda }_{1} \approx  \frac{\left( {\underline{\mathbf{x}}}^{\left( k\right) },{\underline{\mathbf{x}}}^{\left( k + 1\right) }\right) }{\left( {\underline{\mathbf{x}}}^{\left( k\right) },{\underline{\mathbf{x}}}^{\left( k\right) }\right) }. \tag{4.221}
$$

例如, 设

$$
\mathbf{A} = \left( \begin{matrix} {3.23} &  - {1.15} & {1.77} \\   - {1.15} & {9.25} &  - {2.13} \\  {1.77} &  - {2.13} & {1.56} \end{matrix}\right) ,\;{\underline{\mathbf{x}}}^{\left( 0\right) } = \left( \begin{array}{l} 1 \\  0 \\  0 \end{array}\right) .
$$

<table><tr><td>

${\mathbf{x}}^{\left( 0\right) }$

</td><td>

${\mathbf{x}}^{\left( 1\right) }$

</td><td>

${\mathbf{x}}^{\left( 2\right) }$

</td><td>

${\mathbf{x}}^{\left( 3\right) }$

</td><td>

规范化

</td><td>

${\mathbf{x}}^{\left( 4\right) }$

</td><td>

${\mathbf{x}}^{\left( 5\right) }$

</td><td>

规范化

</td></tr><tr><td>

1

</td><td>

3.23

</td><td>

14.89

</td><td>

88.27

</td><td>

1

</td><td>

7.58

</td><td>

67.75

</td><td>

1

</td></tr><tr><td>

0

</td><td>

-1.15

</td><td>

-18.12

</td><td>

-208.03

</td><td>

-2.36

</td><td>

-24.93

</td><td>

-256.85

</td><td>

-3.79

</td></tr><tr><td>

0

</td><td>

1.77

</td><td>

10.93

</td><td>

82.00

</td><td>

0.93

</td><td>

8.24

</td><td>

79.37

</td><td>

1.17

</td></tr><tr><td>

${\lambda }_{1}$

</td><td/><td/><td/><td>

9.964

</td><td/><td/><td>

10.177

</td></tr></table>

<table><tr><td>

${\mathbf{x}}^{\left( 6\right) }$

</td><td>

${\mathbf{x}}^{\left( 7\right) }$

</td><td>

规范化

</td><td>

${\mathbf{x}}^{\left( 8\right) }$

</td><td>

${\mathbf{x}}^{\left( 9\right) }$

</td><td>

规范化

</td></tr><tr><td>

9.66

</td><td>

96.40

</td><td>

1

</td><td>

10.09

</td><td>

102.33

</td><td/></tr><tr><td>

-38.78

</td><td>

-394.09

</td><td>

-4.09

</td><td>

-41.58

</td><td>

-422.49

</td><td>

$\left( \begin{matrix} 1 \\   - {4.129} \\  {1.229} \end{matrix}\right)  \approx  {\underline{\mathbf{x}}}_{1}$

</td></tr><tr><td>

11.67

</td><td>

117.78

</td><td>

1.22

</td><td>

12.38

</td><td>

125.73

</td><td/></tr><tr><td/><td/><td>

10.16

</td><td/><td/><td>

${10.161} \approx  {\lambda }_{1}$

</td></tr></table>

注 (1) 因为除常数因子外特征向量是唯一确定的, 所以如例题所示将向量 ${\underline{x}}^{\left( k\right) }$ 规范化是更为可取的.

(2)具有最小绝对值的特征值及相应的特征向量可以将米泽斯乘幂法应用于 ${\mathbf{A}}^{-1}$ 而得到. 如果 ${\mathbf{A}}^{-1}$ 不存在,那么 0 就是这个特征值,并且 $\mathbf{A}$ 的零空间中的任何向量都可选作相应的特征向量.

(3) $\mathbf{A}$ 的其他特征值及相应的特征向量可以通过反复应用下列想法而得到. 选取初始向量与已知向量 ${\underline{x}}_{1}$ 正交,并且在这个子空间中 ${\lambda }_{2}$ 成为主特征值,这可以应用乘幂法得到. 为了求 ${\lambda }_{3}$ ,初始向量与已知向量必须与 ${\underline{\mathbf{x}}}_{1}$ 和 ${\underline{\mathbf{x}}}_{2}$ 正交,等等. 这个方法称为矩阵压缩.

(4) 基于 (4.218), 乘幂法有时称作向量迭代.
